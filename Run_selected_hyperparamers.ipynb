{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kferES7hG0qd"
   },
   "source": [
    "Test out a custom trainer that takes class weights into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ibDj9sQ01PBI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import evaluate\n",
    "\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import hyperopt\n",
    "\n",
    "from torch import nn\n",
    "from transformers import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843
    },
    "id": "kA15Apw11PJm",
    "outputId": "bfb3e696-9215-41fd-ecae-40b007f00a0b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>senolytic</th>\n",
       "      <th>Library</th>\n",
       "      <th>Source</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>BalabanJ</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi0</th>\n",
       "      <th>Chi0n</th>\n",
       "      <th>Chi0v</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "      <th>qed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Azaguanine-8</td>\n",
       "      <td>0</td>\n",
       "      <td>Prestwick</td>\n",
       "      <td>Not identified</td>\n",
       "      <td>c12/N=C(\\NC(c1nn[nH]2)=O)/N</td>\n",
       "      <td>3.024307</td>\n",
       "      <td>441.024163</td>\n",
       "      <td>7.844935</td>\n",
       "      <td>5.327239</td>\n",
       "      <td>5.327239</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allantoin</td>\n",
       "      <td>0</td>\n",
       "      <td>Prestwick</td>\n",
       "      <td>Not identified</td>\n",
       "      <td>N1C(NC(C1=O)NC(=O)N)=O</td>\n",
       "      <td>2.534439</td>\n",
       "      <td>225.377060</td>\n",
       "      <td>8.430721</td>\n",
       "      <td>5.379445</td>\n",
       "      <td>5.379445</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.325138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acetazolamide</td>\n",
       "      <td>0</td>\n",
       "      <td>Prestwick</td>\n",
       "      <td>Not identified</td>\n",
       "      <td>c1(S(=O)(=O)N)sc(nn1)NC(=O)C</td>\n",
       "      <td>2.938691</td>\n",
       "      <td>422.352468</td>\n",
       "      <td>10.060478</td>\n",
       "      <td>6.513019</td>\n",
       "      <td>8.146012</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.631859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metformin hydrochloride</td>\n",
       "      <td>0</td>\n",
       "      <td>Prestwick</td>\n",
       "      <td>Not identified</td>\n",
       "      <td>C(NC(=N)N)(=N)N(C)C</td>\n",
       "      <td>3.644486</td>\n",
       "      <td>126.919685</td>\n",
       "      <td>7.439158</td>\n",
       "      <td>5.524564</td>\n",
       "      <td>5.524564</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atracurium besylate</td>\n",
       "      <td>0</td>\n",
       "      <td>Prestwick</td>\n",
       "      <td>Not identified</td>\n",
       "      <td>[N+]1(C(c2c(cc(c(c2)OC)OC)CC1)Cc1cc(c(cc1)OC)O...</td>\n",
       "      <td>0.987040</td>\n",
       "      <td>2158.836594</td>\n",
       "      <td>48.141042</td>\n",
       "      <td>41.328212</td>\n",
       "      <td>41.328212</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>Curcumin</td>\n",
       "      <td>1</td>\n",
       "      <td>GPNCL, ENZO</td>\n",
       "      <td>Source 12 - Yousefzadeh et al, 2018</td>\n",
       "      <td>COC1=C(C=CC(=C1)/C=C/C(=O)CC(=O)/C=C/C2=CC(=C(...</td>\n",
       "      <td>1.958861</td>\n",
       "      <td>822.040000</td>\n",
       "      <td>19.811190</td>\n",
       "      <td>15.008030</td>\n",
       "      <td>15.008030</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.548123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>Dasatinib</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown library, see publication source</td>\n",
       "      <td>Source 13 - Zhu et al, 2015</td>\n",
       "      <td>CC1=C(C(=CC=C1)Cl)NC(=O)C2=CN=C(S2)NC3=CC(=NC(...</td>\n",
       "      <td>1.431593</td>\n",
       "      <td>1111.432171</td>\n",
       "      <td>23.371668</td>\n",
       "      <td>18.507135</td>\n",
       "      <td>20.079560</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>Navitoclax</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown library, see publication source</td>\n",
       "      <td>Source 14 - Zhu et al, 2016</td>\n",
       "      <td>CC1(CCC(=C(C1)CN2CCN(CC2)C3=CC=C(C=C3)C(=O)NS(...</td>\n",
       "      <td>1.017180</td>\n",
       "      <td>2532.551918</td>\n",
       "      <td>46.408991</td>\n",
       "      <td>36.449290</td>\n",
       "      <td>39.654708</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>A1331852</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown library, see publication source</td>\n",
       "      <td>Source 15 - Zhu et al, 2017</td>\n",
       "      <td>O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=CC=C(C5=C(...</td>\n",
       "      <td>0.969918</td>\n",
       "      <td>2030.733706</td>\n",
       "      <td>32.569974</td>\n",
       "      <td>26.984648</td>\n",
       "      <td>27.801144</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>A1155463</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown library, see publication source</td>\n",
       "      <td>Source 15 - Zhu et al, 2017</td>\n",
       "      <td>O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=NC(C(O)=O)...</td>\n",
       "      <td>1.105426</td>\n",
       "      <td>1978.955255</td>\n",
       "      <td>32.915274</td>\n",
       "      <td>25.878524</td>\n",
       "      <td>27.511517</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.131321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2523 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name  senolytic  \\\n",
       "0                Azaguanine-8          0   \n",
       "1                   Allantoin          0   \n",
       "2               Acetazolamide          0   \n",
       "3     Metformin hydrochloride          0   \n",
       "4         Atracurium besylate          0   \n",
       "...                       ...        ...   \n",
       "2518                 Curcumin          1   \n",
       "2519                Dasatinib          1   \n",
       "2520               Navitoclax          1   \n",
       "2521                 A1331852          1   \n",
       "2522                 A1155463          1   \n",
       "\n",
       "                                      Library  \\\n",
       "0                                   Prestwick   \n",
       "1                                   Prestwick   \n",
       "2                                   Prestwick   \n",
       "3                                   Prestwick   \n",
       "4                                   Prestwick   \n",
       "...                                       ...   \n",
       "2518                              GPNCL, ENZO   \n",
       "2519  Unknown library, see publication source   \n",
       "2520  Unknown library, see publication source   \n",
       "2521  Unknown library, see publication source   \n",
       "2522  Unknown library, see publication source   \n",
       "\n",
       "                                   Source  \\\n",
       "0                          Not identified   \n",
       "1                          Not identified   \n",
       "2                          Not identified   \n",
       "3                          Not identified   \n",
       "4                          Not identified   \n",
       "...                                   ...   \n",
       "2518  Source 12 - Yousefzadeh et al, 2018   \n",
       "2519          Source 13 - Zhu et al, 2015   \n",
       "2520          Source 14 - Zhu et al, 2016   \n",
       "2521          Source 15 - Zhu et al, 2017   \n",
       "2522          Source 15 - Zhu et al, 2017   \n",
       "\n",
       "                                                 SMILES  BalabanJ  \\\n",
       "0                           c12/N=C(\\NC(c1nn[nH]2)=O)/N  3.024307   \n",
       "1                                N1C(NC(C1=O)NC(=O)N)=O  2.534439   \n",
       "2                          c1(S(=O)(=O)N)sc(nn1)NC(=O)C  2.938691   \n",
       "3                                   C(NC(=N)N)(=N)N(C)C  3.644486   \n",
       "4     [N+]1(C(c2c(cc(c(c2)OC)OC)CC1)Cc1cc(c(cc1)OC)O...  0.987040   \n",
       "...                                                 ...       ...   \n",
       "2518  COC1=C(C=CC(=C1)/C=C/C(=O)CC(=O)/C=C/C2=CC(=C(...  1.958861   \n",
       "2519  CC1=C(C(=CC=C1)Cl)NC(=O)C2=CN=C(S2)NC3=CC(=NC(...  1.431593   \n",
       "2520  CC1(CCC(=C(C1)CN2CCN(CC2)C3=CC=C(C=C3)C(=O)NS(...  1.017180   \n",
       "2521  O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=CC=C(C5=C(...  0.969918   \n",
       "2522  O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=NC(C(O)=O)...  1.105426   \n",
       "\n",
       "          BertzCT       Chi0      Chi0n      Chi0v  ...  fr_sulfonamd  \\\n",
       "0      441.024163   7.844935   5.327239   5.327239  ...             0   \n",
       "1      225.377060   8.430721   5.379445   5.379445  ...             0   \n",
       "2      422.352468  10.060478   6.513019   8.146012  ...             1   \n",
       "3      126.919685   7.439158   5.524564   5.524564  ...             0   \n",
       "4     2158.836594  48.141042  41.328212  41.328212  ...             0   \n",
       "...           ...        ...        ...        ...  ...           ...   \n",
       "2518   822.040000  19.811190  15.008030  15.008030  ...             0   \n",
       "2519  1111.432171  23.371668  18.507135  20.079560  ...             0   \n",
       "2520  2532.551918  46.408991  36.449290  39.654708  ...             1   \n",
       "2521  2030.733706  32.569974  26.984648  27.801144  ...             0   \n",
       "2522  1978.955255  32.915274  25.878524  27.511517  ...             0   \n",
       "\n",
       "      fr_sulfone  fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiocyan  \\\n",
       "0              0                  0             0            0            0   \n",
       "1              0                  0             0            0            0   \n",
       "2              0                  0             0            0            0   \n",
       "3              0                  0             0            0            0   \n",
       "4              0                  0             0            0            0   \n",
       "...          ...                ...           ...          ...          ...   \n",
       "2518           0                  0             0            0            0   \n",
       "2519           0                  0             0            1            0   \n",
       "2520           1                  0             0            0            0   \n",
       "2521           0                  0             0            1            0   \n",
       "2522           0                  0             0            2            0   \n",
       "\n",
       "      fr_thiophene  fr_unbrch_alkane  fr_urea       qed  \n",
       "0                0                 0        0  0.430316  \n",
       "1                0                 0        2  0.325138  \n",
       "2                0                 0        0  0.631859  \n",
       "3                0                 0        0  0.248785  \n",
       "4                0                 4        0  0.038349  \n",
       "...            ...               ...      ...       ...  \n",
       "2518             0                 0        0  0.548123  \n",
       "2519             0                 0        0  0.465717  \n",
       "2520             0                 0        0  0.104649  \n",
       "2521             0                 0        0  0.185260  \n",
       "2522             0                 1        0  0.131321  \n",
       "\n",
       "[2523 rows x 205 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Senolytic dataset - labelled\n",
    "senolytics_df = pd.read_csv('list_of_compounds_for_training.csv')\n",
    "senolytics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "OrOR9_0E1cNU",
    "outputId": "5ab03543-5a76-409c-8e50-69e6aba570ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>senolytic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12/N=C(\\NC(c1nn[nH]2)=O)/N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1C(NC(C1=O)NC(=O)N)=O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1(S(=O)(=O)N)sc(nn1)NC(=O)C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C(NC(=N)N)(=N)N(C)C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[N+]1(C(c2c(cc(c(c2)OC)OC)CC1)Cc1cc(c(cc1)OC)O...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>COC1=C(C=CC(=C1)/C=C/C(=O)CC(=O)/C=C/C2=CC(=C(...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>CC1=C(C(=CC=C1)Cl)NC(=O)C2=CN=C(S2)NC3=CC(=NC(...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>CC1(CCC(=C(C1)CN2CCN(CC2)C3=CC=C(C=C3)C(=O)NS(...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=CC=C(C5=C(...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=NC(C(O)=O)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2523 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 SMILES  senolytic\n",
       "0                           c12/N=C(\\NC(c1nn[nH]2)=O)/N          0\n",
       "1                                N1C(NC(C1=O)NC(=O)N)=O          0\n",
       "2                          c1(S(=O)(=O)N)sc(nn1)NC(=O)C          0\n",
       "3                                   C(NC(=N)N)(=N)N(C)C          0\n",
       "4     [N+]1(C(c2c(cc(c(c2)OC)OC)CC1)Cc1cc(c(cc1)OC)O...          0\n",
       "...                                                 ...        ...\n",
       "2518  COC1=C(C=CC(=C1)/C=C/C(=O)CC(=O)/C=C/C2=CC(=C(...          1\n",
       "2519  CC1=C(C(=CC=C1)Cl)NC(=O)C2=CN=C(S2)NC3=CC(=NC(...          1\n",
       "2520  CC1(CCC(=C(C1)CN2CCN(CC2)C3=CC=C(C=C3)C(=O)NS(...          1\n",
       "2521  O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=CC=C(C5=C(...          1\n",
       "2522  O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=NC(C(O)=O)...          1\n",
       "\n",
       "[2523 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = senolytics_df[['SMILES', 'senolytic']]\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "OCBDQUq_SA8_",
    "outputId": "cf6c27fe-b6d2-42c4-b299-6b0977b5b4a9"
   },
   "outputs": [],
   "source": [
    "# # Subset for testing new code\n",
    "\n",
    "#training_df =  training_df.groupby('senolytic', group_keys=False).apply(lambda x: x.sample(frac=0.1))\n",
    "#training_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mex0yzEfSnnc",
    "outputId": "c9c972e6-6ddd-4efe-ea79-82a2f72909ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022988505747126436"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check sample is representative of the actual distribution\n",
    "sum(training_df['senolytic'])/len(training_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCOQKbIPDLAt"
   },
   "source": [
    "## Finetune\n",
    "https://huggingface.co/docs/transformers/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtKRX78_524s",
    "outputId": "7888feb8-d87c-427f-9a83-43677acaa74c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3428210 parameters.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepChem/ChemBERTa-77M-MTR\")\n",
    "config = AutoConfig.from_pretrained(\"DeepChem/ChemBERTa-77M-MTR\")\n",
    "config.num_hidden_layers += 1\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"DeepChem/ChemBERTa-77M-MTR\", num_labels=2, problem_type = \"single_label_classification\")\n",
    "\n",
    "print(f\"Model size: {model.num_parameters()} parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0jU4hDaB9ZeP"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = training_df[['SMILES']]\n",
    "y = training_df['senolytic']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y) # the data should be shuffled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1tJA6uNe9FrY"
   },
   "outputs": [],
   "source": [
    "# Dataset set up\n",
    "\n",
    "#smiles_train = X_train['SMILES'].astype(str).tolist()\n",
    "#smiles_test = X_test['SMILES'].astype(str).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BiniuqzuA2KI"
   },
   "outputs": [],
   "source": [
    "# # https://huggingface.co/transformers/v3.2.0/custom_datasets.html -> does not work!!\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "\n",
    "\n",
    "# class SenolyticsDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, encodings, labels):\n",
    "#         self.encodings = encodings\n",
    "#         self.labels = labels\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         #print(idx)\n",
    "#         input_ids = torch.tensor(self.encodings['input_ids'])\n",
    "#         if self.labels is not None and idx in self.labels.keys():\n",
    "#             target_ids = torch.tensor(self.labels[idx])\n",
    "#         else:\n",
    "#             # Handle the case where self.labels is None or idx is out of range\n",
    "#             target_ids = None\n",
    "#         return {\"input_ids\": input_ids, \"labels\": target_ids}\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "# #train_dataset = IMDbDataset(train_encodings, train_labels)\n",
    "# #val_dataset = IMDbDataset(val_encodings, val_labels)\n",
    "# #test_dataset = IMDbDataset(test_encodings, test_labels)\n",
    "\n",
    "# tokenized_train = tokenizer(smiles_train, padding=True, truncation=True, max_length=None, return_tensors='pt')\n",
    "# tokenized_test = tokenizer(smiles_test, padding=True, truncation=True, max_length=None, return_tensors='pt')\n",
    "\n",
    "# train_dataset = SenolyticsDataset(tokenized_train, y_train)\n",
    "# test_dataset = SenolyticsDataset(tokenized_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Yh4grRWQjsLj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#Current version\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, labels, tokenizer):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        # Tokenize the SMILES strings and store them\n",
    "        self.encodings = self.tokenize_smiles(dataframe['SMILES'].tolist())\n",
    "\n",
    "        # Store the labels\n",
    "        self.labels = labels.tolist()\n",
    "\n",
    "    def tokenize_smiles(self, smiles_list):\n",
    "        return self.tokenizer(\n",
    "            smiles_list,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=None,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        }\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rTFXIMO6jycF"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train, y_train, tokenizer)\n",
    "test_dataset = Dataset(X_test, y_test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wHP3C4JUyB9g",
    "outputId": "b5b926e7-f64b-49ac-9409-210adf4f5c04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset[-1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3Uy-yE46GZk7"
   },
   "outputs": [],
   "source": [
    "def optuna_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32, 64, 128]),\n",
    "        \"weight_decay\": trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qj8lOM-WBXp5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# many more parameters to experiment with https://huggingface.co/docs/transformers/v4.33.2/en/main_classes/trainer#transformers.TrainingArguments\n",
    "training_args = TrainingArguments(output_dir=\"test_1\", load_best_model_at_end=True, evaluation_strategy='epoch',\n",
    "    logging_strategy=\"epoch\", save_strategy=\"epoch\",per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,optim=\"adamw_torch\", num_train_epochs=10) # switch optimizer to avoid warning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "1bee975014d1451b9ff65d5fe1900ff3",
      "7f77b287bc334e3dba59b9d4c3307e46",
      "091723f2ddaa43b98f16a4756fd02390",
      "5d939c494595405797930594beee593d",
      "74135322bba54fa3b6578825dbfac89f",
      "9781d331577d4612bcabe465634f52a2",
      "35f2824b2c644032a227f956719fe2a7",
      "8088374a3d6f4332b642708bbd768add",
      "d97c6f2aac474568949ac75dcae64a78",
      "58da272eecb64352a162858fdfdb9a10",
      "f5f0d29fc0ef4fcfb09f17906c822687"
     ]
    },
    "id": "-kEDerSWDgSQ",
    "outputId": "27dbcb00-5bda-487f-9804-33b7284e05a7"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "metric = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KWaaH8HzEqxl"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/67457480/how-to-get-the-accuracy-per-epoch-or-step-for-the-huggingface-transformers-train\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    metrics = [\"accuracy\", \"recall\", \"precision\", \"f1\"] #List of metrics to return\n",
    "    metric={}\n",
    "    for met in metrics:\n",
    "       metric[met] = evaluate.load(met)\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    metric_res={}\n",
    "    for met in metrics:\n",
    "       metric_res[met]=metric[met].compute(predictions=predictions, references=labels)[met]\n",
    "    return metric_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pd8k07IiLvnt",
    "outputId": "ee4e1598-d1dd-4d1c-dcb0-5c1de3765994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51188406 21.53658537]\n"
     ]
    }
   ],
   "source": [
    "# Class weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\",classes=np.unique(y_train),y=y_train)\n",
    "\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1Vgd0ucdLaeI"
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/main/main_classes/trainer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\").long()\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss with class_weights=balanced from above\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, device=model.device, dtype=torch.float))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aUdFmJL-iq4O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zEILHiN8ktsH",
    "outputId": "a7728741-ed0f-4cca-f9bf-34f59c99d12d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4FIGlc2GlkOl",
    "outputId": "0b529f3d-1e13-49fb-bbee-96e5f5e0c402"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3cvzbNImqWMH"
   },
   "outputs": [],
   "source": [
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7HzwkE3BlmMS"
   },
   "outputs": [],
   "source": [
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "tz7rWAHSmjfP",
    "outputId": "b78a7ac2-9311-4960-add0-d91437b788b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12/N=C(\\NC(c1nn[nH]2)=O)/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1C(NC(C1=O)NC(=O)N)=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1(S(=O)(=O)N)sc(nn1)NC(=O)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C(NC(=N)N)(=N)N(C)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[N+]1(C(c2c(cc(c(c2)OC)OC)CC1)Cc1cc(c(cc1)OC)O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>COC1=C(C=CC(=C1)/C=C/C(=O)CC(=O)/C=C/C2=CC(=C(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>CC1=C(C(=CC=C1)Cl)NC(=O)C2=CN=C(S2)NC3=CC(=NC(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>CC1(CCC(=C(C1)CN2CCN(CC2)C3=CC=C(C=C3)C(=O)NS(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=CC=C(C5=C(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=NC(C(O)=O)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2523 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0                           c12/N=C(\\NC(c1nn[nH]2)=O)/N\n",
       "1                                N1C(NC(C1=O)NC(=O)N)=O\n",
       "2                          c1(S(=O)(=O)N)sc(nn1)NC(=O)C\n",
       "3                                   C(NC(=N)N)(=N)N(C)C\n",
       "4     [N+]1(C(c2c(cc(c(c2)OC)OC)CC1)Cc1cc(c(cc1)OC)O...\n",
       "...                                                 ...\n",
       "2518  COC1=C(C=CC(=C1)/C=C/C(=O)CC(=O)/C=C/C2=CC(=C(...\n",
       "2519  CC1=C(C(=CC=C1)Cl)NC(=O)C2=CN=C(S2)NC3=CC(=NC(...\n",
       "2520  CC1(CCC(=C(C1)CN2CCN(CC2)C3=CC=C(C=C3)C(=O)NS(...\n",
       "2521  O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=CC=C(C5=C(...\n",
       "2522  O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=NC(C(O)=O)...\n",
       "\n",
       "[2523 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "cgCjsT4-KDXS",
    "outputId": "34685464-af17-486b-f7c8-b1b6fff548ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 13:28:23,696] A new study created in memory with name: hyper-parameter-search\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8468, 'learning_rate': 0.0006796748158941389, 'epoch': 1.98}\n",
      "{'loss': 0.7282, 'learning_rate': 0.00023544291008097628, 'epoch': 3.95}\n",
      "{'train_runtime': 19.6422, 'train_samples_per_second': 513.691, 'train_steps_per_second': 64.402, 'train_loss': 0.769074258314291, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1714782565832138, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.6728, 'eval_samples_per_second': 137.496, 'eval_steps_per_second': 17.425, 'epoch': 5.0}\n",
      "{'loss': 0.8099, 'learning_rate': 0.0006796748158941389, 'epoch': 1.98}\n",
      "{'loss': 0.7113, 'learning_rate': 0.00023544291008097628, 'epoch': 3.95}\n",
      "{'train_runtime': 23.9679, 'train_samples_per_second': 420.98, 'train_steps_per_second': 52.779, 'train_loss': 0.7342029677078187, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16774167120456696, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.8012, 'eval_samples_per_second': 132.852, 'eval_steps_per_second': 16.837, 'epoch': 5.0}\n",
      "{'loss': 0.8188, 'learning_rate': 0.0006796748158941389, 'epoch': 1.98}\n",
      "{'loss': 0.722, 'learning_rate': 0.00023544291008097628, 'epoch': 3.95}\n",
      "{'train_runtime': 22.0637, 'train_samples_per_second': 457.312, 'train_steps_per_second': 57.334, 'train_loss': 0.7551237928066329, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1726067215204239, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 4.016, 'eval_samples_per_second': 125.747, 'eval_steps_per_second': 15.936, 'epoch': 5.0}\n",
      "{'loss': 0.7846, 'learning_rate': 0.0006796748158941389, 'epoch': 1.98}\n",
      "{'loss': 0.766, 'learning_rate': 0.00023544291008097628, 'epoch': 3.95}\n",
      "{'train_runtime': 20.8086, 'train_samples_per_second': 485.136, 'train_steps_per_second': 60.792, 'train_loss': 0.7613969403293293, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16085176169872284, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.7385, 'eval_samples_per_second': 134.812, 'eval_steps_per_second': 16.851, 'epoch': 5.0}\n",
      "{'loss': 0.7734, 'learning_rate': 0.0006796748158941389, 'epoch': 1.98}\n",
      "{'loss': 0.7481, 'learning_rate': 0.00023544291008097628, 'epoch': 3.95}\n",
      "{'train_runtime': 24.6573, 'train_samples_per_second': 409.413, 'train_steps_per_second': 51.303, 'train_loss': 0.7418275252632472, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-09 13:30:56,210] Trial 0 finished with value: 0.0 and parameters: {'learning_rate': 0.0011239067217073018, 'weight_decay': 0.00010895279260432418, 'num_train_epochs': 5}. Best is trial 0 with value: 0.0.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1570032387971878, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.3276, 'eval_samples_per_second': 151.462, 'eval_steps_per_second': 18.933, 'epoch': 5.0}\n",
      "{'loss': 0.7599, 'learning_rate': 0.00042533396629276305, 'epoch': 1.98}\n",
      "{'loss': 0.6813, 'learning_rate': 9.968764834986634e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 18.9424, 'train_samples_per_second': 426.133, 'train_steps_per_second': 53.425, 'train_loss': 0.7165090745616808, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17606176435947418, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.7976, 'eval_samples_per_second': 132.98, 'eval_steps_per_second': 16.853, 'epoch': 4.0}\n",
      "{'loss': 0.7537, 'learning_rate': 0.00042533396629276305, 'epoch': 1.98}\n",
      "{'loss': 0.6837, 'learning_rate': 9.968764834986634e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 13.9097, 'train_samples_per_second': 580.316, 'train_steps_per_second': 72.755, 'train_loss': 0.7142877903851595, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17070737481117249, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 4.2151, 'eval_samples_per_second': 119.807, 'eval_steps_per_second': 15.183, 'epoch': 4.0}\n",
      "{'loss': 0.755, 'learning_rate': 0.00042533396629276305, 'epoch': 1.98}\n",
      "{'loss': 0.6754, 'learning_rate': 9.968764834986634e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 20.4821, 'train_samples_per_second': 394.1, 'train_steps_per_second': 49.409, 'train_loss': 0.7110565123350724, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16750973463058472, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.6955, 'eval_samples_per_second': 136.652, 'eval_steps_per_second': 17.318, 'epoch': 4.0}\n",
      "{'loss': 0.6817, 'learning_rate': 0.00042533396629276305, 'epoch': 1.98}\n",
      "{'loss': 0.6409, 'learning_rate': 9.968764834986634e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 18.3938, 'train_samples_per_second': 439.06, 'train_steps_per_second': 55.018, 'train_loss': 0.6629796103526481, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14235882461071014, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.7271, 'eval_samples_per_second': 135.225, 'eval_steps_per_second': 16.903, 'epoch': 4.0}\n",
      "{'loss': 0.6143, 'learning_rate': 0.00042533396629276305, 'epoch': 1.98}\n",
      "{'loss': 0.5865, 'learning_rate': 9.968764834986634e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 13.8243, 'train_samples_per_second': 584.19, 'train_steps_per_second': 73.205, 'train_loss': 0.6002428032192788, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-09 13:33:01,477] Trial 1 finished with value: 0.0 and parameters: {'learning_rate': 0.0008406991677505396, 'weight_decay': 6.211302157539118e-05, 'num_train_epochs': 4}. Best is trial 0 with value: 0.0.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16640886664390564, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.3324, 'eval_samples_per_second': 151.24, 'eval_steps_per_second': 18.905, 'epoch': 4.0}\n",
      "{'loss': 1.7201, 'learning_rate': 0.004977183341380332, 'epoch': 1.98}\n",
      "{'loss': 1.0517, 'learning_rate': 0.00011665273456360152, 'epoch': 3.95}\n",
      "{'train_runtime': 18.3422, 'train_samples_per_second': 440.078, 'train_steps_per_second': 55.173, 'train_loss': 1.3738797460148928, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20205111801624298, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.7073, 'eval_samples_per_second': 136.218, 'eval_steps_per_second': 17.263, 'epoch': 4.0}\n",
      "{'loss': 1.4075, 'learning_rate': 0.004977183341380332, 'epoch': 1.98}\n",
      "{'loss': 1.0013, 'learning_rate': 0.00011665273456360152, 'epoch': 3.95}\n",
      "{'train_runtime': 20.2421, 'train_samples_per_second': 398.772, 'train_steps_per_second': 49.995, 'train_loss': 1.1948053610654688, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21323513984680176, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 4.0348, 'eval_samples_per_second': 125.161, 'eval_steps_per_second': 15.862, 'epoch': 4.0}\n",
      "{'loss': 1.3191, 'learning_rate': 0.004977183341380332, 'epoch': 1.98}\n",
      "{'loss': 1.0226, 'learning_rate': 0.00011665273456360152, 'epoch': 3.95}\n",
      "{'train_runtime': 20.5508, 'train_samples_per_second': 392.783, 'train_steps_per_second': 49.244, 'train_loss': 1.1617943241662188, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22868575155735016, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.9448, 'eval_samples_per_second': 128.015, 'eval_steps_per_second': 16.224, 'epoch': 4.0}\n",
      "{'loss': 1.7214, 'learning_rate': 0.004977183341380332, 'epoch': 1.98}\n",
      "{'loss': 1.0061, 'learning_rate': 0.00011665273456360152, 'epoch': 3.95}\n",
      "{'train_runtime': 16.9882, 'train_samples_per_second': 475.389, 'train_steps_per_second': 59.571, 'train_loss': 1.3563945500747017, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16840432584285736, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.9006, 'eval_samples_per_second': 129.212, 'eval_steps_per_second': 16.151, 'epoch': 4.0}\n",
      "{'loss': 1.5788, 'learning_rate': 0.004977183341380332, 'epoch': 1.98}\n",
      "{'loss': 1.0133, 'learning_rate': 0.00011665273456360152, 'epoch': 3.95}\n",
      "{'train_runtime': 15.4945, 'train_samples_per_second': 521.216, 'train_steps_per_second': 65.313, 'train_loss': 1.2894292857807144, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-09 13:35:13,790] Trial 2 finished with value: 0.0 and parameters: {'learning_rate': 0.009837713948197062, 'weight_decay': 0.004338118853316637, 'num_train_epochs': 4}. Best is trial 0 with value: 0.0.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1652437448501587, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.7144, 'eval_samples_per_second': 135.69, 'eval_steps_per_second': 16.961, 'epoch': 4.0}\n",
      "{'loss': 0.7477, 'learning_rate': 0.0004998555500147949, 'epoch': 1.98}\n",
      "{'loss': 0.5281, 'learning_rate': 0.0003032168600011069, 'epoch': 3.95}\n",
      "{'loss': 0.3859, 'learning_rate': 0.0001065781699874189, 'epoch': 5.93}\n",
      "{'train_runtime': 30.2017, 'train_samples_per_second': 467.721, 'train_steps_per_second': 58.639, 'train_loss': 0.5140614092249038, 'epoch': 7.0}\n",
      "{'eval_loss': 0.17168667912483215, 'eval_accuracy': 0.9782178217821782, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5384615384615384, 'eval_f1': 0.5599999999999999, 'eval_runtime': 3.922, 'eval_samples_per_second': 128.76, 'eval_steps_per_second': 16.318, 'epoch': 7.0}\n",
      "{'loss': 0.5427, 'learning_rate': 0.0004998555500147949, 'epoch': 1.98}\n",
      "{'loss': 0.4223, 'learning_rate': 0.0003032168600011069, 'epoch': 3.95}\n",
      "{'loss': 0.2617, 'learning_rate': 0.0001065781699874189, 'epoch': 5.93}\n",
      "{'train_runtime': 35.1749, 'train_samples_per_second': 401.593, 'train_steps_per_second': 50.348, 'train_loss': 0.3911752296934553, 'epoch': 7.0}\n",
      "{'eval_loss': 0.12292348593473434, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.6215, 'eval_samples_per_second': 139.444, 'eval_steps_per_second': 17.672, 'epoch': 7.0}\n",
      "{'loss': 0.5515, 'learning_rate': 0.0004998555500147949, 'epoch': 1.98}\n",
      "{'loss': 0.4277, 'learning_rate': 0.0003032168600011069, 'epoch': 3.95}\n",
      "{'loss': 0.2805, 'learning_rate': 0.0001065781699874189, 'epoch': 5.93}\n",
      "{'train_runtime': 31.3587, 'train_samples_per_second': 450.465, 'train_steps_per_second': 56.476, 'train_loss': 0.3994525799570886, 'epoch': 7.0}\n",
      "{'eval_loss': 0.09374646842479706, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.6666666666666666, 'eval_precision': 0.8888888888888888, 'eval_f1': 0.761904761904762, 'eval_runtime': 4.2229, 'eval_samples_per_second': 119.587, 'eval_steps_per_second': 15.156, 'epoch': 7.0}\n",
      "{'loss': 0.4707, 'learning_rate': 0.0004998555500147949, 'epoch': 1.98}\n",
      "{'loss': 0.416, 'learning_rate': 0.0003032168600011069, 'epoch': 3.95}\n",
      "{'loss': 0.2946, 'learning_rate': 0.0001065781699874189, 'epoch': 5.93}\n",
      "{'train_runtime': 25.8892, 'train_samples_per_second': 545.903, 'train_steps_per_second': 68.407, 'train_loss': 0.3762272469139853, 'epoch': 7.0}\n",
      "{'eval_loss': 0.06754235923290253, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.8181818181818182, 'eval_precision': 1.0, 'eval_f1': 0.9, 'eval_runtime': 4.0457, 'eval_samples_per_second': 124.575, 'eval_steps_per_second': 15.572, 'epoch': 7.0}\n",
      "{'loss': 0.3791, 'learning_rate': 0.0004998555500147949, 'epoch': 1.98}\n",
      "{'loss': 0.3563, 'learning_rate': 0.0003032168600011069, 'epoch': 3.95}\n",
      "{'loss': 0.2648, 'learning_rate': 0.0001065781699874189, 'epoch': 5.93}\n",
      "{'train_runtime': 28.9316, 'train_samples_per_second': 488.496, 'train_steps_per_second': 61.213, 'train_loss': 0.32114808886553325, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 13:38:26,516] Trial 3 finished with value: 0.6686946778711484 and parameters: {'learning_rate': 0.0006964942400284829, 'weight_decay': 0.00011317227506005459, 'num_train_epochs': 7}. Best is trial 3 with value: 0.6686946778711484.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12149006128311157, 'eval_accuracy': 0.9861111111111112, 'eval_recall': 0.36363636363636365, 'eval_precision': 1.0, 'eval_f1': 0.5333333333333333, 'eval_runtime': 3.839, 'eval_samples_per_second': 131.283, 'eval_steps_per_second': 16.41, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6617, 'learning_rate': 9.971228557013705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.4227, 'learning_rate': 6.04863667777936e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2901, 'learning_rate': 2.1260447985450148e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 31.1641, 'train_samples_per_second': 453.278, 'train_steps_per_second': 56.828, 'train_loss': 0.42072809651233195, 'epoch': 7.0}\n",
      "{'eval_loss': 0.17521801590919495, 'eval_accuracy': 0.9722772277227723, 'eval_recall': 0.4166666666666667, 'eval_precision': 0.4166666666666667, 'eval_f1': 0.4166666666666667, 'eval_runtime': 3.9566, 'eval_samples_per_second': 127.635, 'eval_steps_per_second': 16.175, 'epoch': 7.0}\n",
      "{'loss': 0.3169, 'learning_rate': 9.971228557013705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1635, 'learning_rate': 6.04863667777936e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0948, 'learning_rate': 2.1260447985450148e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 35.1009, 'train_samples_per_second': 402.44, 'train_steps_per_second': 50.455, 'train_loss': 0.17319878395636293, 'epoch': 7.0}\n",
      "{'eval_loss': 0.1466241031885147, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.8613, 'eval_samples_per_second': 130.784, 'eval_steps_per_second': 16.575, 'epoch': 7.0}\n",
      "{'loss': 0.189, 'learning_rate': 9.971228557013705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0899, 'learning_rate': 6.04863667777936e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0269, 'learning_rate': 2.1260447985450148e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 35.4565, 'train_samples_per_second': 398.404, 'train_steps_per_second': 49.949, 'train_loss': 0.08696553028619336, 'epoch': 7.0}\n",
      "{'eval_loss': 0.008585195057094097, 'eval_accuracy': 0.998019801980198, 'eval_recall': 1.0, 'eval_precision': 0.9230769230769231, 'eval_f1': 0.9600000000000001, 'eval_runtime': 3.5092, 'eval_samples_per_second': 143.907, 'eval_steps_per_second': 18.238, 'epoch': 7.0}\n",
      "{'loss': 0.1426, 'learning_rate': 9.971228557013705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0265, 'learning_rate': 6.04863667777936e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0008, 'learning_rate': 2.1260447985450148e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 27.3473, 'train_samples_per_second': 516.797, 'train_steps_per_second': 64.76, 'train_loss': 0.04847367867650722, 'epoch': 7.0}\n",
      "{'eval_loss': 0.01520561520010233, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.0117, 'eval_samples_per_second': 125.631, 'eval_steps_per_second': 15.704, 'epoch': 7.0}\n",
      "{'loss': 0.0623, 'learning_rate': 9.971228557013705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0061, 'learning_rate': 6.04863667777936e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0, 'learning_rate': 2.1260447985450148e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 29.8389, 'train_samples_per_second': 473.643, 'train_steps_per_second': 59.352, 'train_loss': 0.019308210958910495, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 13:41:45,514] Trial 4 finished with value: 0.7904472049689442 and parameters: {'learning_rate': 0.0001389382043624805, 'weight_decay': 0.0005920457471593741, 'num_train_epochs': 7}. Best is trial 4 with value: 0.7904472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015922710299491882, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.588, 'eval_samples_per_second': 140.469, 'eval_steps_per_second': 17.559, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9673, 'learning_rate': 0.0021292159138506608, 'epoch': 1.98}\n",
      "{'loss': 0.8487, 'learning_rate': 0.0016047784966460644, 'epoch': 3.95}\n",
      "{'loss': 0.8085, 'learning_rate': 0.0010803410794414682, 'epoch': 5.93}\n",
      "{'loss': 0.7649, 'learning_rate': 0.0005559036622368721, 'epoch': 7.91}\n",
      "{'loss': 0.7568, 'learning_rate': 3.1466245032275774e-05, 'epoch': 9.88}\n",
      "{'train_runtime': 44.1363, 'train_samples_per_second': 457.22, 'train_steps_per_second': 57.322, 'train_loss': 0.834870159767362, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18168622255325317, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.7886, 'eval_samples_per_second': 133.295, 'eval_steps_per_second': 16.893, 'epoch': 10.0}\n",
      "{'loss': 0.9117, 'learning_rate': 0.0021292159138506608, 'epoch': 1.98}\n",
      "{'loss': 0.8216, 'learning_rate': 0.0016047784966460644, 'epoch': 3.95}\n",
      "{'loss': 0.7949, 'learning_rate': 0.0010803410794414682, 'epoch': 5.93}\n",
      "{'loss': 0.7709, 'learning_rate': 0.0005559036622368721, 'epoch': 7.91}\n",
      "{'loss': 0.7777, 'learning_rate': 3.1466245032275774e-05, 'epoch': 9.88}\n",
      "{'train_runtime': 43.5587, 'train_samples_per_second': 463.283, 'train_steps_per_second': 58.082, 'train_loss': 0.8214957648115195, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18500664830207825, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.1006, 'eval_samples_per_second': 162.871, 'eval_steps_per_second': 20.641, 'epoch': 10.0}\n",
      "{'loss': 0.9087, 'learning_rate': 0.0021292159138506608, 'epoch': 1.98}\n",
      "{'loss': 0.8208, 'learning_rate': 0.0016047784966460644, 'epoch': 3.95}\n",
      "{'loss': 0.7826, 'learning_rate': 0.0010803410794414682, 'epoch': 5.93}\n",
      "{'loss': 0.7769, 'learning_rate': 0.0005559036622368721, 'epoch': 7.91}\n",
      "{'loss': 0.7836, 'learning_rate': 3.1466245032275774e-05, 'epoch': 9.88}\n",
      "{'train_runtime': 46.75, 'train_samples_per_second': 431.657, 'train_steps_per_second': 54.118, 'train_loss': 0.8206471454484661, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18742457032203674, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.8061, 'eval_samples_per_second': 132.68, 'eval_steps_per_second': 16.815, 'epoch': 10.0}\n",
      "{'loss': 0.9256, 'learning_rate': 0.0021292159138506608, 'epoch': 1.98}\n",
      "{'loss': 0.8554, 'learning_rate': 0.0016047784966460644, 'epoch': 3.95}\n",
      "{'loss': 0.8433, 'learning_rate': 0.0010803410794414682, 'epoch': 5.93}\n",
      "{'loss': 0.8388, 'learning_rate': 0.0005559036622368721, 'epoch': 7.91}\n",
      "{'loss': 0.7874, 'learning_rate': 3.1466245032275774e-05, 'epoch': 9.88}\n",
      "{'train_runtime': 41.7312, 'train_samples_per_second': 483.811, 'train_steps_per_second': 60.626, 'train_loss': 0.8517875912632396, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16402067244052887, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 4.0175, 'eval_samples_per_second': 125.45, 'eval_steps_per_second': 15.681, 'epoch': 10.0}\n",
      "{'loss': 0.9148, 'learning_rate': 0.0021292159138506608, 'epoch': 1.98}\n",
      "{'loss': 0.8532, 'learning_rate': 0.0016047784966460644, 'epoch': 3.95}\n",
      "{'loss': 0.8446, 'learning_rate': 0.0010803410794414682, 'epoch': 5.93}\n",
      "{'loss': 0.8152, 'learning_rate': 0.0005559036622368721, 'epoch': 7.91}\n",
      "{'loss': 0.7898, 'learning_rate': 3.1466245032275774e-05, 'epoch': 9.88}\n",
      "{'train_runtime': 45.5827, 'train_samples_per_second': 442.931, 'train_steps_per_second': 55.504, 'train_loss': 0.8468288466864424, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-09 13:46:06,159] Trial 5 finished with value: 0.0 and parameters: {'learning_rate': 0.002653653331055257, 'weight_decay': 0.00011103349355139717, 'num_train_epochs': 10}. Best is trial 4 with value: 0.7904472049689442.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16372345387935638, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.5469, 'eval_samples_per_second': 142.096, 'eval_steps_per_second': 17.762, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9831, 'learning_rate': 0.0018072492456530412, 'epoch': 1.98}\n",
      "{'loss': 0.7713, 'learning_rate': 4.235740419499316e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 15.129, 'train_samples_per_second': 533.544, 'train_steps_per_second': 66.891, 'train_loss': 0.8714065118269487, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19555993378162384, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.5076, 'eval_samples_per_second': 143.975, 'eval_steps_per_second': 18.246, 'epoch': 4.0}\n",
      "{'loss': 1.0579, 'learning_rate': 0.0018072492456530412, 'epoch': 1.98}\n",
      "{'loss': 0.7964, 'learning_rate': 4.235740419499316e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 18.7239, 'train_samples_per_second': 431.107, 'train_steps_per_second': 54.049, 'train_loss': 0.9213712488709702, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19575633108615875, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 4.2338, 'eval_samples_per_second': 119.277, 'eval_steps_per_second': 15.116, 'epoch': 4.0}\n",
      "{'loss': 0.9797, 'learning_rate': 0.0018072492456530412, 'epoch': 1.98}\n",
      "{'loss': 0.7727, 'learning_rate': 4.235740419499316e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 16.0218, 'train_samples_per_second': 503.814, 'train_steps_per_second': 63.164, 'train_loss': 0.8705772684496853, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19574424624443054, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 4.6168, 'eval_samples_per_second': 109.383, 'eval_steps_per_second': 13.862, 'epoch': 4.0}\n",
      "{'loss': 0.9625, 'learning_rate': 0.0018072492456530412, 'epoch': 1.98}\n",
      "{'loss': 0.8, 'learning_rate': 4.235740419499316e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 19.8625, 'train_samples_per_second': 406.596, 'train_steps_per_second': 50.95, 'train_loss': 0.8787929484024349, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15323176980018616, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.6564, 'eval_samples_per_second': 137.841, 'eval_steps_per_second': 17.23, 'epoch': 4.0}\n",
      "{'loss': 0.9382, 'learning_rate': 0.0018072492456530412, 'epoch': 1.98}\n",
      "{'loss': 0.8069, 'learning_rate': 4.235740419499316e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 18.4323, 'train_samples_per_second': 438.144, 'train_steps_per_second': 54.904, 'train_loss': 0.870221519658688, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-09 13:48:15,723] Trial 6 finished with value: 0.0 and parameters: {'learning_rate': 0.0035721410871110896, 'weight_decay': 5.262022790373369e-05, 'num_train_epochs': 4}. Best is trial 4 with value: 0.7904472049689442.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15443342924118042, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.5436, 'eval_samples_per_second': 142.229, 'eval_steps_per_second': 17.779, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6944, 'learning_rate': 4.121185240284236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.5251, 'learning_rate': 2.9615945705362792e-05, 'epoch': 3.95}\n",
      "{'loss': 0.473, 'learning_rate': 1.8020039007883234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.4332, 'learning_rate': 6.424132310403675e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 39.5066, 'train_samples_per_second': 459.721, 'train_steps_per_second': 57.636, 'train_loss': 0.5165906092761429, 'epoch': 9.0}\n",
      "{'eval_loss': 0.15878678858280182, 'eval_accuracy': 0.9742574257425742, 'eval_recall': 0.25, 'eval_precision': 0.42857142857142855, 'eval_f1': 0.3157894736842105, 'eval_runtime': 3.7743, 'eval_samples_per_second': 133.801, 'eval_steps_per_second': 16.957, 'epoch': 9.0}\n",
      "{'loss': 0.4129, 'learning_rate': 4.121185240284236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.2828, 'learning_rate': 2.9615945705362792e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2175, 'learning_rate': 1.8020039007883234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.2143, 'learning_rate': 6.424132310403675e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 39.8733, 'train_samples_per_second': 455.493, 'train_steps_per_second': 57.106, 'train_loss': 0.2684677636670501, 'epoch': 9.0}\n",
      "{'eval_loss': 0.18856164813041687, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.9402, 'eval_samples_per_second': 128.165, 'eval_steps_per_second': 16.243, 'epoch': 9.0}\n",
      "{'loss': 0.289, 'learning_rate': 4.121185240284236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1883, 'learning_rate': 2.9615945705362792e-05, 'epoch': 3.95}\n",
      "{'loss': 0.1408, 'learning_rate': 1.8020039007883234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1161, 'learning_rate': 6.424132310403675e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 38.9084, 'train_samples_per_second': 466.788, 'train_steps_per_second': 58.522, 'train_loss': 0.17764395478005257, 'epoch': 9.0}\n",
      "{'eval_loss': 0.05951077118515968, 'eval_accuracy': 0.9920792079207921, 'eval_recall': 0.6666666666666666, 'eval_precision': 1.0, 'eval_f1': 0.8, 'eval_runtime': 4.1632, 'eval_samples_per_second': 121.302, 'eval_steps_per_second': 15.373, 'epoch': 9.0}\n",
      "{'loss': 0.1662, 'learning_rate': 4.121185240284236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.118, 'learning_rate': 2.9615945705362792e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0571, 'learning_rate': 1.8020039007883234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0367, 'learning_rate': 6.424132310403675e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 37.039, 'train_samples_per_second': 490.591, 'train_steps_per_second': 61.476, 'train_loss': 0.08715530650156027, 'epoch': 9.0}\n",
      "{'eval_loss': 0.05519088730216026, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 4.1064, 'eval_samples_per_second': 122.736, 'eval_steps_per_second': 15.342, 'epoch': 9.0}\n",
      "{'loss': 0.1081, 'learning_rate': 4.121185240284236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0515, 'learning_rate': 2.9615945705362792e-05, 'epoch': 3.95}\n",
      "{'loss': 0.014, 'learning_rate': 1.8020039007883234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0006, 'learning_rate': 6.424132310403675e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 39.4027, 'train_samples_per_second': 461.161, 'train_steps_per_second': 57.788, 'train_loss': 0.03874691065644611, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 13:52:10,987] Trial 7 finished with value: 0.7027097154651335 and parameters: {'learning_rate': 5.280775910032191e-05, 'weight_decay': 0.001724352569900053, 'num_train_epochs': 9}. Best is trial 4 with value: 0.7904472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03245764598250389, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.5136, 'eval_samples_per_second': 143.442, 'eval_steps_per_second': 17.93, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6479, 'learning_rate': 0.00015408527752748243, 'epoch': 1.98}\n",
      "{'loss': 0.3836, 'learning_rate': 0.00010353236495284907, 'epoch': 3.95}\n",
      "{'loss': 0.2173, 'learning_rate': 5.297945237821574e-05, 'epoch': 5.93}\n",
      "{'loss': 0.161, 'learning_rate': 2.4265398035824e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.5114, 'train_samples_per_second': 481.747, 'train_steps_per_second': 60.397, 'train_loss': 0.3483138712741464, 'epoch': 8.0}\n",
      "{'eval_loss': 0.20036013424396515, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5, 'eval_precision': 0.6, 'eval_f1': 0.5454545454545454, 'eval_runtime': 3.1449, 'eval_samples_per_second': 160.578, 'eval_steps_per_second': 20.35, 'epoch': 8.0}\n",
      "{'loss': 0.2786, 'learning_rate': 0.00015408527752748243, 'epoch': 1.98}\n",
      "{'loss': 0.0811, 'learning_rate': 0.00010353236495284907, 'epoch': 3.95}\n",
      "{'loss': 0.05, 'learning_rate': 5.297945237821574e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0212, 'learning_rate': 2.4265398035824e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.3857, 'train_samples_per_second': 469.497, 'train_steps_per_second': 58.862, 'train_loss': 0.10644657118936168, 'epoch': 8.0}\n",
      "{'eval_loss': 0.1974656730890274, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.6837, 'eval_samples_per_second': 137.091, 'eval_steps_per_second': 17.374, 'epoch': 8.0}\n",
      "{'loss': 0.1825, 'learning_rate': 0.00015408527752748243, 'epoch': 1.98}\n",
      "{'loss': 0.048, 'learning_rate': 0.00010353236495284907, 'epoch': 3.95}\n",
      "{'loss': 0.0158, 'learning_rate': 5.297945237821574e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0031, 'learning_rate': 2.4265398035824e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.5517, 'train_samples_per_second': 467.242, 'train_steps_per_second': 58.579, 'train_loss': 0.061597684729881606, 'epoch': 8.0}\n",
      "{'eval_loss': 0.002429034560918808, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 3.351, 'eval_samples_per_second': 150.703, 'eval_steps_per_second': 19.099, 'epoch': 8.0}\n",
      "{'loss': 0.0925, 'learning_rate': 0.00015408527752748243, 'epoch': 1.98}\n",
      "{'loss': 0.0299, 'learning_rate': 0.00010353236495284907, 'epoch': 3.95}\n",
      "{'loss': 0.0013, 'learning_rate': 5.297945237821574e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.4265398035824e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 31.2681, 'train_samples_per_second': 516.564, 'train_steps_per_second': 64.73, 'train_loss': 0.030559926511522652, 'epoch': 8.0}\n",
      "{'eval_loss': 0.006014170590788126, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.0466, 'eval_samples_per_second': 124.551, 'eval_steps_per_second': 15.569, 'epoch': 8.0}\n",
      "{'loss': 0.058, 'learning_rate': 0.00015408527752748243, 'epoch': 1.98}\n",
      "{'loss': 0.0462, 'learning_rate': 0.00010353236495284907, 'epoch': 3.95}\n",
      "{'loss': 0.0002, 'learning_rate': 5.297945237821574e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0053, 'learning_rate': 2.4265398035824e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.4995, 'train_samples_per_second': 468.181, 'train_steps_per_second': 58.668, 'train_loss': 0.027092721922103505, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 13:55:38,183] Trial 8 finished with value: 0.7998604975587073 and parameters: {'learning_rate': 0.00020463819010211576, 'weight_decay': 0.004502646111135673, 'num_train_epochs': 8}. Best is trial 8 with value: 0.7998604975587073.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.024608569219708443, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.9906, 'eval_samples_per_second': 126.296, 'eval_steps_per_second': 15.787, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6533, 'learning_rate': 0.00016839508637919742, 'epoch': 1.98}\n",
      "{'loss': 0.3203, 'learning_rate': 3.9467598370124395e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 20.2087, 'train_samples_per_second': 399.433, 'train_steps_per_second': 50.078, 'train_loss': 0.4810036306118541, 'epoch': 4.0}\n",
      "{'eval_loss': 0.1345600038766861, 'eval_accuracy': 0.9742574257425742, 'eval_recall': 0.4166666666666667, 'eval_precision': 0.45454545454545453, 'eval_f1': 0.43478260869565216, 'eval_runtime': 3.6309, 'eval_samples_per_second': 139.085, 'eval_steps_per_second': 17.627, 'epoch': 4.0}\n",
      "{'loss': 0.3793, 'learning_rate': 0.00016839508637919742, 'epoch': 1.98}\n",
      "{'loss': 0.1328, 'learning_rate': 3.9467598370124395e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 20.0538, 'train_samples_per_second': 402.516, 'train_steps_per_second': 50.464, 'train_loss': 0.253023150408265, 'epoch': 4.0}\n",
      "{'eval_loss': 0.1393509954214096, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.9085, 'eval_samples_per_second': 129.204, 'eval_steps_per_second': 16.374, 'epoch': 4.0}\n",
      "{'loss': 0.2749, 'learning_rate': 0.00016839508637919742, 'epoch': 1.98}\n",
      "{'loss': 0.0828, 'learning_rate': 3.9467598370124395e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 15.535, 'train_samples_per_second': 519.602, 'train_steps_per_second': 65.143, 'train_loss': 0.17677056999589968, 'epoch': 4.0}\n",
      "{'eval_loss': 0.044678427278995514, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.8333333333333334, 'eval_precision': 1.0, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.8471, 'eval_samples_per_second': 131.269, 'eval_steps_per_second': 16.636, 'epoch': 4.0}\n",
      "{'loss': 0.1858, 'learning_rate': 0.00016839508637919742, 'epoch': 1.98}\n",
      "{'loss': 0.0343, 'learning_rate': 3.9467598370124395e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 19.1432, 'train_samples_per_second': 421.874, 'train_steps_per_second': 52.865, 'train_loss': 0.10878008023825135, 'epoch': 4.0}\n",
      "{'eval_loss': 0.05372210964560509, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.9401, 'eval_samples_per_second': 127.915, 'eval_steps_per_second': 15.989, 'epoch': 4.0}\n",
      "{'loss': 0.1558, 'learning_rate': 0.00016839508637919742, 'epoch': 1.98}\n",
      "{'loss': 0.0068, 'learning_rate': 3.9467598370124395e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 14.6882, 'train_samples_per_second': 549.828, 'train_steps_per_second': 68.899, 'train_loss': 0.08030496678235038, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 13:57:45,965] Trial 9 finished with value: 0.7578392621870883 and parameters: {'learning_rate': 0.0003328434129213824, 'weight_decay': 0.0007399547168076419, 'num_train_epochs': 4}. Best is trial 8 with value: 0.7998604975587073.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.046343956142663956, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.8333333333333334, 'eval_f1': 0.8695652173913043, 'eval_runtime': 3.417, 'eval_samples_per_second': 147.497, 'eval_steps_per_second': 18.437, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6297, 'learning_rate': 0.00015341386326090496, 'epoch': 1.98}\n",
      "{'loss': 0.3702, 'learning_rate': 0.00010308123095745845, 'epoch': 3.95}\n",
      "{'loss': 0.2106, 'learning_rate': 5.2748598654011946e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1288, 'learning_rate': 2.415966350565432e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.5827, 'train_samples_per_second': 480.724, 'train_steps_per_second': 60.269, 'train_loss': 0.33089697020489117, 'epoch': 8.0}\n",
      "{'eval_loss': 0.17716334760189056, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.7777777777777778, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.4811, 'eval_samples_per_second': 145.07, 'eval_steps_per_second': 18.385, 'epoch': 8.0}\n",
      "{'loss': 0.2637, 'learning_rate': 0.00015341386326090496, 'epoch': 1.98}\n",
      "{'loss': 0.1078, 'learning_rate': 0.00010308123095745845, 'epoch': 3.95}\n",
      "{'loss': 0.044, 'learning_rate': 5.2748598654011946e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0122, 'learning_rate': 2.415966350565432e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.8022, 'train_samples_per_second': 450.922, 'train_steps_per_second': 56.533, 'train_loss': 0.10568381913048064, 'epoch': 8.0}\n",
      "{'eval_loss': 0.21333934366703033, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.94, 'eval_samples_per_second': 128.172, 'eval_steps_per_second': 16.244, 'epoch': 8.0}\n",
      "{'loss': 0.1677, 'learning_rate': 0.00015341386326090496, 'epoch': 1.98}\n",
      "{'loss': 0.0504, 'learning_rate': 0.00010308123095745845, 'epoch': 3.95}\n",
      "{'loss': 0.0073, 'learning_rate': 5.2748598654011946e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0004, 'learning_rate': 2.415966350565432e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 37.3111, 'train_samples_per_second': 432.686, 'train_steps_per_second': 54.247, 'train_loss': 0.057013431932085114, 'epoch': 8.0}\n",
      "{'eval_loss': 0.01917157508432865, 'eval_accuracy': 0.998019801980198, 'eval_recall': 1.0, 'eval_precision': 0.9230769230769231, 'eval_f1': 0.9600000000000001, 'eval_runtime': 3.9753, 'eval_samples_per_second': 127.035, 'eval_steps_per_second': 16.1, 'epoch': 8.0}\n",
      "{'loss': 0.0896, 'learning_rate': 0.00015341386326090496, 'epoch': 1.98}\n",
      "{'loss': 0.0222, 'learning_rate': 0.00010308123095745845, 'epoch': 3.95}\n",
      "{'loss': 0.0001, 'learning_rate': 5.2748598654011946e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0337, 'learning_rate': 2.415966350565432e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.6303, 'train_samples_per_second': 466.413, 'train_steps_per_second': 58.446, 'train_loss': 0.03596421795105501, 'epoch': 8.0}\n",
      "{'eval_loss': 0.010405230335891247, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.8312, 'eval_samples_per_second': 131.552, 'eval_steps_per_second': 16.444, 'epoch': 8.0}\n",
      "{'loss': 0.0707, 'learning_rate': 0.00015341386326090496, 'epoch': 1.98}\n",
      "{'loss': 0.0533, 'learning_rate': 0.00010308123095745845, 'epoch': 3.95}\n",
      "{'loss': 0.0119, 'learning_rate': 5.2748598654011946e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0001, 'learning_rate': 2.415966350565432e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 36.9635, 'train_samples_per_second': 436.971, 'train_steps_per_second': 54.757, 'train_loss': 0.033611059487635146, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:01:21,739] Trial 10 finished with value: 0.8404472049689442 and parameters: {'learning_rate': 0.00020374649556435147, 'weight_decay': 0.009203660948980062, 'num_train_epochs': 8}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01284811645746231, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.106, 'eval_samples_per_second': 162.267, 'eval_steps_per_second': 20.283, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6526, 'learning_rate': 0.00015723757010401913, 'epoch': 1.98}\n",
      "{'loss': 0.3812, 'learning_rate': 0.00010565044080480025, 'epoch': 3.95}\n",
      "{'loss': 0.223, 'learning_rate': 5.406331150558138e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1568, 'learning_rate': 2.4761822063625057e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.6974, 'train_samples_per_second': 452.246, 'train_steps_per_second': 56.699, 'train_loss': 0.34940997891039716, 'epoch': 8.0}\n",
      "{'eval_loss': 0.19442370533943176, 'eval_accuracy': 0.9841584158415841, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.7, 'eval_f1': 0.6363636363636365, 'eval_runtime': 3.4589, 'eval_samples_per_second': 145.999, 'eval_steps_per_second': 18.503, 'epoch': 8.0}\n",
      "{'loss': 0.2808, 'learning_rate': 0.00015723757010401913, 'epoch': 1.98}\n",
      "{'loss': 0.0774, 'learning_rate': 0.00010565044080480025, 'epoch': 3.95}\n",
      "{'loss': 0.0425, 'learning_rate': 5.406331150558138e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0049, 'learning_rate': 2.4761822063625057e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 37.7724, 'train_samples_per_second': 427.403, 'train_steps_per_second': 53.584, 'train_loss': 0.10017371397413012, 'epoch': 8.0}\n",
      "{'eval_loss': 0.13901343941688538, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.4578, 'eval_samples_per_second': 146.046, 'eval_steps_per_second': 18.509, 'epoch': 8.0}\n",
      "{'loss': 0.1772, 'learning_rate': 0.00015723757010401913, 'epoch': 1.98}\n",
      "{'loss': 0.0429, 'learning_rate': 0.00010565044080480025, 'epoch': 3.95}\n",
      "{'loss': 0.0215, 'learning_rate': 5.406331150558138e-05, 'epoch': 5.93}\n",
      "{'loss': 0.003, 'learning_rate': 2.4761822063625057e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 40.2318, 'train_samples_per_second': 401.274, 'train_steps_per_second': 50.308, 'train_loss': 0.0610192481119171, 'epoch': 8.0}\n",
      "{'eval_loss': 0.015950394794344902, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.9166666666666666, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9166666666666666, 'eval_runtime': 3.9037, 'eval_samples_per_second': 129.366, 'eval_steps_per_second': 16.395, 'epoch': 8.0}\n",
      "{'loss': 0.1221, 'learning_rate': 0.00015723757010401913, 'epoch': 1.98}\n",
      "{'loss': 0.0281, 'learning_rate': 0.00010565044080480025, 'epoch': 3.95}\n",
      "{'loss': 0.0004, 'learning_rate': 5.406331150558138e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0001, 'learning_rate': 2.4761822063625057e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 38.2878, 'train_samples_per_second': 421.857, 'train_steps_per_second': 52.863, 'train_loss': 0.03721450434891213, 'epoch': 8.0}\n",
      "{'eval_loss': 0.014855530112981796, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.6177, 'eval_samples_per_second': 139.317, 'eval_steps_per_second': 17.415, 'epoch': 8.0}\n",
      "{'loss': 0.0623, 'learning_rate': 0.00015723757010401913, 'epoch': 1.98}\n",
      "{'loss': 0.0286, 'learning_rate': 0.00010565044080480025, 'epoch': 3.95}\n",
      "{'loss': 0.001, 'learning_rate': 5.406331150558138e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.4761822063625057e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 39.552, 'train_samples_per_second': 408.374, 'train_steps_per_second': 51.173, 'train_loss': 0.022711157301298652, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:05:12,825] Trial 11 finished with value: 0.8257199322416714 and parameters: {'learning_rate': 0.000208824699403238, 'weight_decay': 0.009913735492424547, 'num_train_epochs': 8}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.022750306874513626, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.5917, 'eval_samples_per_second': 140.322, 'eval_steps_per_second': 17.54, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6661, 'learning_rate': 7.170172608725825e-05, 'epoch': 1.98}\n",
      "{'loss': 0.4598, 'learning_rate': 4.8177537738420235e-05, 'epoch': 3.95}\n",
      "{'loss': 0.354, 'learning_rate': 2.4653349389582234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.2855, 'learning_rate': 1.1291610407442244e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.8027, 'train_samples_per_second': 450.915, 'train_steps_per_second': 56.532, 'train_loss': 0.43866688766969525, 'epoch': 8.0}\n",
      "{'eval_loss': 0.16839510202407837, 'eval_accuracy': 0.9782178217821782, 'eval_recall': 0.3333333333333333, 'eval_precision': 0.5714285714285714, 'eval_f1': 0.4210526315789474, 'eval_runtime': 3.9142, 'eval_samples_per_second': 129.017, 'eval_steps_per_second': 16.351, 'epoch': 8.0}\n",
      "{'loss': 0.311, 'learning_rate': 7.170172608725825e-05, 'epoch': 1.98}\n",
      "{'loss': 0.17, 'learning_rate': 4.8177537738420235e-05, 'epoch': 3.95}\n",
      "{'loss': 0.1127, 'learning_rate': 2.4653349389582234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0842, 'learning_rate': 1.1291610407442244e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 36.3023, 'train_samples_per_second': 444.71, 'train_steps_per_second': 55.754, 'train_loss': 0.1675688740263579, 'epoch': 8.0}\n",
      "{'eval_loss': 0.15547725558280945, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.9055, 'eval_samples_per_second': 129.304, 'eval_steps_per_second': 16.387, 'epoch': 8.0}\n",
      "{'loss': 0.22, 'learning_rate': 7.170172608725825e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1052, 'learning_rate': 4.8177537738420235e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0616, 'learning_rate': 2.4653349389582234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0109, 'learning_rate': 1.1291610407442244e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.6514, 'train_samples_per_second': 452.829, 'train_steps_per_second': 56.772, 'train_loss': 0.09944504534774147, 'epoch': 8.0}\n",
      "{'eval_loss': 0.0688643530011177, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.75, 'eval_precision': 1.0, 'eval_f1': 0.8571428571428571, 'eval_runtime': 3.6596, 'eval_samples_per_second': 137.993, 'eval_steps_per_second': 17.488, 'epoch': 8.0}\n",
      "{'loss': 0.1216, 'learning_rate': 7.170172608725825e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0655, 'learning_rate': 4.8177537738420235e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0141, 'learning_rate': 2.4653349389582234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0014, 'learning_rate': 1.1291610407442244e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 32.4558, 'train_samples_per_second': 497.661, 'train_steps_per_second': 62.362, 'train_loss': 0.050049644300178275, 'epoch': 8.0}\n",
      "{'eval_loss': 0.02360892854630947, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.7971, 'eval_samples_per_second': 132.733, 'eval_steps_per_second': 16.592, 'epoch': 8.0}\n",
      "{'loss': 0.0205, 'learning_rate': 7.170172608725825e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0159, 'learning_rate': 4.8177537738420235e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0009, 'learning_rate': 2.4653349389582234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0001, 'learning_rate': 1.1291610407442244e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.0662, 'train_samples_per_second': 460.615, 'train_steps_per_second': 57.719, 'train_loss': 0.00924692739456415, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:08:47,965] Trial 12 finished with value: 0.7464086862121592 and parameters: {'learning_rate': 9.522591443609626e-05, 'weight_decay': 0.009815474609681843, 'num_train_epochs': 8}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02589944750070572, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 4.2204, 'eval_samples_per_second': 119.42, 'eval_steps_per_second': 14.927, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6624, 'learning_rate': 0.0002021501874607177, 'epoch': 1.98}\n",
      "{'loss': 0.3589, 'learning_rate': 0.00010286227613423552, 'epoch': 3.95}\n",
      "{'loss': 0.1714, 'learning_rate': 3.5743648077533574e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 24.7315, 'train_samples_per_second': 489.579, 'train_steps_per_second': 61.379, 'train_loss': 0.39724014304843347, 'epoch': 6.0}\n",
      "{'eval_loss': 0.16912882030010223, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5, 'eval_f1': 0.5384615384615384, 'eval_runtime': 3.4955, 'eval_samples_per_second': 144.471, 'eval_steps_per_second': 18.309, 'epoch': 6.0}\n",
      "{'loss': 0.296, 'learning_rate': 0.0002021501874607177, 'epoch': 1.98}\n",
      "{'loss': 0.1259, 'learning_rate': 0.00010286227613423552, 'epoch': 3.95}\n",
      "{'loss': 0.0671, 'learning_rate': 3.5743648077533574e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 24.6526, 'train_samples_per_second': 491.144, 'train_steps_per_second': 61.576, 'train_loss': 0.1656474765581576, 'epoch': 6.0}\n",
      "{'eval_loss': 0.12470228970050812, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 3.6534, 'eval_samples_per_second': 138.228, 'eval_steps_per_second': 17.518, 'epoch': 6.0}\n",
      "{'loss': 0.2015, 'learning_rate': 0.0002021501874607177, 'epoch': 1.98}\n",
      "{'loss': 0.0957, 'learning_rate': 0.00010286227613423552, 'epoch': 3.95}\n",
      "{'loss': 0.0247, 'learning_rate': 3.5743648077533574e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 24.0442, 'train_samples_per_second': 503.572, 'train_steps_per_second': 63.134, 'train_loss': 0.10653824521147687, 'epoch': 6.0}\n",
      "{'eval_loss': 0.08505552262067795, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.75, 'eval_precision': 0.8181818181818182, 'eval_f1': 0.7826086956521738, 'eval_runtime': 3.8009, 'eval_samples_per_second': 132.864, 'eval_steps_per_second': 16.838, 'epoch': 6.0}\n",
      "{'loss': 0.1854, 'learning_rate': 0.0002021501874607177, 'epoch': 1.98}\n",
      "{'loss': 0.0492, 'learning_rate': 0.00010286227613423552, 'epoch': 3.95}\n",
      "{'loss': 0.013, 'learning_rate': 3.5743648077533574e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 24.9916, 'train_samples_per_second': 484.723, 'train_steps_per_second': 60.74, 'train_loss': 0.08153613075944202, 'epoch': 6.0}\n",
      "{'eval_loss': 0.02502698451280594, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 4.1784, 'eval_samples_per_second': 120.62, 'eval_steps_per_second': 15.077, 'epoch': 6.0}\n",
      "{'loss': 0.0754, 'learning_rate': 0.0002021501874607177, 'epoch': 1.98}\n",
      "{'loss': 0.0031, 'learning_rate': 0.00010286227613423552, 'epoch': 3.95}\n",
      "{'loss': 0.0007, 'learning_rate': 3.5743648077533574e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 27.2533, 'train_samples_per_second': 444.496, 'train_steps_per_second': 55.7, 'train_loss': 0.026075250070360496, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:11:33,121] Trial 13 finished with value: 0.7838768401697462 and parameters: {'learning_rate': 0.00030143809878719984, 'weight_decay': 0.009497965446382798, 'num_train_epochs': 6}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.020827215164899826, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.4166, 'eval_samples_per_second': 147.515, 'eval_steps_per_second': 18.439, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6942, 'learning_rate': 3.2101063859814236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.5563, 'learning_rate': 2.306868798479616e-05, 'epoch': 3.95}\n",
      "{'loss': 0.4904, 'learning_rate': 1.4036312109778087e-05, 'epoch': 5.93}\n",
      "{'loss': 0.4653, 'learning_rate': 5.003936234760013e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 39.9145, 'train_samples_per_second': 455.022, 'train_steps_per_second': 57.047, 'train_loss': 0.5377086895727828, 'epoch': 9.0}\n",
      "{'eval_loss': 0.14611737430095673, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.16666666666666666, 'eval_precision': 1.0, 'eval_f1': 0.2857142857142857, 'eval_runtime': 3.6301, 'eval_samples_per_second': 139.116, 'eval_steps_per_second': 17.631, 'epoch': 9.0}\n",
      "{'loss': 0.448, 'learning_rate': 3.2101063859814236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.3447, 'learning_rate': 2.306868798479616e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2956, 'learning_rate': 1.4036312109778087e-05, 'epoch': 5.93}\n",
      "{'loss': 0.259, 'learning_rate': 5.003936234760013e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 38.4909, 'train_samples_per_second': 471.852, 'train_steps_per_second': 59.157, 'train_loss': 0.3216487598042243, 'epoch': 9.0}\n",
      "{'eval_loss': 0.19331330060958862, 'eval_accuracy': 0.9841584158415841, 'eval_recall': 0.3333333333333333, 'eval_precision': 1.0, 'eval_f1': 0.5, 'eval_runtime': 3.8056, 'eval_samples_per_second': 132.701, 'eval_steps_per_second': 16.818, 'epoch': 9.0}\n",
      "{'loss': 0.3584, 'learning_rate': 3.2101063859814236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.2634, 'learning_rate': 2.306868798479616e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2069, 'learning_rate': 1.4036312109778087e-05, 'epoch': 5.93}\n",
      "{'loss': 0.181, 'learning_rate': 5.003936234760013e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 38.7096, 'train_samples_per_second': 469.186, 'train_steps_per_second': 58.823, 'train_loss': 0.24056808980976116, 'epoch': 9.0}\n",
      "{'eval_loss': 0.08788919448852539, 'eval_accuracy': 0.9920792079207921, 'eval_recall': 0.6666666666666666, 'eval_precision': 1.0, 'eval_f1': 0.8, 'eval_runtime': 3.2189, 'eval_samples_per_second': 156.884, 'eval_steps_per_second': 19.882, 'epoch': 9.0}\n",
      "{'loss': 0.2602, 'learning_rate': 3.2101063859814236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1672, 'learning_rate': 2.306868798479616e-05, 'epoch': 3.95}\n",
      "{'loss': 0.1028, 'learning_rate': 1.4036312109778087e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0821, 'learning_rate': 5.003936234760013e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 36.841, 'train_samples_per_second': 493.227, 'train_steps_per_second': 61.806, 'train_loss': 0.14061210675882466, 'epoch': 9.0}\n",
      "{'eval_loss': 0.05078360438346863, 'eval_accuracy': 0.9920634920634921, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.8181818181818182, 'eval_f1': 0.8181818181818182, 'eval_runtime': 3.631, 'eval_samples_per_second': 138.804, 'eval_steps_per_second': 17.35, 'epoch': 9.0}\n",
      "{'loss': 0.1426, 'learning_rate': 3.2101063859814236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0719, 'learning_rate': 2.306868798479616e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0207, 'learning_rate': 1.4036312109778087e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0199, 'learning_rate': 5.003936234760013e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 39.2815, 'train_samples_per_second': 462.584, 'train_steps_per_second': 57.966, 'train_loss': 0.061151164846039156, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:15:24,933] Trial 14 finished with value: 0.6522077922077922 and parameters: {'learning_rate': 4.113343973483231e-05, 'weight_decay': 0.004203794060988996, 'num_train_epochs': 9}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03946886956691742, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 3.4747, 'eval_samples_per_second': 145.048, 'eval_steps_per_second': 18.131, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6586, 'learning_rate': 0.00027487618702159153, 'epoch': 1.98}\n",
      "{'loss': 0.4024, 'learning_rate': 0.00018469371096463893, 'epoch': 3.95}\n",
      "{'loss': 0.2333, 'learning_rate': 9.451123490768632e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1726, 'learning_rate': 4.328758850733725e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.8853, 'train_samples_per_second': 449.878, 'train_steps_per_second': 56.402, 'train_loss': 0.3639991006596757, 'epoch': 8.0}\n",
      "{'eval_loss': 0.17473319172859192, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.6363636363636364, 'eval_f1': 0.6086956521739131, 'eval_runtime': 3.8846, 'eval_samples_per_second': 130.002, 'eval_steps_per_second': 16.476, 'epoch': 8.0}\n",
      "{'loss': 0.2783, 'learning_rate': 0.00027487618702159153, 'epoch': 1.98}\n",
      "{'loss': 0.2056, 'learning_rate': 0.00018469371096463893, 'epoch': 3.95}\n",
      "{'loss': 0.0699, 'learning_rate': 9.451123490768632e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0327, 'learning_rate': 4.328758850733725e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 37.3364, 'train_samples_per_second': 432.392, 'train_steps_per_second': 54.21, 'train_loss': 0.1448965860366119, 'epoch': 8.0}\n",
      "{'eval_loss': 0.16422085464000702, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 3.7324, 'eval_samples_per_second': 135.303, 'eval_steps_per_second': 17.147, 'epoch': 8.0}\n",
      "{'loss': 0.2432, 'learning_rate': 0.00027487618702159153, 'epoch': 1.98}\n",
      "{'loss': 0.1872, 'learning_rate': 0.00018469371096463893, 'epoch': 3.95}\n",
      "{'loss': 0.0386, 'learning_rate': 9.451123490768632e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0109, 'learning_rate': 4.328758850733725e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 40.3894, 'train_samples_per_second': 399.709, 'train_steps_per_second': 50.112, 'train_loss': 0.12032686709886484, 'epoch': 8.0}\n",
      "{'eval_loss': 0.037823386490345, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.8333333333333334, 'eval_precision': 1.0, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.3601, 'eval_samples_per_second': 150.293, 'eval_steps_per_second': 19.047, 'epoch': 8.0}\n",
      "{'loss': 0.1883, 'learning_rate': 0.00027487618702159153, 'epoch': 1.98}\n",
      "{'loss': 0.0307, 'learning_rate': 0.00018469371096463893, 'epoch': 3.95}\n",
      "{'loss': 0.0022, 'learning_rate': 9.451123490768632e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 4.328758850733725e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.3299, 'train_samples_per_second': 470.494, 'train_steps_per_second': 58.957, 'train_loss': 0.05464205763668209, 'epoch': 8.0}\n",
      "{'eval_loss': 0.021903444081544876, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.76, 'eval_samples_per_second': 134.042, 'eval_steps_per_second': 16.755, 'epoch': 8.0}\n",
      "{'loss': 0.0759, 'learning_rate': 0.00027487618702159153, 'epoch': 1.98}\n",
      "{'loss': 0.0693, 'learning_rate': 0.00018469371096463893, 'epoch': 3.95}\n",
      "{'loss': 0.0136, 'learning_rate': 9.451123490768632e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 4.328758850733725e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 38.5137, 'train_samples_per_second': 419.383, 'train_steps_per_second': 52.553, 'train_loss': 0.039232471736173655, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:19:10,465] Trial 15 finished with value: 0.8327062716078736 and parameters: {'learning_rate': 0.00036505866307854414, 'weight_decay': 0.002134010915556437, 'num_train_epochs': 8}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016550738364458084, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.6532, 'eval_samples_per_second': 137.962, 'eval_steps_per_second': 17.245, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.66, 'learning_rate': 0.00032508782135666546, 'epoch': 1.98}\n",
      "{'loss': 0.4059, 'learning_rate': 0.0002450169293968956, 'epoch': 3.95}\n",
      "{'loss': 0.2227, 'learning_rate': 0.00016494603743712582, 'epoch': 5.93}\n",
      "{'loss': 0.1948, 'learning_rate': 8.487514547735602e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0898, 'learning_rate': 4.804253517586189e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 46.1034, 'train_samples_per_second': 437.712, 'train_steps_per_second': 54.877, 'train_loss': 0.31571815551034077, 'epoch': 10.0}\n",
      "{'eval_loss': 0.20997507870197296, 'eval_accuracy': 0.9841584158415841, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.7, 'eval_f1': 0.6363636363636365, 'eval_runtime': 3.3472, 'eval_samples_per_second': 150.871, 'eval_steps_per_second': 19.12, 'epoch': 10.0}\n",
      "{'loss': 0.3337, 'learning_rate': 0.00032508782135666546, 'epoch': 1.98}\n",
      "{'loss': 0.1822, 'learning_rate': 0.0002450169293968956, 'epoch': 3.95}\n",
      "{'loss': 0.1176, 'learning_rate': 0.00016494603743712582, 'epoch': 5.93}\n",
      "{'loss': 0.0634, 'learning_rate': 8.487514547735602e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0036, 'learning_rate': 4.804253517586189e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 43.2901, 'train_samples_per_second': 466.158, 'train_steps_per_second': 58.443, 'train_loss': 0.13845254353186845, 'epoch': 10.0}\n",
      "{'eval_loss': 0.18586106598377228, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 3.4982, 'eval_samples_per_second': 144.359, 'eval_steps_per_second': 18.295, 'epoch': 10.0}\n",
      "{'loss': 0.2851, 'learning_rate': 0.00032508782135666546, 'epoch': 1.98}\n",
      "{'loss': 0.1226, 'learning_rate': 0.0002450169293968956, 'epoch': 3.95}\n",
      "{'loss': 0.0614, 'learning_rate': 0.00016494603743712582, 'epoch': 5.93}\n",
      "{'loss': 0.051, 'learning_rate': 8.487514547735602e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0234, 'learning_rate': 4.804253517586189e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 44.8181, 'train_samples_per_second': 450.265, 'train_steps_per_second': 56.45, 'train_loss': 0.10956883449328275, 'epoch': 10.0}\n",
      "{'eval_loss': 0.06555552780628204, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.9166666666666666, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9166666666666666, 'eval_runtime': 3.7384, 'eval_samples_per_second': 135.083, 'eval_steps_per_second': 17.119, 'epoch': 10.0}\n",
      "{'loss': 0.1414, 'learning_rate': 0.00032508782135666546, 'epoch': 1.98}\n",
      "{'loss': 0.1017, 'learning_rate': 0.0002450169293968956, 'epoch': 3.95}\n",
      "{'loss': 0.0279, 'learning_rate': 0.00016494603743712582, 'epoch': 5.93}\n",
      "{'loss': 0.0128, 'learning_rate': 8.487514547735602e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0002, 'learning_rate': 4.804253517586189e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 41.2972, 'train_samples_per_second': 488.896, 'train_steps_per_second': 61.263, 'train_loss': 0.056149629352815825, 'epoch': 10.0}\n",
      "{'eval_loss': 0.05859491974115372, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.5575, 'eval_samples_per_second': 141.671, 'eval_steps_per_second': 17.709, 'epoch': 10.0}\n",
      "{'loss': 0.1773, 'learning_rate': 0.00032508782135666546, 'epoch': 1.98}\n",
      "{'loss': 0.0399, 'learning_rate': 0.0002450169293968956, 'epoch': 3.95}\n",
      "{'loss': 0.0165, 'learning_rate': 0.00016494603743712582, 'epoch': 5.93}\n",
      "{'loss': 0.0201, 'learning_rate': 8.487514547735602e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0054, 'learning_rate': 4.804253517586189e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 43.2675, 'train_samples_per_second': 466.631, 'train_steps_per_second': 58.473, 'train_loss': 0.05121207340236702, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:23:27,177] Trial 16 finished with value: 0.8302688539530644 and parameters: {'learning_rate': 0.0004051587133164353, 'weight_decay': 0.0023954614932576545, 'num_train_epochs': 10}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.013354039750993252, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.3295, 'eval_samples_per_second': 151.376, 'eval_steps_per_second': 18.922, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6568, 'learning_rate': 6.791451752331709e-05, 'epoch': 1.98}\n",
      "{'loss': 0.457, 'learning_rate': 3.455768180459553e-05, 'epoch': 3.95}\n",
      "{'loss': 0.3703, 'learning_rate': 1.2008460858739758e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 26.5712, 'train_samples_per_second': 455.681, 'train_steps_per_second': 57.129, 'train_loss': 0.4949110983545758, 'epoch': 6.0}\n",
      "{'eval_loss': 0.13922736048698425, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.25, 'eval_precision': 1.0, 'eval_f1': 0.4, 'eval_runtime': 3.29, 'eval_samples_per_second': 153.495, 'eval_steps_per_second': 19.453, 'epoch': 6.0}\n",
      "{'loss': 0.3682, 'learning_rate': 6.791451752331709e-05, 'epoch': 1.98}\n",
      "{'loss': 0.196, 'learning_rate': 3.455768180459553e-05, 'epoch': 3.95}\n",
      "{'loss': 0.1317, 'learning_rate': 1.2008460858739758e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 28.2371, 'train_samples_per_second': 428.798, 'train_steps_per_second': 53.759, 'train_loss': 0.23214354376862015, 'epoch': 6.0}\n",
      "{'eval_loss': 0.20200684666633606, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.698, 'eval_samples_per_second': 136.56, 'eval_steps_per_second': 17.307, 'epoch': 6.0}\n",
      "{'loss': 0.2407, 'learning_rate': 6.791451752331709e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1525, 'learning_rate': 3.455768180459553e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0808, 'learning_rate': 1.2008460858739758e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 27.0165, 'train_samples_per_second': 448.171, 'train_steps_per_second': 56.188, 'train_loss': 0.15967464918204446, 'epoch': 6.0}\n",
      "{'eval_loss': 0.025004543364048004, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.8333333333333334, 'eval_precision': 1.0, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.8954, 'eval_samples_per_second': 129.641, 'eval_steps_per_second': 16.43, 'epoch': 6.0}\n",
      "{'loss': 0.1927, 'learning_rate': 6.791451752331709e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0735, 'learning_rate': 3.455768180459553e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0284, 'learning_rate': 1.2008460858739758e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 22.3932, 'train_samples_per_second': 540.967, 'train_steps_per_second': 67.788, 'train_loss': 0.09702683103866556, 'epoch': 6.0}\n",
      "{'eval_loss': 0.04051058739423752, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 3.6426, 'eval_samples_per_second': 138.364, 'eval_steps_per_second': 17.296, 'epoch': 6.0}\n",
      "{'loss': 0.0851, 'learning_rate': 6.791451752331709e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0234, 'learning_rate': 3.455768180459553e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0042, 'learning_rate': 1.2008460858739758e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 27.0367, 'train_samples_per_second': 448.057, 'train_steps_per_second': 56.146, 'train_loss': 0.03713670087916648, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:26:17,574] Trial 17 finished with value: 0.7413700025464731 and parameters: {'learning_rate': 0.00010127135324203863, 'weight_decay': 0.0012032819459177556, 'num_train_epochs': 6}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.019221531227231026, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 4.0035, 'eval_samples_per_second': 125.891, 'eval_steps_per_second': 15.736, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7144, 'learning_rate': 0.0003702298234416611, 'epoch': 1.98}\n",
      "{'loss': 0.4847, 'learning_rate': 0.0002660571100365792, 'epoch': 3.95}\n",
      "{'loss': 0.3848, 'learning_rate': 0.00016188439663149728, 'epoch': 5.93}\n",
      "{'loss': 0.2878, 'learning_rate': 5.7711683226415375e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 40.4292, 'train_samples_per_second': 449.23, 'train_steps_per_second': 56.321, 'train_loss': 0.43862463876140395, 'epoch': 9.0}\n",
      "{'eval_loss': 0.15095873177051544, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5833333333333334, 'eval_f1': 0.5833333333333334, 'eval_runtime': 4.0476, 'eval_samples_per_second': 124.764, 'eval_steps_per_second': 15.812, 'epoch': 9.0}\n",
      "{'loss': 0.4553, 'learning_rate': 0.0003702298234416611, 'epoch': 1.98}\n",
      "{'loss': 0.2292, 'learning_rate': 0.0002660571100365792, 'epoch': 3.95}\n",
      "{'loss': 0.2424, 'learning_rate': 0.00016188439663149728, 'epoch': 5.93}\n",
      "{'loss': 0.1931, 'learning_rate': 5.7711683226415375e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.6962, 'train_samples_per_second': 457.525, 'train_steps_per_second': 57.361, 'train_loss': 0.26274579148256944, 'epoch': 9.0}\n",
      "{'eval_loss': 0.13551901280879974, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.5, 'eval_precision': 0.8571428571428571, 'eval_f1': 0.631578947368421, 'eval_runtime': 4.1926, 'eval_samples_per_second': 120.45, 'eval_steps_per_second': 15.265, 'epoch': 9.0}\n",
      "{'loss': 0.5083, 'learning_rate': 0.0003702298234416611, 'epoch': 1.98}\n",
      "{'loss': 0.5628, 'learning_rate': 0.0002660571100365792, 'epoch': 3.95}\n",
      "{'loss': 0.3077, 'learning_rate': 0.00016188439663149728, 'epoch': 5.93}\n",
      "{'loss': 0.2917, 'learning_rate': 5.7711683226415375e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 38.35, 'train_samples_per_second': 473.585, 'train_steps_per_second': 59.374, 'train_loss': 0.3923083319180254, 'epoch': 9.0}\n",
      "{'eval_loss': 0.04829233139753342, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.75, 'eval_precision': 1.0, 'eval_f1': 0.8571428571428571, 'eval_runtime': 3.9059, 'eval_samples_per_second': 129.291, 'eval_steps_per_second': 16.385, 'epoch': 9.0}\n",
      "{'loss': 0.2996, 'learning_rate': 0.0003702298234416611, 'epoch': 1.98}\n",
      "{'loss': 0.3648, 'learning_rate': 0.0002660571100365792, 'epoch': 3.95}\n",
      "{'loss': 0.2259, 'learning_rate': 0.00016188439663149728, 'epoch': 5.93}\n",
      "{'loss': 0.1804, 'learning_rate': 5.7711683226415375e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 34.9634, 'train_samples_per_second': 519.716, 'train_steps_per_second': 65.125, 'train_loss': 0.2526481906520624, 'epoch': 9.0}\n",
      "{'eval_loss': 0.11274825781583786, 'eval_accuracy': 0.9880952380952381, 'eval_recall': 0.7272727272727273, 'eval_precision': 0.7272727272727273, 'eval_f1': 0.7272727272727273, 'eval_runtime': 4.0149, 'eval_samples_per_second': 125.533, 'eval_steps_per_second': 15.692, 'epoch': 9.0}\n",
      "{'loss': 0.2842, 'learning_rate': 0.0003702298234416611, 'epoch': 1.98}\n",
      "{'loss': 0.2742, 'learning_rate': 0.0002660571100365792, 'epoch': 3.95}\n",
      "{'loss': 0.1889, 'learning_rate': 0.00016188439663149728, 'epoch': 5.93}\n",
      "{'loss': 0.1763, 'learning_rate': 5.7711683226415375e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.4257, 'train_samples_per_second': 460.893, 'train_steps_per_second': 57.754, 'train_loss': 0.22211226612839932, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:30:10,656] Trial 18 finished with value: 0.7503417634996582 and parameters: {'learning_rate': 0.000474402536846743, 'weight_decay': 0.0031315784244297013, 'num_train_epochs': 9}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015229472890496254, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.6326, 'eval_samples_per_second': 138.743, 'eval_steps_per_second': 17.343, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6443, 'learning_rate': 0.00012233315152878024, 'epoch': 1.98}\n",
      "{'loss': 0.3757, 'learning_rate': 6.224810657358366e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2299, 'learning_rate': 2.1630616183870767e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 26.237, 'train_samples_per_second': 461.486, 'train_steps_per_second': 57.857, 'train_loss': 0.41403279552660754, 'epoch': 6.0}\n",
      "{'eval_loss': 0.1641356498003006, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5, 'eval_precision': 0.6, 'eval_f1': 0.5454545454545454, 'eval_runtime': 4.2049, 'eval_samples_per_second': 120.098, 'eval_steps_per_second': 15.22, 'epoch': 6.0}\n",
      "{'loss': 0.3146, 'learning_rate': 0.00012233315152878024, 'epoch': 1.98}\n",
      "{'loss': 0.1049, 'learning_rate': 6.224810657358366e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0529, 'learning_rate': 2.1630616183870767e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 24.0208, 'train_samples_per_second': 504.063, 'train_steps_per_second': 63.195, 'train_loss': 0.1564699650910218, 'epoch': 6.0}\n",
      "{'eval_loss': 0.19549410045146942, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.5532, 'eval_samples_per_second': 142.126, 'eval_steps_per_second': 18.012, 'epoch': 6.0}\n",
      "{'loss': 0.1878, 'learning_rate': 0.00012233315152878024, 'epoch': 1.98}\n",
      "{'loss': 0.0497, 'learning_rate': 6.224810657358366e-05, 'epoch': 3.95}\n",
      "{'loss': 0.006, 'learning_rate': 2.1630616183870767e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 24.3597, 'train_samples_per_second': 497.05, 'train_steps_per_second': 62.316, 'train_loss': 0.08020211441616609, 'epoch': 6.0}\n",
      "{'eval_loss': 0.024717560037970543, 'eval_accuracy': 0.998019801980198, 'eval_recall': 0.9166666666666666, 'eval_precision': 1.0, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.3006, 'eval_samples_per_second': 117.426, 'eval_steps_per_second': 14.882, 'epoch': 6.0}\n",
      "{'loss': 0.12, 'learning_rate': 0.00012233315152878024, 'epoch': 1.98}\n",
      "{'loss': 0.0582, 'learning_rate': 6.224810657358366e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0018, 'learning_rate': 2.1630616183870767e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 22.4854, 'train_samples_per_second': 538.749, 'train_steps_per_second': 67.51, 'train_loss': 0.0592812174782275, 'epoch': 6.0}\n",
      "{'eval_loss': 0.021112293004989624, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.567, 'eval_samples_per_second': 141.297, 'eval_steps_per_second': 17.662, 'epoch': 6.0}\n",
      "{'loss': 0.0356, 'learning_rate': 0.00012233315152878024, 'epoch': 1.98}\n",
      "{'loss': 0.0091, 'learning_rate': 6.224810657358366e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0004, 'learning_rate': 2.1630616183870767e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 24.1467, 'train_samples_per_second': 501.683, 'train_steps_per_second': 62.866, 'train_loss': 0.014841633396244728, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:32:52,091] Trial 19 finished with value: 0.7998228540428028 and parameters: {'learning_rate': 0.00018241819648397682, 'weight_decay': 0.006001920138610421, 'num_train_epochs': 6}. Best is trial 10 with value: 0.8404472049689442.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.010614769533276558, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.8244, 'eval_samples_per_second': 131.786, 'eval_steps_per_second': 16.473, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6863, 'learning_rate': 5.218766172768199e-05, 'epoch': 1.98}\n",
      "{'loss': 0.5007, 'learning_rate': 3.506572546531913e-05, 'epoch': 3.95}\n",
      "{'loss': 0.4293, 'learning_rate': 1.7943789202956276e-05, 'epoch': 5.93}\n",
      "{'loss': 0.3686, 'learning_rate': 8.218529405934171e-07, 'epoch': 7.91}\n",
      "{'train_runtime': 33.7304, 'train_samples_per_second': 478.619, 'train_steps_per_second': 60.005, 'train_loss': 0.4937177573739304, 'epoch': 8.0}\n",
      "{'eval_loss': 0.15084871649742126, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.4166666666666667, 'eval_precision': 0.7142857142857143, 'eval_f1': 0.5263157894736842, 'eval_runtime': 4.5122, 'eval_samples_per_second': 111.919, 'eval_steps_per_second': 14.184, 'epoch': 8.0}\n",
      "{'loss': 0.3766, 'learning_rate': 5.218766172768199e-05, 'epoch': 1.98}\n",
      "{'loss': 0.2265, 'learning_rate': 3.506572546531913e-05, 'epoch': 3.95}\n",
      "{'loss': 0.1788, 'learning_rate': 1.7943789202956276e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1586, 'learning_rate': 8.218529405934171e-07, 'epoch': 7.91}\n",
      "{'train_runtime': 33.8728, 'train_samples_per_second': 476.606, 'train_steps_per_second': 59.753, 'train_loss': 0.23277901227884143, 'epoch': 8.0}\n",
      "{'eval_loss': 0.18467608094215393, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 4.0114, 'eval_samples_per_second': 125.891, 'eval_steps_per_second': 15.954, 'epoch': 8.0}\n",
      "{'loss': 0.2741, 'learning_rate': 5.218766172768199e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1717, 'learning_rate': 3.506572546531913e-05, 'epoch': 3.95}\n",
      "{'loss': 0.099, 'learning_rate': 1.7943789202956276e-05, 'epoch': 5.93}\n",
      "{'loss': 0.066, 'learning_rate': 8.218529405934171e-07, 'epoch': 7.91}\n",
      "{'train_runtime': 34.5702, 'train_samples_per_second': 466.992, 'train_steps_per_second': 58.548, 'train_loss': 0.15217486789575208, 'epoch': 8.0}\n",
      "{'eval_loss': 0.07058849185705185, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.75, 'eval_precision': 1.0, 'eval_f1': 0.8571428571428571, 'eval_runtime': 4.2083, 'eval_samples_per_second': 120.002, 'eval_steps_per_second': 15.208, 'epoch': 8.0}\n",
      "{'loss': 0.1751, 'learning_rate': 5.218766172768199e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0502, 'learning_rate': 3.506572546531913e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0404, 'learning_rate': 1.7943789202956276e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0164, 'learning_rate': 8.218529405934171e-07, 'epoch': 7.91}\n",
      "{'train_runtime': 31.6128, 'train_samples_per_second': 510.933, 'train_steps_per_second': 64.025, 'train_loss': 0.06967272908742765, 'epoch': 8.0}\n",
      "{'eval_loss': 0.0261500533670187, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 3.6886, 'eval_samples_per_second': 136.637, 'eval_steps_per_second': 17.08, 'epoch': 8.0}\n",
      "{'loss': 0.059, 'learning_rate': 5.218766172768199e-05, 'epoch': 1.98}\n",
      "{'loss': 0.034, 'learning_rate': 3.506572546531913e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0256, 'learning_rate': 1.7943789202956276e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0007, 'learning_rate': 8.218529405934171e-07, 'epoch': 7.91}\n",
      "{'train_runtime': 37.3299, 'train_samples_per_second': 432.683, 'train_steps_per_second': 54.219, 'train_loss': 0.029479509244548233, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:36:25,033] Trial 20 finished with value: 0.7562435500515996 and parameters: {'learning_rate': 6.930959799004485e-05, 'weight_decay': 0.0021692706436994454, 'num_train_epochs': 8}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.026104094460606575, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.436, 'eval_samples_per_second': 146.683, 'eval_steps_per_second': 18.335, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.71, 'learning_rate': 0.0003406747060794259, 'epoch': 1.98}\n",
      "{'loss': 0.4683, 'learning_rate': 0.00025676467995148843, 'epoch': 3.95}\n",
      "{'loss': 0.3099, 'learning_rate': 0.00017285465382355105, 'epoch': 5.93}\n",
      "{'loss': 0.2217, 'learning_rate': 8.894462769561366e-05, 'epoch': 7.91}\n",
      "{'loss': 0.1333, 'learning_rate': 5.034601567676244e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 44.2409, 'train_samples_per_second': 456.139, 'train_steps_per_second': 57.187, 'train_loss': 0.36941252207096387, 'epoch': 10.0}\n",
      "{'eval_loss': 0.16696679592132568, 'eval_accuracy': 0.9841584158415841, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.7, 'eval_f1': 0.6363636363636365, 'eval_runtime': 3.4264, 'eval_samples_per_second': 147.383, 'eval_steps_per_second': 18.678, 'epoch': 10.0}\n",
      "{'loss': 0.3601, 'learning_rate': 0.0003406747060794259, 'epoch': 1.98}\n",
      "{'loss': 0.239, 'learning_rate': 0.00025676467995148843, 'epoch': 3.95}\n",
      "{'loss': 0.1612, 'learning_rate': 0.00017285465382355105, 'epoch': 5.93}\n",
      "{'loss': 0.1792, 'learning_rate': 8.894462769561366e-05, 'epoch': 7.91}\n",
      "{'loss': 0.1338, 'learning_rate': 5.034601567676244e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 43.8947, 'train_samples_per_second': 459.737, 'train_steps_per_second': 57.638, 'train_loss': 0.21456956901097957, 'epoch': 10.0}\n",
      "{'eval_loss': 0.12333620339632034, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 4.0043, 'eval_samples_per_second': 126.116, 'eval_steps_per_second': 15.983, 'epoch': 10.0}\n",
      "{'loss': 0.3417, 'learning_rate': 0.0003406747060794259, 'epoch': 1.98}\n",
      "{'loss': 0.258, 'learning_rate': 0.00025676467995148843, 'epoch': 3.95}\n",
      "{'loss': 0.194, 'learning_rate': 0.00017285465382355105, 'epoch': 5.93}\n",
      "{'loss': 0.1841, 'learning_rate': 8.894462769561366e-05, 'epoch': 7.91}\n",
      "{'loss': 0.1461, 'learning_rate': 5.034601567676244e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 43.8798, 'train_samples_per_second': 459.893, 'train_steps_per_second': 57.658, 'train_loss': 0.2270381147211248, 'epoch': 10.0}\n",
      "{'eval_loss': 0.06200822815299034, 'eval_accuracy': 0.9920792079207921, 'eval_recall': 0.6666666666666666, 'eval_precision': 1.0, 'eval_f1': 0.8, 'eval_runtime': 3.5509, 'eval_samples_per_second': 142.216, 'eval_steps_per_second': 18.023, 'epoch': 10.0}\n",
      "{'loss': 0.312, 'learning_rate': 0.0003406747060794259, 'epoch': 1.98}\n",
      "{'loss': 0.2441, 'learning_rate': 0.00025676467995148843, 'epoch': 3.95}\n",
      "{'loss': 0.1509, 'learning_rate': 0.00017285465382355105, 'epoch': 5.93}\n",
      "{'loss': 0.1382, 'learning_rate': 8.894462769561366e-05, 'epoch': 7.91}\n",
      "{'loss': 0.1264, 'learning_rate': 5.034601567676244e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 39.5823, 'train_samples_per_second': 510.077, 'train_steps_per_second': 63.917, 'train_loss': 0.19435958881152007, 'epoch': 10.0}\n",
      "{'eval_loss': 0.08802943676710129, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 3.5105, 'eval_samples_per_second': 143.571, 'eval_steps_per_second': 17.946, 'epoch': 10.0}\n",
      "{'loss': 0.2416, 'learning_rate': 0.0003406747060794259, 'epoch': 1.98}\n",
      "{'loss': 0.2136, 'learning_rate': 0.00025676467995148843, 'epoch': 3.95}\n",
      "{'loss': 0.1563, 'learning_rate': 0.00017285465382355105, 'epoch': 5.93}\n",
      "{'loss': 0.1529, 'learning_rate': 8.894462769561366e-05, 'epoch': 7.91}\n",
      "{'loss': 0.1124, 'learning_rate': 5.034601567676244e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 43.1764, 'train_samples_per_second': 467.616, 'train_steps_per_second': 58.597, 'train_loss': 0.17439589641782136, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:40:39,685] Trial 21 finished with value: 0.7833389798607191 and parameters: {'learning_rate': 0.0004245847322073633, 'weight_decay': 0.002617403917231295, 'num_train_epochs': 10}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01750561036169529, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.4634, 'eval_samples_per_second': 145.521, 'eval_steps_per_second': 18.19, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6482, 'learning_rate': 0.0002266083620943772, 'epoch': 1.98}\n",
      "{'loss': 0.3793, 'learning_rate': 0.00017079349458344685, 'epoch': 3.95}\n",
      "{'loss': 0.1903, 'learning_rate': 0.00011497862707251651, 'epoch': 5.93}\n",
      "{'loss': 0.1454, 'learning_rate': 5.916375956158617e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0577, 'learning_rate': 3.3488920506558203e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 42.9067, 'train_samples_per_second': 470.322, 'train_steps_per_second': 58.965, 'train_loss': 0.28257428647972377, 'epoch': 10.0}\n",
      "{'eval_loss': 0.20991645753383636, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5, 'eval_precision': 0.6666666666666666, 'eval_f1': 0.5714285714285715, 'eval_runtime': 3.6619, 'eval_samples_per_second': 137.905, 'eval_steps_per_second': 17.477, 'epoch': 10.0}\n",
      "{'loss': 0.2503, 'learning_rate': 0.0002266083620943772, 'epoch': 1.98}\n",
      "{'loss': 0.1224, 'learning_rate': 0.00017079349458344685, 'epoch': 3.95}\n",
      "{'loss': 0.0388, 'learning_rate': 0.00011497862707251651, 'epoch': 5.93}\n",
      "{'loss': 0.0083, 'learning_rate': 5.916375956158617e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0052, 'learning_rate': 3.3488920506558203e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 45.4019, 'train_samples_per_second': 444.475, 'train_steps_per_second': 55.725, 'train_loss': 0.08401351540483784, 'epoch': 10.0}\n",
      "{'eval_loss': 0.1784883588552475, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.875, 'eval_f1': 0.7000000000000001, 'eval_runtime': 4.1359, 'eval_samples_per_second': 122.1, 'eval_steps_per_second': 15.474, 'epoch': 10.0}\n",
      "{'loss': 0.1704, 'learning_rate': 0.0002266083620943772, 'epoch': 1.98}\n",
      "{'loss': 0.0783, 'learning_rate': 0.00017079349458344685, 'epoch': 3.95}\n",
      "{'loss': 0.031, 'learning_rate': 0.00011497862707251651, 'epoch': 5.93}\n",
      "{'loss': 0.0068, 'learning_rate': 5.916375956158617e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0026, 'learning_rate': 3.3488920506558203e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 45.2597, 'train_samples_per_second': 445.871, 'train_steps_per_second': 55.9, 'train_loss': 0.05713115640991393, 'epoch': 10.0}\n",
      "{'eval_loss': 0.00411819014698267, 'eval_accuracy': 0.998019801980198, 'eval_recall': 1.0, 'eval_precision': 0.9230769230769231, 'eval_f1': 0.9600000000000001, 'eval_runtime': 3.5326, 'eval_samples_per_second': 142.953, 'eval_steps_per_second': 18.117, 'epoch': 10.0}\n",
      "{'loss': 0.1043, 'learning_rate': 0.0002266083620943772, 'epoch': 1.98}\n",
      "{'loss': 0.0596, 'learning_rate': 0.00017079349458344685, 'epoch': 3.95}\n",
      "{'loss': 0.0019, 'learning_rate': 0.00011497862707251651, 'epoch': 5.93}\n",
      "{'loss': 0.0071, 'learning_rate': 5.916375956158617e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0004, 'learning_rate': 3.3488920506558203e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 39.5515, 'train_samples_per_second': 510.474, 'train_steps_per_second': 63.967, 'train_loss': 0.03423269742294795, 'epoch': 10.0}\n",
      "{'eval_loss': 0.015917226672172546, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.8657, 'eval_samples_per_second': 130.379, 'eval_steps_per_second': 16.297, 'epoch': 10.0}\n",
      "{'loss': 0.0851, 'learning_rate': 0.0002266083620943772, 'epoch': 1.98}\n",
      "{'loss': 0.0181, 'learning_rate': 0.00017079349458344685, 'epoch': 3.95}\n",
      "{'loss': 0.0203, 'learning_rate': 0.00011497862707251651, 'epoch': 5.93}\n",
      "{'loss': 0.0168, 'learning_rate': 5.916375956158617e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0001, 'learning_rate': 3.3488920506558203e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 45.9399, 'train_samples_per_second': 439.487, 'train_steps_per_second': 55.072, 'train_loss': 0.027756635705170153, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:44:58,465] Trial 22 finished with value: 0.8280662525879918 and parameters: {'learning_rate': 0.00028242322960530755, 'weight_decay': 0.0014598004623382166, 'num_train_epochs': 10}. Best is trial 10 with value: 0.8404472049689442.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02137482352554798, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.7112, 'eval_samples_per_second': 135.806, 'eval_steps_per_second': 16.976, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6868, 'learning_rate': 0.00039473897963830375, 'epoch': 1.98}\n",
      "{'loss': 0.4324, 'learning_rate': 0.0002836700489578581, 'epoch': 3.95}\n",
      "{'loss': 0.239, 'learning_rate': 0.00017260111827741248, 'epoch': 5.93}\n",
      "{'loss': 0.1847, 'learning_rate': 6.153218759696687e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 41.7559, 'train_samples_per_second': 434.957, 'train_steps_per_second': 54.531, 'train_loss': 0.3498755091892087, 'epoch': 9.0}\n",
      "{'eval_loss': 0.17893925309181213, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.5, 'eval_precision': 0.8571428571428571, 'eval_f1': 0.631578947368421, 'eval_runtime': 3.6786, 'eval_samples_per_second': 137.28, 'eval_steps_per_second': 17.398, 'epoch': 9.0}\n",
      "{'loss': 0.3538, 'learning_rate': 0.00039473897963830375, 'epoch': 1.98}\n",
      "{'loss': 0.2313, 'learning_rate': 0.0002836700489578581, 'epoch': 3.95}\n",
      "{'loss': 0.1525, 'learning_rate': 0.00017260111827741248, 'epoch': 5.93}\n",
      "{'loss': 0.1253, 'learning_rate': 6.153218759696687e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 40.2384, 'train_samples_per_second': 451.36, 'train_steps_per_second': 56.588, 'train_loss': 0.19594230702114984, 'epoch': 9.0}\n",
      "{'eval_loss': 0.12490839511156082, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.4136, 'eval_samples_per_second': 147.937, 'eval_steps_per_second': 18.748, 'epoch': 9.0}\n",
      "{'loss': 0.4266, 'learning_rate': 0.00039473897963830375, 'epoch': 1.98}\n",
      "{'loss': 0.2865, 'learning_rate': 0.0002836700489578581, 'epoch': 3.95}\n",
      "{'loss': 0.195, 'learning_rate': 0.00017260111827741248, 'epoch': 5.93}\n",
      "{'loss': 0.1279, 'learning_rate': 6.153218759696687e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.5713, 'train_samples_per_second': 458.968, 'train_steps_per_second': 57.542, 'train_loss': 0.23926318105396913, 'epoch': 9.0}\n",
      "{'eval_loss': 0.05850444734096527, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 3.9586, 'eval_samples_per_second': 127.572, 'eval_steps_per_second': 16.167, 'epoch': 9.0}\n",
      "{'loss': 0.3161, 'learning_rate': 0.00039473897963830375, 'epoch': 1.98}\n",
      "{'loss': 0.2092, 'learning_rate': 0.0002836700489578581, 'epoch': 3.95}\n",
      "{'loss': 0.0543, 'learning_rate': 0.00017260111827741248, 'epoch': 5.93}\n",
      "{'loss': 0.0368, 'learning_rate': 6.153218759696687e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 35.5935, 'train_samples_per_second': 510.515, 'train_steps_per_second': 63.972, 'train_loss': 0.13731724764623293, 'epoch': 9.0}\n",
      "{'eval_loss': 0.06525465846061707, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.8181818181818182, 'eval_precision': 1.0, 'eval_f1': 0.9, 'eval_runtime': 4.3807, 'eval_samples_per_second': 115.051, 'eval_steps_per_second': 14.381, 'epoch': 9.0}\n",
      "{'loss': 0.2437, 'learning_rate': 0.00039473897963830375, 'epoch': 1.98}\n",
      "{'loss': 0.1248, 'learning_rate': 0.0002836700489578581, 'epoch': 3.95}\n",
      "{'loss': 0.0792, 'learning_rate': 0.00017260111827741248, 'epoch': 5.93}\n",
      "{'loss': 0.097, 'learning_rate': 6.153218759696687e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 43.0957, 'train_samples_per_second': 421.643, 'train_steps_per_second': 52.836, 'train_loss': 0.12605262106324583, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:48:58,804] Trial 23 finished with value: 0.7670175438596492 and parameters: {'learning_rate': 0.0005058079103187494, 'weight_decay': 0.005868233964609601, 'num_train_epochs': 9}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.026206234470009804, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.8181818181818182, 'eval_precision': 1.0, 'eval_f1': 0.9, 'eval_runtime': 3.3309, 'eval_samples_per_second': 151.31, 'eval_steps_per_second': 18.914, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6518, 'learning_rate': 9.256232541200551e-05, 'epoch': 1.98}\n",
      "{'loss': 0.4069, 'learning_rate': 5.6149136815622546e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2805, 'learning_rate': 1.973594821923957e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 32.3537, 'train_samples_per_second': 436.611, 'train_steps_per_second': 54.739, 'train_loss': 0.40884442062851806, 'epoch': 7.0}\n",
      "{'eval_loss': 0.163301020860672, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.4166666666666667, 'eval_precision': 0.625, 'eval_f1': 0.5, 'eval_runtime': 4.3677, 'eval_samples_per_second': 115.621, 'eval_steps_per_second': 14.653, 'epoch': 7.0}\n",
      "{'loss': 0.2926, 'learning_rate': 9.256232541200551e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1418, 'learning_rate': 5.6149136815622546e-05, 'epoch': 3.95}\n",
      "{'loss': 0.062, 'learning_rate': 1.973594821923957e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 30.6333, 'train_samples_per_second': 461.133, 'train_steps_per_second': 57.813, 'train_loss': 0.15324895870611535, 'epoch': 7.0}\n",
      "{'eval_loss': 0.16195447742938995, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.802, 'eval_samples_per_second': 132.824, 'eval_steps_per_second': 16.833, 'epoch': 7.0}\n",
      "{'loss': 0.189, 'learning_rate': 9.256232541200551e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0495, 'learning_rate': 5.6149136815622546e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0182, 'learning_rate': 1.973594821923957e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 28.7986, 'train_samples_per_second': 490.51, 'train_steps_per_second': 61.496, 'train_loss': 0.07721367830075092, 'epoch': 7.0}\n",
      "{'eval_loss': 0.02778732031583786, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.8333333333333334, 'eval_precision': 1.0, 'eval_f1': 0.9090909090909091, 'eval_runtime': 4.1192, 'eval_samples_per_second': 122.595, 'eval_steps_per_second': 15.537, 'epoch': 7.0}\n",
      "{'loss': 0.1055, 'learning_rate': 9.256232541200551e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0291, 'learning_rate': 5.6149136815622546e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0145, 'learning_rate': 1.973594821923957e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 28.5999, 'train_samples_per_second': 494.163, 'train_steps_per_second': 61.923, 'train_loss': 0.0420869899145104, 'epoch': 7.0}\n",
      "{'eval_loss': 0.029479434713721275, 'eval_accuracy': 0.996031746031746, 'eval_recall': 1.0, 'eval_precision': 0.8461538461538461, 'eval_f1': 0.9166666666666666, 'eval_runtime': 3.8301, 'eval_samples_per_second': 131.591, 'eval_steps_per_second': 16.449, 'epoch': 7.0}\n",
      "{'loss': 0.0412, 'learning_rate': 9.256232541200551e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0158, 'learning_rate': 5.6149136815622546e-05, 'epoch': 3.95}\n",
      "{'loss': 0.002, 'learning_rate': 1.973594821923957e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 29.7058, 'train_samples_per_second': 475.766, 'train_steps_per_second': 59.618, 'train_loss': 0.01666012807643511, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:52:09,761] Trial 24 finished with value: 0.7732747644512351 and parameters: {'learning_rate': 0.00012897551400838848, 'weight_decay': 0.002463675633151658, 'num_train_epochs': 7}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03471343591809273, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.9559, 'eval_samples_per_second': 127.406, 'eval_steps_per_second': 15.926, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.687, 'learning_rate': 0.00020281071456198225, 'epoch': 1.98}\n",
      "{'loss': 0.3812, 'learning_rate': 0.0001457452349440919, 'epoch': 3.95}\n",
      "{'loss': 0.212, 'learning_rate': 8.867975532620158e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1629, 'learning_rate': 3.161427570831124e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.2792, 'train_samples_per_second': 462.382, 'train_steps_per_second': 57.97, 'train_loss': 0.33011305117533823, 'epoch': 9.0}\n",
      "{'eval_loss': 0.17361803352832794, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.6363636363636364, 'eval_f1': 0.6086956521739131, 'eval_runtime': 3.9637, 'eval_samples_per_second': 127.408, 'eval_steps_per_second': 16.147, 'epoch': 9.0}\n",
      "{'loss': 0.3027, 'learning_rate': 0.00020281071456198225, 'epoch': 1.98}\n",
      "{'loss': 0.1004, 'learning_rate': 0.0001457452349440919, 'epoch': 3.95}\n",
      "{'loss': 0.0339, 'learning_rate': 8.867975532620158e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0035, 'learning_rate': 3.161427570831124e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 38.9519, 'train_samples_per_second': 466.267, 'train_steps_per_second': 58.457, 'train_loss': 0.09676906007080681, 'epoch': 9.0}\n",
      "{'eval_loss': 0.17920945584774017, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 4.0217, 'eval_samples_per_second': 125.567, 'eval_steps_per_second': 15.913, 'epoch': 9.0}\n",
      "{'loss': 0.1592, 'learning_rate': 0.00020281071456198225, 'epoch': 1.98}\n",
      "{'loss': 0.1043, 'learning_rate': 0.0001457452349440919, 'epoch': 3.95}\n",
      "{'loss': 0.0612, 'learning_rate': 8.867975532620158e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0199, 'learning_rate': 3.161427570831124e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.1791, 'train_samples_per_second': 463.563, 'train_steps_per_second': 58.118, 'train_loss': 0.07569858819233204, 'epoch': 9.0}\n",
      "{'eval_loss': 0.0007958991336636245, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 3.7843, 'eval_samples_per_second': 133.446, 'eval_steps_per_second': 16.912, 'epoch': 9.0}\n",
      "{'loss': 0.1067, 'learning_rate': 0.00020281071456198225, 'epoch': 1.98}\n",
      "{'loss': 0.0229, 'learning_rate': 0.0001457452349440919, 'epoch': 3.95}\n",
      "{'loss': 0.0092, 'learning_rate': 8.867975532620158e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0114, 'learning_rate': 3.161427570831124e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 34.3184, 'train_samples_per_second': 529.482, 'train_steps_per_second': 66.349, 'train_loss': 0.033039116845038775, 'epoch': 9.0}\n",
      "{'eval_loss': 8.418921424890868e-06, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 4.1196, 'eval_samples_per_second': 122.341, 'eval_steps_per_second': 15.293, 'epoch': 9.0}\n",
      "{'loss': 0.1184, 'learning_rate': 0.00020281071456198225, 'epoch': 1.98}\n",
      "{'loss': 0.0557, 'learning_rate': 0.0001457452349440919, 'epoch': 3.95}\n",
      "{'loss': 0.0032, 'learning_rate': 8.867975532620158e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0003, 'learning_rate': 3.161427570831124e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.3191, 'train_samples_per_second': 462.142, 'train_steps_per_second': 57.911, 'train_loss': 0.039043038990225876, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:56:01,323] Trial 25 finished with value: 0.8595837419636047 and parameters: {'learning_rate': 0.00025987619417987257, 'weight_decay': 0.0010315325907121007, 'num_train_epochs': 9}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.021524859592318535, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.7437, 'eval_samples_per_second': 134.625, 'eval_steps_per_second': 16.828, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6528, 'learning_rate': 0.0001812590659824179, 'epoch': 1.98}\n",
      "{'loss': 0.3824, 'learning_rate': 0.00012179086848162461, 'epoch': 3.95}\n",
      "{'loss': 0.2018, 'learning_rate': 6.232267098083135e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1131, 'learning_rate': 2.854473480038077e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.3478, 'train_samples_per_second': 470.015, 'train_steps_per_second': 58.927, 'train_loss': 0.33406305860860547, 'epoch': 8.0}\n",
      "{'eval_loss': 0.2243821918964386, 'eval_accuracy': 0.9782178217821782, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5384615384615384, 'eval_f1': 0.5599999999999999, 'eval_runtime': 4.233, 'eval_samples_per_second': 119.302, 'eval_steps_per_second': 15.119, 'epoch': 8.0}\n",
      "{'loss': 0.2547, 'learning_rate': 0.0001812590659824179, 'epoch': 1.98}\n",
      "{'loss': 0.0835, 'learning_rate': 0.00012179086848162461, 'epoch': 3.95}\n",
      "{'loss': 0.0264, 'learning_rate': 6.232267098083135e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0242, 'learning_rate': 2.854473480038077e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.5676, 'train_samples_per_second': 453.896, 'train_steps_per_second': 56.906, 'train_loss': 0.09605921117226288, 'epoch': 8.0}\n",
      "{'eval_loss': 0.1395559161901474, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 4.1838, 'eval_samples_per_second': 120.705, 'eval_steps_per_second': 15.297, 'epoch': 8.0}\n",
      "{'loss': 0.1481, 'learning_rate': 0.0001812590659824179, 'epoch': 1.98}\n",
      "{'loss': 0.0465, 'learning_rate': 0.00012179086848162461, 'epoch': 3.95}\n",
      "{'loss': 0.0187, 'learning_rate': 6.232267098083135e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0006, 'learning_rate': 2.854473480038077e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 36.6763, 'train_samples_per_second': 440.175, 'train_steps_per_second': 55.185, 'train_loss': 0.05284852936153904, 'epoch': 8.0}\n",
      "{'eval_loss': 3.543898856150918e-05, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 4.687, 'eval_samples_per_second': 107.745, 'eval_steps_per_second': 13.655, 'epoch': 8.0}\n",
      "{'loss': 0.1195, 'learning_rate': 0.0001812590659824179, 'epoch': 1.98}\n",
      "{'loss': 0.0571, 'learning_rate': 0.00012179086848162461, 'epoch': 3.95}\n",
      "{'loss': 0.0148, 'learning_rate': 6.232267098083135e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0002, 'learning_rate': 2.854473480038077e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.1781, 'train_samples_per_second': 459.15, 'train_steps_per_second': 57.536, 'train_loss': 0.047332830567978344, 'epoch': 8.0}\n",
      "{'eval_loss': 0.018668752163648605, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.7459, 'eval_samples_per_second': 134.547, 'eval_steps_per_second': 16.818, 'epoch': 8.0}\n",
      "{'loss': 0.0707, 'learning_rate': 0.0001812590659824179, 'epoch': 1.98}\n",
      "{'loss': 0.0498, 'learning_rate': 0.00012179086848162461, 'epoch': 3.95}\n",
      "{'loss': 0.0001, 'learning_rate': 6.232267098083135e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.854473480038077e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 40.8192, 'train_samples_per_second': 395.696, 'train_steps_per_second': 49.585, 'train_loss': 0.02979805420534241, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:59:46,914] Trial 26 finished with value: 0.8411489593549091 and parameters: {'learning_rate': 0.00024072726348321118, 'weight_decay': 0.0008559505656596687, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.013256501406431198, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.4266, 'eval_samples_per_second': 147.085, 'eval_steps_per_second': 18.386, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6757, 'learning_rate': 6.285623955782027e-05, 'epoch': 1.98}\n",
      "{'loss': 0.4815, 'learning_rate': 4.517018453311001e-05, 'epoch': 3.95}\n",
      "{'loss': 0.3963, 'learning_rate': 2.7484129508399745e-05, 'epoch': 5.93}\n",
      "{'loss': 0.3215, 'learning_rate': 9.798074483689485e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 45.0615, 'train_samples_per_second': 403.049, 'train_steps_per_second': 50.531, 'train_loss': 0.44908691258822087, 'epoch': 9.0}\n",
      "{'eval_loss': 0.16710777580738068, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.4166666666666667, 'eval_precision': 0.625, 'eval_f1': 0.5, 'eval_runtime': 3.3766, 'eval_samples_per_second': 149.56, 'eval_steps_per_second': 18.954, 'epoch': 9.0}\n",
      "{'loss': 0.3185, 'learning_rate': 6.285623955782027e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1813, 'learning_rate': 4.517018453311001e-05, 'epoch': 3.95}\n",
      "{'loss': 0.1313, 'learning_rate': 2.7484129508399745e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1026, 'learning_rate': 9.798074483689485e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 45.9063, 'train_samples_per_second': 395.632, 'train_steps_per_second': 49.601, 'train_loss': 0.16957830011085506, 'epoch': 9.0}\n",
      "{'eval_loss': 0.18143512308597565, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.8591, 'eval_samples_per_second': 130.859, 'eval_steps_per_second': 16.584, 'epoch': 9.0}\n",
      "{'loss': 0.223, 'learning_rate': 6.285623955782027e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0934, 'learning_rate': 4.517018453311001e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0546, 'learning_rate': 2.7484129508399745e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0301, 'learning_rate': 9.798074483689485e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 46.8192, 'train_samples_per_second': 387.918, 'train_steps_per_second': 48.634, 'train_loss': 0.09179449479308734, 'epoch': 9.0}\n",
      "{'eval_loss': 0.011989705264568329, 'eval_accuracy': 0.998019801980198, 'eval_recall': 0.9166666666666666, 'eval_precision': 1.0, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.6232, 'eval_samples_per_second': 139.378, 'eval_steps_per_second': 17.664, 'epoch': 9.0}\n",
      "{'loss': 0.1215, 'learning_rate': 6.285623955782027e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0577, 'learning_rate': 4.517018453311001e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0116, 'learning_rate': 2.7484129508399745e-05, 'epoch': 5.93}\n",
      "{'loss': 0.002, 'learning_rate': 9.798074483689485e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 40.5818, 'train_samples_per_second': 447.763, 'train_steps_per_second': 56.109, 'train_loss': 0.042347404758781716, 'epoch': 9.0}\n",
      "{'eval_loss': 0.026887496933341026, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.233, 'eval_samples_per_second': 155.891, 'eval_steps_per_second': 19.486, 'epoch': 9.0}\n",
      "{'loss': 0.0373, 'learning_rate': 6.285623955782027e-05, 'epoch': 1.98}\n",
      "{'loss': 0.066, 'learning_rate': 4.517018453311001e-05, 'epoch': 3.95}\n",
      "{'loss': 0.01, 'learning_rate': 2.7484129508399745e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 9.798074483689485e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 46.3286, 'train_samples_per_second': 392.22, 'train_steps_per_second': 49.149, 'train_loss': 0.026031901388108847, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:04:09,403] Trial 27 finished with value: 0.7969320534537927 and parameters: {'learning_rate': 8.054229458253053e-05, 'weight_decay': 0.0004550302766717642, 'num_train_epochs': 9}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03537813946604729, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.3708, 'eval_samples_per_second': 149.519, 'eval_steps_per_second': 18.69, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6355, 'learning_rate': 0.00012210104169115303, 'epoch': 1.98}\n",
      "{'loss': 0.3762, 'learning_rate': 8.204164481085348e-05, 'epoch': 3.95}\n",
      "{'loss': 0.224, 'learning_rate': 4.1982247930553934e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1573, 'learning_rate': 1.9228510502543783e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 40.6011, 'train_samples_per_second': 397.625, 'train_steps_per_second': 49.851, 'train_loss': 0.3452305281350735, 'epoch': 8.0}\n",
      "{'eval_loss': 0.18303821980953217, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5, 'eval_precision': 0.6, 'eval_f1': 0.5454545454545454, 'eval_runtime': 4.0497, 'eval_samples_per_second': 124.702, 'eval_steps_per_second': 15.804, 'epoch': 8.0}\n",
      "{'loss': 0.3018, 'learning_rate': 0.00012210104169115303, 'epoch': 1.98}\n",
      "{'loss': 0.0903, 'learning_rate': 8.204164481085348e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0351, 'learning_rate': 4.1982247930553934e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0111, 'learning_rate': 1.9228510502543783e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.5438, 'train_samples_per_second': 454.2, 'train_steps_per_second': 56.944, 'train_loss': 0.10828670415578211, 'epoch': 8.0}\n",
      "{'eval_loss': 0.16533122956752777, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 4.0053, 'eval_samples_per_second': 126.084, 'eval_steps_per_second': 15.979, 'epoch': 8.0}\n",
      "{'loss': 0.128, 'learning_rate': 0.00012210104169115303, 'epoch': 1.98}\n",
      "{'loss': 0.0399, 'learning_rate': 8.204164481085348e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0287, 'learning_rate': 4.1982247930553934e-05, 'epoch': 5.93}\n",
      "{'loss': 0.001, 'learning_rate': 1.9228510502543783e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.5422, 'train_samples_per_second': 454.221, 'train_steps_per_second': 56.946, 'train_loss': 0.04880201291890397, 'epoch': 8.0}\n",
      "{'eval_loss': 5.7136381656164303e-05, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 4.1009, 'eval_samples_per_second': 123.143, 'eval_steps_per_second': 15.606, 'epoch': 8.0}\n",
      "{'loss': 0.0776, 'learning_rate': 0.00012210104169115303, 'epoch': 1.98}\n",
      "{'loss': 0.0674, 'learning_rate': 8.204164481085348e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0277, 'learning_rate': 4.1982247930553934e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0009, 'learning_rate': 1.9228510502543783e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 31.6965, 'train_samples_per_second': 509.584, 'train_steps_per_second': 63.856, 'train_loss': 0.04289542914239064, 'epoch': 8.0}\n",
      "{'eval_loss': 0.02525922656059265, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.7039, 'eval_samples_per_second': 136.075, 'eval_steps_per_second': 17.009, 'epoch': 8.0}\n",
      "{'loss': 0.0238, 'learning_rate': 0.00012210104169115303, 'epoch': 1.98}\n",
      "{'loss': 0.0393, 'learning_rate': 8.204164481085348e-05, 'epoch': 3.95}\n",
      "{'loss': 0.015, 'learning_rate': 4.1982247930553934e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0002, 'learning_rate': 1.9228510502543783e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.4847, 'train_samples_per_second': 482.37, 'train_steps_per_second': 60.446, 'train_loss': 0.01935130377673095, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:07:46,340] Trial 28 finished with value: 0.8382398684458181 and parameters: {'learning_rate': 0.0001621604385714526, 'weight_decay': 0.0010302890161730603, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.022622711956501007, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.6123, 'eval_samples_per_second': 139.523, 'eval_steps_per_second': 17.44, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6531, 'learning_rate': 0.00015258875096570525, 'epoch': 1.98}\n",
      "{'loss': 0.3826, 'learning_rate': 9.25617049524459e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2255, 'learning_rate': 3.2534658939186565e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 35.1122, 'train_samples_per_second': 402.31, 'train_steps_per_second': 50.438, 'train_loss': 0.382750504169001, 'epoch': 7.0}\n",
      "{'eval_loss': 0.18413634598255157, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.6363636363636364, 'eval_f1': 0.6086956521739131, 'eval_runtime': 3.3715, 'eval_samples_per_second': 149.787, 'eval_steps_per_second': 18.983, 'epoch': 7.0}\n",
      "{'loss': 0.2962, 'learning_rate': 0.00015258875096570525, 'epoch': 1.98}\n",
      "{'loss': 0.1039, 'learning_rate': 9.25617049524459e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0439, 'learning_rate': 3.2534658939186565e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 32.6095, 'train_samples_per_second': 433.186, 'train_steps_per_second': 54.309, 'train_loss': 0.12561674253675373, 'epoch': 7.0}\n",
      "{'eval_loss': 0.1558654010295868, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.7884, 'eval_samples_per_second': 133.301, 'eval_steps_per_second': 16.894, 'epoch': 7.0}\n",
      "{'loss': 0.1642, 'learning_rate': 0.00015258875096570525, 'epoch': 1.98}\n",
      "{'loss': 0.0403, 'learning_rate': 9.25617049524459e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0071, 'learning_rate': 3.2534658939186565e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 29.867, 'train_samples_per_second': 472.963, 'train_steps_per_second': 59.296, 'train_loss': 0.05994760537470619, 'epoch': 7.0}\n",
      "{'eval_loss': 0.01432446576654911, 'eval_accuracy': 0.998019801980198, 'eval_recall': 1.0, 'eval_precision': 0.9230769230769231, 'eval_f1': 0.9600000000000001, 'eval_runtime': 4.0223, 'eval_samples_per_second': 125.55, 'eval_steps_per_second': 15.911, 'epoch': 7.0}\n",
      "{'loss': 0.1063, 'learning_rate': 0.00015258875096570525, 'epoch': 1.98}\n",
      "{'loss': 0.017, 'learning_rate': 9.25617049524459e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0198, 'learning_rate': 3.2534658939186565e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 26.8089, 'train_samples_per_second': 527.176, 'train_steps_per_second': 66.06, 'train_loss': 0.04138120791792264, 'epoch': 7.0}\n",
      "{'eval_loss': 0.023163840174674988, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.159, 'eval_samples_per_second': 121.183, 'eval_steps_per_second': 15.148, 'epoch': 7.0}\n",
      "{'loss': 0.0787, 'learning_rate': 0.00015258875096570525, 'epoch': 1.98}\n",
      "{'loss': 0.0511, 'learning_rate': 9.25617049524459e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0028, 'learning_rate': 3.2534658939186565e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 29.7149, 'train_samples_per_second': 475.62, 'train_steps_per_second': 59.6, 'train_loss': 0.03745042073647142, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:11:00,573] Trial 29 finished with value: 0.8288530020703935 and parameters: {'learning_rate': 0.00021261579697896458, 'weight_decay': 0.0003399680087934945, 'num_train_epochs': 7}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.023858852684497833, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.8559, 'eval_samples_per_second': 130.709, 'eval_steps_per_second': 16.339, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7596, 'learning_rate': 0.0004976334802805095, 'epoch': 1.98}\n",
      "{'loss': 0.6885, 'learning_rate': 0.0003576128049061399, 'epoch': 3.95}\n",
      "{'loss': 0.4747, 'learning_rate': 0.0002175921295317703, 'epoch': 5.93}\n",
      "{'loss': 0.4098, 'learning_rate': 7.757145415740074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 40.1509, 'train_samples_per_second': 452.343, 'train_steps_per_second': 56.711, 'train_loss': 0.5537934401708577, 'epoch': 9.0}\n",
      "{'eval_loss': 0.17693516612052917, 'eval_accuracy': 0.9782178217821782, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5384615384615384, 'eval_f1': 0.5599999999999999, 'eval_runtime': 3.6772, 'eval_samples_per_second': 137.331, 'eval_steps_per_second': 17.404, 'epoch': 9.0}\n",
      "{'loss': 0.6414, 'learning_rate': 0.0004976334802805095, 'epoch': 1.98}\n",
      "{'loss': 0.4986, 'learning_rate': 0.0003576128049061399, 'epoch': 3.95}\n",
      "{'loss': 0.3802, 'learning_rate': 0.0002175921295317703, 'epoch': 5.93}\n",
      "{'loss': 0.3251, 'learning_rate': 7.757145415740074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 42.314, 'train_samples_per_second': 429.219, 'train_steps_per_second': 53.812, 'train_loss': 0.43152080463850034, 'epoch': 9.0}\n",
      "{'eval_loss': 0.1797298789024353, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.3333333333333333, 'eval_precision': 0.6666666666666666, 'eval_f1': 0.4444444444444444, 'eval_runtime': 3.7388, 'eval_samples_per_second': 135.068, 'eval_steps_per_second': 17.118, 'epoch': 9.0}\n",
      "{'loss': 0.5731, 'learning_rate': 0.0004976334802805095, 'epoch': 1.98}\n",
      "{'loss': 0.4772, 'learning_rate': 0.0003576128049061399, 'epoch': 3.95}\n",
      "{'loss': 0.412, 'learning_rate': 0.0002175921295317703, 'epoch': 5.93}\n",
      "{'loss': 0.4112, 'learning_rate': 7.757145415740074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 43.3035, 'train_samples_per_second': 419.412, 'train_steps_per_second': 52.582, 'train_loss': 0.45491408464099214, 'epoch': 9.0}\n",
      "{'eval_loss': 0.08810976147651672, 'eval_accuracy': 0.9920792079207921, 'eval_recall': 0.6666666666666666, 'eval_precision': 1.0, 'eval_f1': 0.8, 'eval_runtime': 3.4296, 'eval_samples_per_second': 147.248, 'eval_steps_per_second': 18.661, 'epoch': 9.0}\n",
      "{'loss': 0.5094, 'learning_rate': 0.0004976334802805095, 'epoch': 1.98}\n",
      "{'loss': 0.4643, 'learning_rate': 0.0003576128049061399, 'epoch': 3.95}\n",
      "{'loss': 0.3241, 'learning_rate': 0.0002175921295317703, 'epoch': 5.93}\n",
      "{'loss': 0.3078, 'learning_rate': 7.757145415740074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 43.1157, 'train_samples_per_second': 421.447, 'train_steps_per_second': 52.811, 'train_loss': 0.38546119324722256, 'epoch': 9.0}\n",
      "{'eval_loss': 0.14589688181877136, 'eval_accuracy': 0.9861111111111112, 'eval_recall': 0.45454545454545453, 'eval_precision': 0.8333333333333334, 'eval_f1': 0.5882352941176471, 'eval_runtime': 4.1005, 'eval_samples_per_second': 122.912, 'eval_steps_per_second': 15.364, 'epoch': 9.0}\n",
      "{'loss': 0.3936, 'learning_rate': 0.0004976334802805095, 'epoch': 1.98}\n",
      "{'loss': 0.3977, 'learning_rate': 0.0003576128049061399, 'epoch': 3.95}\n",
      "{'loss': 0.3086, 'learning_rate': 0.0002175921295317703, 'epoch': 5.93}\n",
      "{'loss': 0.3013, 'learning_rate': 7.757145415740074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 46.7135, 'train_samples_per_second': 388.988, 'train_steps_per_second': 48.744, 'train_loss': 0.33420997153890725, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:15:15,758] Trial 30 finished with value: 0.5785359477124182 and parameters: {'learning_rate': 0.000637654155654879, 'weight_decay': 0.0009381305031932445, 'num_train_epochs': 9}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13738617300987244, 'eval_accuracy': 0.9801587301587301, 'eval_recall': 0.45454545454545453, 'eval_precision': 0.5555555555555556, 'eval_f1': 0.5, 'eval_runtime': 3.5806, 'eval_samples_per_second': 140.758, 'eval_steps_per_second': 17.595, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6474, 'learning_rate': 0.00010256490410621743, 'epoch': 1.98}\n",
      "{'loss': 0.3971, 'learning_rate': 6.891500118423008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.259, 'learning_rate': 3.526509826224274e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1748, 'learning_rate': 1.6151953402553923e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 36.6457, 'train_samples_per_second': 440.543, 'train_steps_per_second': 55.232, 'train_loss': 0.36565201384983514, 'epoch': 8.0}\n",
      "{'eval_loss': 0.17006607353687286, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5, 'eval_precision': 0.6, 'eval_f1': 0.5454545454545454, 'eval_runtime': 3.8287, 'eval_samples_per_second': 131.899, 'eval_steps_per_second': 16.716, 'epoch': 8.0}\n",
      "{'loss': 0.297, 'learning_rate': 0.00010256490410621743, 'epoch': 1.98}\n",
      "{'loss': 0.1234, 'learning_rate': 6.891500118423008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0348, 'learning_rate': 3.526509826224274e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0306, 'learning_rate': 1.6151953402553923e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.261, 'train_samples_per_second': 457.844, 'train_steps_per_second': 57.401, 'train_loss': 0.12002336852581023, 'epoch': 8.0}\n",
      "{'eval_loss': 0.14833495020866394, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.5245, 'eval_samples_per_second': 143.283, 'eval_steps_per_second': 18.159, 'epoch': 8.0}\n",
      "{'loss': 0.1157, 'learning_rate': 0.00010256490410621743, 'epoch': 1.98}\n",
      "{'loss': 0.0292, 'learning_rate': 6.891500118423008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0071, 'learning_rate': 3.526509826224274e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0067, 'learning_rate': 1.6151953402553923e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.7877, 'train_samples_per_second': 477.808, 'train_steps_per_second': 59.904, 'train_loss': 0.03920772606060608, 'epoch': 8.0}\n",
      "{'eval_loss': 0.0022448429372161627, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 4.6293, 'eval_samples_per_second': 109.089, 'eval_steps_per_second': 13.825, 'epoch': 8.0}\n",
      "{'loss': 0.0805, 'learning_rate': 0.00010256490410621743, 'epoch': 1.98}\n",
      "{'loss': 0.0184, 'learning_rate': 6.891500118423008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0011, 'learning_rate': 3.526509826224274e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0125, 'learning_rate': 1.6151953402553923e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 32.2314, 'train_samples_per_second': 501.127, 'train_steps_per_second': 62.796, 'train_loss': 0.02779604022354128, 'epoch': 8.0}\n",
      "{'eval_loss': 0.028173105791211128, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.1136, 'eval_samples_per_second': 122.522, 'eval_steps_per_second': 15.315, 'epoch': 8.0}\n",
      "{'loss': 0.0173, 'learning_rate': 0.00010256490410621743, 'epoch': 1.98}\n",
      "{'loss': 0.0466, 'learning_rate': 6.891500118423008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0005, 'learning_rate': 3.526509826224274e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0002, 'learning_rate': 1.6151953402553923e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.9462, 'train_samples_per_second': 475.811, 'train_steps_per_second': 59.624, 'train_loss': 0.015924374035075347, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:18:49,232] Trial 31 finished with value: 0.8242047807265198 and parameters: {'learning_rate': 0.00013621480702820477, 'weight_decay': 0.0011007519511578529, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0320654958486557, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.5297, 'eval_samples_per_second': 142.787, 'eval_steps_per_second': 17.848, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6606, 'learning_rate': 0.0001770327159640033, 'epoch': 1.98}\n",
      "{'loss': 0.359, 'learning_rate': 0.00010738963336604762, 'epoch': 3.95}\n",
      "{'loss': 0.2142, 'learning_rate': 3.774655076809197e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 31.6311, 'train_samples_per_second': 446.586, 'train_steps_per_second': 55.989, 'train_loss': 0.37075520261810835, 'epoch': 7.0}\n",
      "{'eval_loss': 0.16970349848270416, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5, 'eval_precision': 0.6666666666666666, 'eval_f1': 0.5714285714285715, 'eval_runtime': 3.5336, 'eval_samples_per_second': 142.912, 'eval_steps_per_second': 18.112, 'epoch': 7.0}\n",
      "{'loss': 0.2723, 'learning_rate': 0.0001770327159640033, 'epoch': 1.98}\n",
      "{'loss': 0.1028, 'learning_rate': 0.00010738963336604762, 'epoch': 3.95}\n",
      "{'loss': 0.0502, 'learning_rate': 3.774655076809197e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 33.3136, 'train_samples_per_second': 424.032, 'train_steps_per_second': 53.162, 'train_loss': 0.1257699673489485, 'epoch': 7.0}\n",
      "{'eval_loss': 0.1272544413805008, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.7697, 'eval_samples_per_second': 133.964, 'eval_steps_per_second': 16.978, 'epoch': 7.0}\n",
      "{'loss': 0.1845, 'learning_rate': 0.0001770327159640033, 'epoch': 1.98}\n",
      "{'loss': 0.0745, 'learning_rate': 0.00010738963336604762, 'epoch': 3.95}\n",
      "{'loss': 0.0326, 'learning_rate': 3.774655076809197e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 35.9221, 'train_samples_per_second': 393.24, 'train_steps_per_second': 49.301, 'train_loss': 0.08244773619327082, 'epoch': 7.0}\n",
      "{'eval_loss': 0.034939005970954895, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.8333333333333334, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.8695652173913043, 'eval_runtime': 3.6271, 'eval_samples_per_second': 139.228, 'eval_steps_per_second': 17.645, 'epoch': 7.0}\n",
      "{'loss': 0.1326, 'learning_rate': 0.0001770327159640033, 'epoch': 1.98}\n",
      "{'loss': 0.0147, 'learning_rate': 0.00010738963336604762, 'epoch': 3.95}\n",
      "{'loss': 0.0005, 'learning_rate': 3.774655076809197e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 30.3584, 'train_samples_per_second': 465.539, 'train_steps_per_second': 58.336, 'train_loss': 0.04171855942273059, 'epoch': 7.0}\n",
      "{'eval_loss': 0.022952839732170105, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.062, 'eval_samples_per_second': 124.078, 'eval_steps_per_second': 15.51, 'epoch': 7.0}\n",
      "{'loss': 0.0773, 'learning_rate': 0.0001770327159640033, 'epoch': 1.98}\n",
      "{'loss': 0.0641, 'learning_rate': 0.00010738963336604762, 'epoch': 3.95}\n",
      "{'loss': 0.0193, 'learning_rate': 3.774655076809197e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 29.6847, 'train_samples_per_second': 476.104, 'train_steps_per_second': 59.66, 'train_loss': 0.04535925177565946, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:22:09,172] Trial 32 finished with value: 0.7728364389233955 and parameters: {'learning_rate': 0.00024667579856195893, 'weight_decay': 0.0008142509932181491, 'num_train_epochs': 7}. Best is trial 25 with value: 0.8595837419636047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07266197353601456, 'eval_accuracy': 0.9920634920634921, 'eval_recall': 0.7272727272727273, 'eval_precision': 0.8888888888888888, 'eval_f1': 0.7999999999999999, 'eval_runtime': 3.4998, 'eval_samples_per_second': 144.008, 'eval_steps_per_second': 18.001, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.654, 'learning_rate': 0.00012368467683240657, 'epoch': 1.98}\n",
      "{'loss': 0.3987, 'learning_rate': 8.310571461705008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.238, 'learning_rate': 4.2526752401693594e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1593, 'learning_rate': 1.947790186337111e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.9898, 'train_samples_per_second': 474.966, 'train_steps_per_second': 59.547, 'train_loss': 0.35834459632105037, 'epoch': 8.0}\n",
      "{'eval_loss': 0.18634122610092163, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5833333333333334, 'eval_f1': 0.5833333333333334, 'eval_runtime': 3.7368, 'eval_samples_per_second': 135.141, 'eval_steps_per_second': 17.127, 'epoch': 8.0}\n",
      "{'loss': 0.2667, 'learning_rate': 0.00012368467683240657, 'epoch': 1.98}\n",
      "{'loss': 0.1024, 'learning_rate': 8.310571461705008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0392, 'learning_rate': 4.2526752401693594e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0063, 'learning_rate': 1.947790186337111e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.2343, 'train_samples_per_second': 485.763, 'train_steps_per_second': 60.901, 'train_loss': 0.1024024827295837, 'epoch': 8.0}\n",
      "{'eval_loss': 0.16576167941093445, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.8126, 'eval_samples_per_second': 132.454, 'eval_steps_per_second': 16.786, 'epoch': 8.0}\n",
      "{'loss': 0.175, 'learning_rate': 0.00012368467683240657, 'epoch': 1.98}\n",
      "{'loss': 0.0672, 'learning_rate': 8.310571461705008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0086, 'learning_rate': 4.2526752401693594e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0021, 'learning_rate': 1.947790186337111e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.1826, 'train_samples_per_second': 472.287, 'train_steps_per_second': 59.211, 'train_loss': 0.06250302632942772, 'epoch': 8.0}\n",
      "{'eval_loss': 0.0004216424422338605, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 4.8873, 'eval_samples_per_second': 103.328, 'eval_steps_per_second': 13.095, 'epoch': 8.0}\n",
      "{'loss': 0.0785, 'learning_rate': 0.00012368467683240657, 'epoch': 1.98}\n",
      "{'loss': 0.0306, 'learning_rate': 8.310571461705008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0013, 'learning_rate': 4.2526752401693594e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 1.947790186337111e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.2567, 'train_samples_per_second': 485.677, 'train_steps_per_second': 60.86, 'train_loss': 0.027285915036577804, 'epoch': 8.0}\n",
      "{'eval_loss': 0.02395235188305378, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.0152, 'eval_samples_per_second': 125.523, 'eval_steps_per_second': 15.69, 'epoch': 8.0}\n",
      "{'loss': 0.02, 'learning_rate': 0.00012368467683240657, 'epoch': 1.98}\n",
      "{'loss': 0.029, 'learning_rate': 8.310571461705008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0003, 'learning_rate': 4.2526752401693594e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 1.947790186337111e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.4826, 'train_samples_per_second': 468.41, 'train_steps_per_second': 58.696, 'train_loss': 0.012173378940958502, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:25:37,984] Trial 33 finished with value: 0.8317805383022774 and parameters: {'learning_rate': 0.00016426363904776305, 'weight_decay': 0.0012992515988882083, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.018556322902441025, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.3624, 'eval_samples_per_second': 149.892, 'eval_steps_per_second': 18.736, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6621, 'learning_rate': 0.00021980008925462195, 'epoch': 1.98}\n",
      "{'loss': 0.3696, 'learning_rate': 0.0001579542565999731, 'epoch': 3.95}\n",
      "{'loss': 0.1782, 'learning_rate': 9.610842394532429e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1457, 'learning_rate': 3.426259129067545e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.6295, 'train_samples_per_second': 458.295, 'train_steps_per_second': 57.457, 'train_loss': 0.3046903078316281, 'epoch': 9.0}\n",
      "{'eval_loss': 0.16943277418613434, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.6363636363636364, 'eval_f1': 0.6086956521739131, 'eval_runtime': 3.4321, 'eval_samples_per_second': 147.139, 'eval_steps_per_second': 18.647, 'epoch': 9.0}\n",
      "{'loss': 0.2509, 'learning_rate': 0.00021980008925462195, 'epoch': 1.98}\n",
      "{'loss': 0.1248, 'learning_rate': 0.0001579542565999731, 'epoch': 3.95}\n",
      "{'loss': 0.0724, 'learning_rate': 9.610842394532429e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0133, 'learning_rate': 3.426259129067545e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.5824, 'train_samples_per_second': 458.84, 'train_steps_per_second': 57.526, 'train_loss': 0.10249955653097213, 'epoch': 9.0}\n",
      "{'eval_loss': 0.17865198850631714, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 4.0227, 'eval_samples_per_second': 125.536, 'eval_steps_per_second': 15.91, 'epoch': 9.0}\n",
      "{'loss': 0.2085, 'learning_rate': 0.00021980008925462195, 'epoch': 1.98}\n",
      "{'loss': 0.0604, 'learning_rate': 0.0001579542565999731, 'epoch': 3.95}\n",
      "{'loss': 0.0114, 'learning_rate': 9.610842394532429e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0179, 'learning_rate': 3.426259129067545e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.1871, 'train_samples_per_second': 463.469, 'train_steps_per_second': 58.106, 'train_loss': 0.06598461302529839, 'epoch': 9.0}\n",
      "{'eval_loss': 0.11690743267536163, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.875, 'eval_f1': 0.7000000000000001, 'eval_runtime': 3.2569, 'eval_samples_per_second': 155.057, 'eval_steps_per_second': 19.651, 'epoch': 9.0}\n",
      "{'loss': 0.1332, 'learning_rate': 0.00021980008925462195, 'epoch': 1.98}\n",
      "{'loss': 0.0438, 'learning_rate': 0.0001579542565999731, 'epoch': 3.95}\n",
      "{'loss': 0.0212, 'learning_rate': 9.610842394532429e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0002, 'learning_rate': 3.426259129067545e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 34.8152, 'train_samples_per_second': 521.927, 'train_steps_per_second': 65.402, 'train_loss': 0.04357209376627592, 'epoch': 9.0}\n",
      "{'eval_loss': 0.021757803857326508, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.4987, 'eval_samples_per_second': 144.052, 'eval_steps_per_second': 18.007, 'epoch': 9.0}\n",
      "{'loss': 0.0927, 'learning_rate': 0.00021980008925462195, 'epoch': 1.98}\n",
      "{'loss': 0.0177, 'learning_rate': 0.0001579542565999731, 'epoch': 3.95}\n",
      "{'loss': 0.0152, 'learning_rate': 9.610842394532429e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0014, 'learning_rate': 3.426259129067545e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.8814, 'train_samples_per_second': 455.626, 'train_steps_per_second': 57.094, 'train_loss': 0.027880718278055244, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:29:39,000] Trial 34 finished with value: 0.7822300811316831 and parameters: {'learning_rate': 0.0002816459219092708, 'weight_decay': 0.00032983855007218067, 'num_train_epochs': 9}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0309719480574131, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.6587, 'eval_samples_per_second': 137.755, 'eval_steps_per_second': 17.219, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6553, 'learning_rate': 8.913374189854705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.4133, 'learning_rate': 5.4069327304311394e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2898, 'learning_rate': 1.900491271007573e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 33.0927, 'train_samples_per_second': 426.861, 'train_steps_per_second': 53.516, 'train_loss': 0.4157305393832878, 'epoch': 7.0}\n",
      "{'eval_loss': 0.16346041858196259, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.4166666666666667, 'eval_precision': 0.625, 'eval_f1': 0.5, 'eval_runtime': 3.4153, 'eval_samples_per_second': 147.864, 'eval_steps_per_second': 18.739, 'epoch': 7.0}\n",
      "{'loss': 0.3026, 'learning_rate': 8.913374189854705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1461, 'learning_rate': 5.4069327304311394e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0677, 'learning_rate': 1.900491271007573e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 34.9501, 'train_samples_per_second': 404.176, 'train_steps_per_second': 50.672, 'train_loss': 0.15895072488984033, 'epoch': 7.0}\n",
      "{'eval_loss': 0.16014181077480316, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.8862, 'eval_samples_per_second': 129.946, 'eval_steps_per_second': 16.468, 'epoch': 7.0}\n",
      "{'loss': 0.165, 'learning_rate': 8.913374189854705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0478, 'learning_rate': 5.4069327304311394e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0198, 'learning_rate': 1.900491271007573e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 20.262, 'train_samples_per_second': 697.166, 'train_steps_per_second': 87.405, 'train_loss': 0.0678844640377482, 'epoch': 7.0}\n",
      "{'eval_loss': 0.06640589237213135, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.75, 'eval_precision': 1.0, 'eval_f1': 0.8571428571428571, 'eval_runtime': 3.5212, 'eval_samples_per_second': 143.416, 'eval_steps_per_second': 18.175, 'epoch': 7.0}\n",
      "{'loss': 0.1182, 'learning_rate': 8.913374189854705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0382, 'learning_rate': 5.4069327304311394e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0024, 'learning_rate': 1.900491271007573e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 18.547, 'train_samples_per_second': 762.009, 'train_steps_per_second': 95.487, 'train_loss': 0.044865125736599246, 'epoch': 7.0}\n",
      "{'eval_loss': 0.026802022010087967, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.6459, 'eval_samples_per_second': 138.238, 'eval_steps_per_second': 17.28, 'epoch': 7.0}\n",
      "{'loss': 0.0054, 'learning_rate': 8.913374189854705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0141, 'learning_rate': 5.4069327304311394e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0069, 'learning_rate': 1.900491271007573e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 19.9055, 'train_samples_per_second': 710.005, 'train_steps_per_second': 88.97, 'train_loss': 0.0074444321924973045, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:32:24,627] Trial 35 finished with value: 0.7708561685543783 and parameters: {'learning_rate': 0.00012419815649278271, 'weight_decay': 0.0017164896408033608, 'num_train_epochs': 7}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.021779343485832214, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.8777, 'eval_samples_per_second': 129.973, 'eval_steps_per_second': 16.247, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7904, 'learning_rate': 0.0006576205405891412, 'epoch': 1.98}\n",
      "{'loss': 0.7232, 'learning_rate': 0.0004418657700546461, 'epoch': 3.95}\n",
      "{'loss': 0.7349, 'learning_rate': 0.00022611099952015093, 'epoch': 5.93}\n",
      "{'loss': 0.7241, 'learning_rate': 1.0356228985655767e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 23.5988, 'train_samples_per_second': 684.104, 'train_steps_per_second': 85.767, 'train_loss': 0.7442510363612722, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16800475120544434, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.3232, 'eval_samples_per_second': 151.961, 'eval_steps_per_second': 19.258, 'epoch': 8.0}\n",
      "{'loss': 0.8264, 'learning_rate': 0.0006576205405891412, 'epoch': 1.98}\n",
      "{'loss': 0.7294, 'learning_rate': 0.0004418657700546461, 'epoch': 3.95}\n",
      "{'loss': 0.7358, 'learning_rate': 0.00022611099952015093, 'epoch': 5.93}\n",
      "{'loss': 0.7313, 'learning_rate': 1.0356228985655767e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 22.7389, 'train_samples_per_second': 709.972, 'train_steps_per_second': 89.01, 'train_loss': 0.7568902809158145, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16930928826332092, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.2986, 'eval_samples_per_second': 153.095, 'eval_steps_per_second': 19.402, 'epoch': 8.0}\n",
      "{'loss': 0.8117, 'learning_rate': 0.0006576205405891412, 'epoch': 1.98}\n",
      "{'loss': 0.7182, 'learning_rate': 0.0004418657700546461, 'epoch': 3.95}\n",
      "{'loss': 0.727, 'learning_rate': 0.00022611099952015093, 'epoch': 5.93}\n",
      "{'loss': 0.7305, 'learning_rate': 1.0356228985655767e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 22.966, 'train_samples_per_second': 702.952, 'train_steps_per_second': 88.13, 'train_loss': 0.7482260884974785, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16935397684574127, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.7454, 'eval_samples_per_second': 134.833, 'eval_steps_per_second': 17.088, 'epoch': 8.0}\n",
      "{'loss': 0.765, 'learning_rate': 0.0006576205405891412, 'epoch': 1.98}\n",
      "{'loss': 0.7724, 'learning_rate': 0.0004418657700546461, 'epoch': 3.95}\n",
      "{'loss': 0.7338, 'learning_rate': 0.00022611099952015093, 'epoch': 5.93}\n",
      "{'loss': 0.7821, 'learning_rate': 1.0356228985655767e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 21.1395, 'train_samples_per_second': 764.069, 'train_steps_per_second': 95.745, 'train_loss': 0.7608768379264198, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16414913535118103, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.6467, 'eval_samples_per_second': 138.205, 'eval_steps_per_second': 17.276, 'epoch': 8.0}\n",
      "{'loss': 0.6709, 'learning_rate': 0.0006576205405891412, 'epoch': 1.98}\n",
      "{'loss': 0.6056, 'learning_rate': 0.0004418657700546461, 'epoch': 3.95}\n",
      "{'loss': 0.6059, 'learning_rate': 0.00022611099952015093, 'epoch': 5.93}\n",
      "{'loss': 0.5936, 'learning_rate': 1.0356228985655767e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 23.3864, 'train_samples_per_second': 690.659, 'train_steps_per_second': 86.546, 'train_loss': 0.6184067434001818, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:34:58,252] Trial 36 finished with value: 0.03333333333333334 and parameters: {'learning_rate': 0.0008733753111236364, 'weight_decay': 0.0006168822269633476, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16063062846660614, 'eval_accuracy': 0.9801587301587301, 'eval_recall': 0.09090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.16666666666666669, 'eval_runtime': 3.9025, 'eval_samples_per_second': 129.15, 'eval_steps_per_second': 16.144, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6437, 'learning_rate': 0.00010797077615458393, 'epoch': 1.98}\n",
      "{'loss': 0.3952, 'learning_rate': 5.49399430727647e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2638, 'learning_rate': 1.9091099909454917e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 18.0403, 'train_samples_per_second': 671.165, 'train_steps_per_second': 84.145, 'train_loss': 0.4319742426413635, 'epoch': 6.0}\n",
      "{'eval_loss': 0.16215327382087708, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5, 'eval_precision': 0.6, 'eval_f1': 0.5454545454545454, 'eval_runtime': 3.9871, 'eval_samples_per_second': 126.657, 'eval_steps_per_second': 16.052, 'epoch': 6.0}\n",
      "{'loss': 0.3467, 'learning_rate': 0.00010797077615458393, 'epoch': 1.98}\n",
      "{'loss': 0.1427, 'learning_rate': 5.49399430727647e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0549, 'learning_rate': 1.9091099909454917e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 17.5557, 'train_samples_per_second': 689.692, 'train_steps_per_second': 86.468, 'train_loss': 0.18306794939305, 'epoch': 6.0}\n",
      "{'eval_loss': 0.16851793229579926, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.3911, 'eval_samples_per_second': 148.92, 'eval_steps_per_second': 18.873, 'epoch': 6.0}\n",
      "{'loss': 0.1674, 'learning_rate': 0.00010797077615458393, 'epoch': 1.98}\n",
      "{'loss': 0.0675, 'learning_rate': 5.49399430727647e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0087, 'learning_rate': 1.9091099909454917e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 16.75, 'train_samples_per_second': 722.866, 'train_steps_per_second': 90.627, 'train_loss': 0.08025497249885903, 'epoch': 6.0}\n",
      "{'eval_loss': 0.02341589517891407, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.8333333333333334, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.8695652173913043, 'eval_runtime': 3.6932, 'eval_samples_per_second': 136.736, 'eval_steps_per_second': 17.329, 'epoch': 6.0}\n",
      "{'loss': 0.1047, 'learning_rate': 0.00010797077615458393, 'epoch': 1.98}\n",
      "{'loss': 0.0205, 'learning_rate': 5.49399430727647e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0007, 'learning_rate': 1.9091099909454917e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 15.4979, 'train_samples_per_second': 781.654, 'train_steps_per_second': 97.949, 'train_loss': 0.041485903288621354, 'epoch': 6.0}\n",
      "{'eval_loss': 0.02703866921365261, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.3874, 'eval_samples_per_second': 114.875, 'eval_steps_per_second': 14.359, 'epoch': 6.0}\n",
      "{'loss': 0.0372, 'learning_rate': 0.00010797077615458393, 'epoch': 1.98}\n",
      "{'loss': 0.0403, 'learning_rate': 5.49399430727647e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0001, 'learning_rate': 1.9091099909454917e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 18.0752, 'train_samples_per_second': 670.199, 'train_steps_per_second': 83.982, 'train_loss': 0.025569518087574575, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:37:03,939] Trial 37 finished with value: 0.7737735410369682 and parameters: {'learning_rate': 0.00016100160923640313, 'weight_decay': 0.0010141476938847955, 'num_train_epochs': 6}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03779217600822449, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.9865, 'eval_samples_per_second': 126.428, 'eval_steps_per_second': 15.803, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6559, 'learning_rate': 0.0001794441714881127, 'epoch': 1.98}\n",
      "{'loss': 0.3804, 'learning_rate': 0.0001088524439160778, 'epoch': 3.95}\n",
      "{'loss': 0.1852, 'learning_rate': 3.826071634404291e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 20.3711, 'train_samples_per_second': 693.432, 'train_steps_per_second': 86.937, 'train_loss': 0.36899274786201186, 'epoch': 7.0}\n",
      "{'eval_loss': 0.1881508082151413, 'eval_accuracy': 0.9782178217821782, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5384615384615384, 'eval_f1': 0.5599999999999999, 'eval_runtime': 4.0415, 'eval_samples_per_second': 124.954, 'eval_steps_per_second': 15.836, 'epoch': 7.0}\n",
      "{'loss': 0.3173, 'learning_rate': 0.0001794441714881127, 'epoch': 1.98}\n",
      "{'loss': 0.1151, 'learning_rate': 0.0001088524439160778, 'epoch': 3.95}\n",
      "{'loss': 0.0564, 'learning_rate': 3.826071634404291e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 19.7302, 'train_samples_per_second': 715.957, 'train_steps_per_second': 89.761, 'train_loss': 0.1385400003460691, 'epoch': 7.0}\n",
      "{'eval_loss': 0.17137880623340607, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 4.3801, 'eval_samples_per_second': 115.294, 'eval_steps_per_second': 14.612, 'epoch': 7.0}\n",
      "{'loss': 0.2032, 'learning_rate': 0.0001794441714881127, 'epoch': 1.98}\n",
      "{'loss': 0.0751, 'learning_rate': 0.0001088524439160778, 'epoch': 3.95}\n",
      "{'loss': 0.0301, 'learning_rate': 3.826071634404291e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 20.6923, 'train_samples_per_second': 682.67, 'train_steps_per_second': 85.587, 'train_loss': 0.087079581990207, 'epoch': 7.0}\n",
      "{'eval_loss': 0.01701604574918747, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.9166666666666666, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9166666666666666, 'eval_runtime': 3.7909, 'eval_samples_per_second': 133.213, 'eval_steps_per_second': 16.882, 'epoch': 7.0}\n",
      "{'loss': 0.1128, 'learning_rate': 0.0001794441714881127, 'epoch': 1.98}\n",
      "{'loss': 0.0648, 'learning_rate': 0.0001088524439160778, 'epoch': 3.95}\n",
      "{'loss': 0.0004, 'learning_rate': 3.826071634404291e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 19.3951, 'train_samples_per_second': 728.689, 'train_steps_per_second': 91.312, 'train_loss': 0.05026309650584862, 'epoch': 7.0}\n",
      "{'eval_loss': 0.018414532765746117, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.1454, 'eval_samples_per_second': 121.58, 'eval_steps_per_second': 15.197, 'epoch': 7.0}\n",
      "{'loss': 0.1295, 'learning_rate': 0.0001794441714881127, 'epoch': 1.98}\n",
      "{'loss': 0.0399, 'learning_rate': 0.0001088524439160778, 'epoch': 3.95}\n",
      "{'loss': 0.0036, 'learning_rate': 3.826071634404291e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 19.932, 'train_samples_per_second': 709.063, 'train_steps_per_second': 88.852, 'train_loss': 0.04882797271745276, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:39:25,671] Trial 38 finished with value: 0.8017891963109355 and parameters: {'learning_rate': 0.0002500358990601476, 'weight_decay': 0.00018119100191491065, 'num_train_epochs': 7}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02273561619222164, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.8096, 'eval_samples_per_second': 132.297, 'eval_steps_per_second': 16.537, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7507, 'learning_rate': 0.00043145629304222626, 'epoch': 1.98}\n",
      "{'loss': 0.5337, 'learning_rate': 0.0003100560980387861, 'epoch': 3.95}\n",
      "{'loss': 0.382, 'learning_rate': 0.00018865590303534597, 'epoch': 5.93}\n",
      "{'loss': 0.3027, 'learning_rate': 6.725570803190583e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 27.0906, 'train_samples_per_second': 670.418, 'train_steps_per_second': 84.051, 'train_loss': 0.4652224286481064, 'epoch': 9.0}\n",
      "{'eval_loss': 0.1426733434200287, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.875, 'eval_f1': 0.7000000000000001, 'eval_runtime': 3.8471, 'eval_samples_per_second': 131.269, 'eval_steps_per_second': 16.636, 'epoch': 9.0}\n",
      "{'loss': 0.4075, 'learning_rate': 0.00043145629304222626, 'epoch': 1.98}\n",
      "{'loss': 0.2508, 'learning_rate': 0.0003100560980387861, 'epoch': 3.95}\n",
      "{'loss': 0.2175, 'learning_rate': 0.00018865590303534597, 'epoch': 5.93}\n",
      "{'loss': 0.2357, 'learning_rate': 6.725570803190583e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 26.5824, 'train_samples_per_second': 683.233, 'train_steps_per_second': 85.658, 'train_loss': 0.26173723209935634, 'epoch': 9.0}\n",
      "{'eval_loss': 0.1590849608182907, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 4.1097, 'eval_samples_per_second': 122.879, 'eval_steps_per_second': 15.573, 'epoch': 9.0}\n",
      "{'loss': 0.4076, 'learning_rate': 0.00043145629304222626, 'epoch': 1.98}\n",
      "{'loss': 0.3151, 'learning_rate': 0.0003100560980387861, 'epoch': 3.95}\n",
      "{'loss': 0.2442, 'learning_rate': 0.00018865590303534597, 'epoch': 5.93}\n",
      "{'loss': 0.2376, 'learning_rate': 6.725570803190583e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 26.237, 'train_samples_per_second': 692.228, 'train_steps_per_second': 86.786, 'train_loss': 0.2897039404237904, 'epoch': 9.0}\n",
      "{'eval_loss': 0.058564092963933945, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.75, 'eval_precision': 1.0, 'eval_f1': 0.8571428571428571, 'eval_runtime': 4.4223, 'eval_samples_per_second': 114.194, 'eval_steps_per_second': 14.472, 'epoch': 9.0}\n",
      "{'loss': 0.4482, 'learning_rate': 0.00043145629304222626, 'epoch': 1.98}\n",
      "{'loss': 0.3197, 'learning_rate': 0.0003100560980387861, 'epoch': 3.95}\n",
      "{'loss': 0.2119, 'learning_rate': 0.00018865590303534597, 'epoch': 5.93}\n",
      "{'loss': 0.1805, 'learning_rate': 6.725570803190583e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 23.6777, 'train_samples_per_second': 767.431, 'train_steps_per_second': 96.166, 'train_loss': 0.27136523984323535, 'epoch': 9.0}\n",
      "{'eval_loss': 0.08757384121417999, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 3.5839, 'eval_samples_per_second': 140.628, 'eval_steps_per_second': 17.578, 'epoch': 9.0}\n",
      "{'loss': 0.3566, 'learning_rate': 0.00043145629304222626, 'epoch': 1.98}\n",
      "{'loss': 0.3295, 'learning_rate': 0.0003100560980387861, 'epoch': 3.95}\n",
      "{'loss': 0.219, 'learning_rate': 0.00018865590303534597, 'epoch': 5.93}\n",
      "{'loss': 0.1819, 'learning_rate': 6.725570803190583e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 26.4096, 'train_samples_per_second': 688.045, 'train_steps_per_second': 86.219, 'train_loss': 0.25800932631662243, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:42:17,711] Trial 39 finished with value: 0.7416806722689075 and parameters: {'learning_rate': 0.0005528564880456664, 'weight_decay': 0.001615137776926221, 'num_train_epochs': 9}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07914615422487259, 'eval_accuracy': 0.9900793650793651, 'eval_recall': 0.5454545454545454, 'eval_precision': 1.0, 'eval_f1': 0.7058823529411764, 'eval_runtime': 4.3218, 'eval_samples_per_second': 116.619, 'eval_steps_per_second': 14.577, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6434, 'learning_rate': 0.0001351046785749484, 'epoch': 1.98}\n",
      "{'loss': 0.3782, 'learning_rate': 9.077899662778684e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2153, 'learning_rate': 4.6453314680625305e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1542, 'learning_rate': 2.127632733463754e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.6979, 'train_samples_per_second': 681.242, 'train_steps_per_second': 85.408, 'train_loss': 0.3446599411163406, 'epoch': 8.0}\n",
      "{'eval_loss': 0.1940620094537735, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5833333333333334, 'eval_f1': 0.5833333333333334, 'eval_runtime': 3.5514, 'eval_samples_per_second': 142.196, 'eval_steps_per_second': 18.021, 'epoch': 8.0}\n",
      "{'loss': 0.2732, 'learning_rate': 0.0001351046785749484, 'epoch': 1.98}\n",
      "{'loss': 0.0944, 'learning_rate': 9.077899662778684e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0376, 'learning_rate': 4.6453314680625305e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0084, 'learning_rate': 2.127632733463754e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.9309, 'train_samples_per_second': 704.028, 'train_steps_per_second': 88.265, 'train_loss': 0.10217945736127983, 'epoch': 8.0}\n",
      "{'eval_loss': 0.16990135610103607, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 4.4151, 'eval_samples_per_second': 114.381, 'eval_steps_per_second': 14.496, 'epoch': 8.0}\n",
      "{'loss': 0.1544, 'learning_rate': 0.0001351046785749484, 'epoch': 1.98}\n",
      "{'loss': 0.0524, 'learning_rate': 9.077899662778684e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0078, 'learning_rate': 4.6453314680625305e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0011, 'learning_rate': 2.127632733463754e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.5184, 'train_samples_per_second': 686.441, 'train_steps_per_second': 86.06, 'train_loss': 0.05327114556870504, 'epoch': 8.0}\n",
      "{'eval_loss': 0.002989380154758692, 'eval_accuracy': 0.998019801980198, 'eval_recall': 0.9166666666666666, 'eval_precision': 1.0, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.4594, 'eval_samples_per_second': 113.245, 'eval_steps_per_second': 14.352, 'epoch': 8.0}\n",
      "{'loss': 0.1246, 'learning_rate': 0.0001351046785749484, 'epoch': 1.98}\n",
      "{'loss': 0.047, 'learning_rate': 9.077899662778684e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0002, 'learning_rate': 4.6453314680625305e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.127632733463754e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 20.8681, 'train_samples_per_second': 774.005, 'train_steps_per_second': 96.99, 'train_loss': 0.04245926024934752, 'epoch': 8.0}\n",
      "{'eval_loss': 0.016591187566518784, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 6.1375, 'eval_samples_per_second': 82.119, 'eval_steps_per_second': 10.265, 'epoch': 8.0}\n",
      "{'loss': 0.0376, 'learning_rate': 0.0001351046785749484, 'epoch': 1.98}\n",
      "{'loss': 0.0103, 'learning_rate': 9.077899662778684e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0, 'learning_rate': 4.6453314680625305e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.127632733463754e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 24.0411, 'train_samples_per_second': 671.848, 'train_steps_per_second': 84.189, 'train_loss': 0.011835344879004915, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:44:57,770] Trial 40 finished with value: 0.8276338078397576 and parameters: {'learning_rate': 0.00017943036052210995, 'weight_decay': 0.0006964673934965837, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.011053582653403282, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 4.0497, 'eval_samples_per_second': 124.454, 'eval_steps_per_second': 15.557, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6667, 'learning_rate': 0.000273985602873132, 'epoch': 1.98}\n",
      "{'loss': 0.3631, 'learning_rate': 0.0001840953132165926, 'epoch': 3.95}\n",
      "{'loss': 0.1698, 'learning_rate': 9.420502356005325e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1404, 'learning_rate': 4.314733903513889e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.1201, 'train_samples_per_second': 698.267, 'train_steps_per_second': 87.543, 'train_loss': 0.3310684978597514, 'epoch': 8.0}\n",
      "{'eval_loss': 0.1348343789577484, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.6666666666666666, 'eval_precision': 0.6153846153846154, 'eval_f1': 0.64, 'eval_runtime': 4.6235, 'eval_samples_per_second': 109.225, 'eval_steps_per_second': 13.842, 'epoch': 8.0}\n",
      "{'loss': 0.3274, 'learning_rate': 0.000273985602873132, 'epoch': 1.98}\n",
      "{'loss': 0.1753, 'learning_rate': 0.0001840953132165926, 'epoch': 3.95}\n",
      "{'loss': 0.0655, 'learning_rate': 9.420502356005325e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0347, 'learning_rate': 4.314733903513889e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.566, 'train_samples_per_second': 685.055, 'train_steps_per_second': 85.886, 'train_loss': 0.1489201920344439, 'epoch': 8.0}\n",
      "{'eval_loss': 0.13271553814411163, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 4.0478, 'eval_samples_per_second': 124.76, 'eval_steps_per_second': 15.811, 'epoch': 8.0}\n",
      "{'loss': 0.2055, 'learning_rate': 0.000273985602873132, 'epoch': 1.98}\n",
      "{'loss': 0.1244, 'learning_rate': 0.0001840953132165926, 'epoch': 3.95}\n",
      "{'loss': 0.0212, 'learning_rate': 9.420502356005325e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0041, 'learning_rate': 4.314733903513889e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.9973, 'train_samples_per_second': 701.996, 'train_steps_per_second': 88.01, 'train_loss': 0.08827479701975117, 'epoch': 8.0}\n",
      "{'eval_loss': 0.030238673090934753, 'eval_accuracy': 0.994059405940594, 'eval_recall': 1.0, 'eval_precision': 0.8, 'eval_f1': 0.888888888888889, 'eval_runtime': 4.3827, 'eval_samples_per_second': 115.227, 'eval_steps_per_second': 14.603, 'epoch': 8.0}\n",
      "{'loss': 0.1089, 'learning_rate': 0.000273985602873132, 'epoch': 1.98}\n",
      "{'loss': 0.0221, 'learning_rate': 0.0001840953132165926, 'epoch': 3.95}\n",
      "{'loss': 0.0226, 'learning_rate': 9.420502356005325e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0095, 'learning_rate': 4.314733903513889e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 21.666, 'train_samples_per_second': 745.5, 'train_steps_per_second': 93.418, 'train_loss': 0.04027593097274041, 'epoch': 8.0}\n",
      "{'eval_loss': 0.02191917970776558, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.5156, 'eval_samples_per_second': 111.614, 'eval_steps_per_second': 13.952, 'epoch': 8.0}\n",
      "{'loss': 0.1131, 'learning_rate': 0.000273985602873132, 'epoch': 1.98}\n",
      "{'loss': 0.0514, 'learning_rate': 0.0001840953132165926, 'epoch': 3.95}\n",
      "{'loss': 0.0001, 'learning_rate': 9.420502356005325e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0014, 'learning_rate': 4.314733903513889e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.1182, 'train_samples_per_second': 698.671, 'train_steps_per_second': 87.55, 'train_loss': 0.04099773109473864, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:47:37,741] Trial 41 finished with value: 0.8208916494133887 and parameters: {'learning_rate': 0.0003638758925296713, 'weight_decay': 0.0008530734766577331, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01551055908203125, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 5.1246, 'eval_samples_per_second': 98.349, 'eval_steps_per_second': 12.294, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6566, 'learning_rate': 0.0002671312678039836, 'epoch': 1.98}\n",
      "{'loss': 0.3588, 'learning_rate': 0.0001794897757423092, 'epoch': 3.95}\n",
      "{'loss': 0.1819, 'learning_rate': 9.184828368063479e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1518, 'learning_rate': 4.206791618960372e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.7802, 'train_samples_per_second': 708.685, 'train_steps_per_second': 88.849, 'train_loss': 0.3333811446170326, 'epoch': 8.0}\n",
      "{'eval_loss': 0.18987822532653809, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5, 'eval_precision': 0.6666666666666666, 'eval_f1': 0.5714285714285715, 'eval_runtime': 4.8143, 'eval_samples_per_second': 104.896, 'eval_steps_per_second': 13.294, 'epoch': 8.0}\n",
      "{'loss': 0.3123, 'learning_rate': 0.0002671312678039836, 'epoch': 1.98}\n",
      "{'loss': 0.1551, 'learning_rate': 0.0001794897757423092, 'epoch': 3.95}\n",
      "{'loss': 0.0709, 'learning_rate': 9.184828368063479e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0673, 'learning_rate': 4.206791618960372e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.5962, 'train_samples_per_second': 714.455, 'train_steps_per_second': 89.572, 'train_loss': 0.14961924996772752, 'epoch': 8.0}\n",
      "{'eval_loss': 0.14221204817295074, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 4.4373, 'eval_samples_per_second': 113.808, 'eval_steps_per_second': 14.423, 'epoch': 8.0}\n",
      "{'loss': 0.1817, 'learning_rate': 0.0002671312678039836, 'epoch': 1.98}\n",
      "{'loss': 0.0909, 'learning_rate': 0.0001794897757423092, 'epoch': 3.95}\n",
      "{'loss': 0.0101, 'learning_rate': 9.184828368063479e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0001, 'learning_rate': 4.206791618960372e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.55, 'train_samples_per_second': 715.92, 'train_steps_per_second': 89.756, 'train_loss': 0.06983697012414476, 'epoch': 8.0}\n",
      "{'eval_loss': 0.07629992812871933, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.8333333333333334, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.8695652173913043, 'eval_runtime': 4.3566, 'eval_samples_per_second': 115.916, 'eval_steps_per_second': 14.69, 'epoch': 8.0}\n",
      "{'loss': 0.1475, 'learning_rate': 0.0002671312678039836, 'epoch': 1.98}\n",
      "{'loss': 0.0528, 'learning_rate': 0.0001794897757423092, 'epoch': 3.95}\n",
      "{'loss': 0.0005, 'learning_rate': 9.184828368063479e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0152, 'learning_rate': 4.206791618960372e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 21.2118, 'train_samples_per_second': 761.463, 'train_steps_per_second': 95.419, 'train_loss': 0.05337702762393056, 'epoch': 8.0}\n",
      "{'eval_loss': 2.2522710423800163e-05, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 4.361, 'eval_samples_per_second': 115.569, 'eval_steps_per_second': 14.446, 'epoch': 8.0}\n",
      "{'loss': 0.0823, 'learning_rate': 0.0002671312678039836, 'epoch': 1.98}\n",
      "{'loss': 0.0606, 'learning_rate': 0.0001794897757423092, 'epoch': 3.95}\n",
      "{'loss': 0.0, 'learning_rate': 9.184828368063479e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0079, 'learning_rate': 4.206791618960372e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.7089, 'train_samples_per_second': 681.263, 'train_steps_per_second': 85.369, 'train_loss': 0.037277457708811926, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:50:16,589] Trial 42 finished with value: 0.7929606625258799 and parameters: {'learning_rate': 0.000354772759865658, 'weight_decay': 0.0018218114251380656, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05907484143972397, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 3.7357, 'eval_samples_per_second': 134.915, 'eval_steps_per_second': 16.864, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6578, 'learning_rate': 0.0001746433949891143, 'epoch': 1.98}\n",
      "{'loss': 0.3704, 'learning_rate': 0.00011734569322103218, 'epoch': 3.95}\n",
      "{'loss': 0.2098, 'learning_rate': 6.004799145295006e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1454, 'learning_rate': 2.7502896848679415e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.7192, 'train_samples_per_second': 710.588, 'train_steps_per_second': 89.088, 'train_loss': 0.3417705035328556, 'epoch': 8.0}\n",
      "{'eval_loss': 0.17944274842739105, 'eval_accuracy': 0.9841584158415841, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.7, 'eval_f1': 0.6363636363636365, 'eval_runtime': 4.2721, 'eval_samples_per_second': 118.208, 'eval_steps_per_second': 14.981, 'epoch': 8.0}\n",
      "{'loss': 0.2739, 'learning_rate': 0.0001746433949891143, 'epoch': 1.98}\n",
      "{'loss': 0.0996, 'learning_rate': 0.00011734569322103218, 'epoch': 3.95}\n",
      "{'loss': 0.0584, 'learning_rate': 6.004799145295006e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0039, 'learning_rate': 2.7502896848679415e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 24.9395, 'train_samples_per_second': 647.328, 'train_steps_per_second': 81.157, 'train_loss': 0.10764092400676609, 'epoch': 8.0}\n",
      "{'eval_loss': 0.1704009771347046, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 4.254, 'eval_samples_per_second': 118.713, 'eval_steps_per_second': 15.045, 'epoch': 8.0}\n",
      "{'loss': 0.1662, 'learning_rate': 0.0001746433949891143, 'epoch': 1.98}\n",
      "{'loss': 0.0592, 'learning_rate': 0.00011734569322103218, 'epoch': 3.95}\n",
      "{'loss': 0.008, 'learning_rate': 6.004799145295006e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0021, 'learning_rate': 2.7502896848679415e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.6723, 'train_samples_per_second': 712.058, 'train_steps_per_second': 89.272, 'train_loss': 0.05819569996709056, 'epoch': 8.0}\n",
      "{'eval_loss': 0.021043434739112854, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.8333333333333334, 'eval_precision': 1.0, 'eval_f1': 0.9090909090909091, 'eval_runtime': 4.1469, 'eval_samples_per_second': 121.777, 'eval_steps_per_second': 15.433, 'epoch': 8.0}\n",
      "{'loss': 0.133, 'learning_rate': 0.0001746433949891143, 'epoch': 1.98}\n",
      "{'loss': 0.0322, 'learning_rate': 0.00011734569322103218, 'epoch': 3.95}\n",
      "{'loss': 0.0082, 'learning_rate': 6.004799145295006e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.7502896848679415e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 21.2986, 'train_samples_per_second': 758.358, 'train_steps_per_second': 95.03, 'train_loss': 0.0428532936890449, 'epoch': 8.0}\n",
      "{'eval_loss': 0.02168019860982895, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.3542, 'eval_samples_per_second': 115.75, 'eval_steps_per_second': 14.469, 'epoch': 8.0}\n",
      "{'loss': 0.0758, 'learning_rate': 0.0001746433949891143, 'epoch': 1.98}\n",
      "{'loss': 0.0269, 'learning_rate': 0.00011734569322103218, 'epoch': 3.95}\n",
      "{'loss': 0.0002, 'learning_rate': 6.004799145295006e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0052, 'learning_rate': 2.7502896848679415e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.3472, 'train_samples_per_second': 691.819, 'train_steps_per_second': 86.692, 'train_loss': 0.026704014012498712, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:52:55,262] Trial 43 finished with value: 0.8155467720685113 and parameters: {'learning_rate': 0.00023194109675719643, 'weight_decay': 0.001238904463365714, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04418201372027397, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.9265, 'eval_samples_per_second': 128.358, 'eval_steps_per_second': 16.045, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7724, 'learning_rate': 0.0005844352227502615, 'epoch': 1.98}\n",
      "{'loss': 0.7117, 'learning_rate': 0.0004199908719482745, 'epoch': 3.95}\n",
      "{'loss': 0.7238, 'learning_rate': 0.00025554652114628763, 'epoch': 5.93}\n",
      "{'loss': 0.7138, 'learning_rate': 9.110217034430074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 25.8832, 'train_samples_per_second': 701.69, 'train_steps_per_second': 87.972, 'train_loss': 0.7289663255345575, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1697949469089508, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 5.327, 'eval_samples_per_second': 94.801, 'eval_steps_per_second': 12.014, 'epoch': 9.0}\n",
      "{'loss': 0.8059, 'learning_rate': 0.0005844352227502615, 'epoch': 1.98}\n",
      "{'loss': 0.707, 'learning_rate': 0.0004199908719482745, 'epoch': 3.95}\n",
      "{'loss': 0.7157, 'learning_rate': 0.00025554652114628763, 'epoch': 5.93}\n",
      "{'loss': 0.7045, 'learning_rate': 9.110217034430074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 25.0789, 'train_samples_per_second': 724.195, 'train_steps_per_second': 90.793, 'train_loss': 0.7305437640029713, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1679583340883255, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 5.059, 'eval_samples_per_second': 99.822, 'eval_steps_per_second': 12.651, 'epoch': 9.0}\n",
      "{'loss': 0.7846, 'learning_rate': 0.0005844352227502615, 'epoch': 1.98}\n",
      "{'loss': 0.624, 'learning_rate': 0.0004199908719482745, 'epoch': 3.95}\n",
      "{'loss': 0.6723, 'learning_rate': 0.00025554652114628763, 'epoch': 5.93}\n",
      "{'loss': 0.6522, 'learning_rate': 9.110217034430074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 25.5652, 'train_samples_per_second': 710.418, 'train_steps_per_second': 89.066, 'train_loss': 0.6817908071351251, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14753016829490662, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 6.0741, 'eval_samples_per_second': 83.14, 'eval_steps_per_second': 10.537, 'epoch': 9.0}\n",
      "{'loss': 0.6774, 'learning_rate': 0.0005844352227502615, 'epoch': 1.98}\n",
      "{'loss': 0.6769, 'learning_rate': 0.0004199908719482745, 'epoch': 3.95}\n",
      "{'loss': 0.6281, 'learning_rate': 0.00025554652114628763, 'epoch': 5.93}\n",
      "{'loss': 0.6565, 'learning_rate': 9.110217034430074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 23.7996, 'train_samples_per_second': 763.501, 'train_steps_per_second': 95.674, 'train_loss': 0.6569112879066652, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1631297767162323, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 5.4869, 'eval_samples_per_second': 91.854, 'eval_steps_per_second': 11.482, 'epoch': 9.0}\n",
      "{'loss': 0.7094, 'learning_rate': 0.0005844352227502615, 'epoch': 1.98}\n",
      "{'loss': 0.7407, 'learning_rate': 0.0004199908719482745, 'epoch': 3.95}\n",
      "{'loss': 0.5887, 'learning_rate': 0.00025554652114628763, 'epoch': 5.93}\n",
      "{'loss': 0.5424, 'learning_rate': 9.110217034430074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 25.6771, 'train_samples_per_second': 707.674, 'train_steps_per_second': 88.678, 'train_loss': 0.6240788234866498, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:55:52,577] Trial 44 finished with value: 0.07499999999999998 and parameters: {'learning_rate': 0.0007488795735522484, 'weight_decay': 0.0005162876944908032, 'num_train_epochs': 9}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16141773760318756, 'eval_accuracy': 0.9801587301587301, 'eval_recall': 0.2727272727272727, 'eval_precision': 0.6, 'eval_f1': 0.37499999999999994, 'eval_runtime': 4.0934, 'eval_samples_per_second': 123.126, 'eval_steps_per_second': 15.391, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6527, 'learning_rate': 0.00023531555048772777, 'epoch': 1.98}\n",
      "{'loss': 0.3487, 'learning_rate': 0.00014274452354526995, 'epoch': 3.95}\n",
      "{'loss': 0.1716, 'learning_rate': 5.017349660281214e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 19.8931, 'train_samples_per_second': 710.097, 'train_steps_per_second': 89.026, 'train_loss': 0.3480902337408685, 'epoch': 7.0}\n",
      "{'eval_loss': 0.17862221598625183, 'eval_accuracy': 0.9782178217821782, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5384615384615384, 'eval_f1': 0.5599999999999999, 'eval_runtime': 4.8565, 'eval_samples_per_second': 103.984, 'eval_steps_per_second': 13.178, 'epoch': 7.0}\n",
      "{'loss': 0.3004, 'learning_rate': 0.00023531555048772777, 'epoch': 1.98}\n",
      "{'loss': 0.1331, 'learning_rate': 0.00014274452354526995, 'epoch': 3.95}\n",
      "{'loss': 0.0375, 'learning_rate': 5.017349660281214e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 19.4186, 'train_samples_per_second': 727.448, 'train_steps_per_second': 91.201, 'train_loss': 0.13694702683701346, 'epoch': 7.0}\n",
      "{'eval_loss': 0.1854940503835678, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 4.9693, 'eval_samples_per_second': 101.624, 'eval_steps_per_second': 12.879, 'epoch': 7.0}\n",
      "{'loss': 0.1913, 'learning_rate': 0.00023531555048772777, 'epoch': 1.98}\n",
      "{'loss': 0.0503, 'learning_rate': 0.00014274452354526995, 'epoch': 3.95}\n",
      "{'loss': 0.0156, 'learning_rate': 5.017349660281214e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 20.4794, 'train_samples_per_second': 689.766, 'train_steps_per_second': 86.477, 'train_loss': 0.0732042604351636, 'epoch': 7.0}\n",
      "{'eval_loss': 0.08248172700405121, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.8333333333333334, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.8695652173913043, 'eval_runtime': 4.7132, 'eval_samples_per_second': 107.145, 'eval_steps_per_second': 13.579, 'epoch': 7.0}\n",
      "{'loss': 0.1493, 'learning_rate': 0.00023531555048772777, 'epoch': 1.98}\n",
      "{'loss': 0.0889, 'learning_rate': 0.00014274452354526995, 'epoch': 3.95}\n",
      "{'loss': 0.0009, 'learning_rate': 5.017349660281214e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 18.2305, 'train_samples_per_second': 775.239, 'train_steps_per_second': 97.145, 'train_loss': 0.06902549527312052, 'epoch': 7.0}\n",
      "{'eval_loss': 0.04013532027602196, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 4.6975, 'eval_samples_per_second': 107.292, 'eval_steps_per_second': 13.411, 'epoch': 7.0}\n",
      "{'loss': 0.1024, 'learning_rate': 0.00023531555048772777, 'epoch': 1.98}\n",
      "{'loss': 0.0616, 'learning_rate': 0.00014274452354526995, 'epoch': 3.95}\n",
      "{'loss': 0.0014, 'learning_rate': 5.017349660281214e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 20.5755, 'train_samples_per_second': 686.886, 'train_steps_per_second': 86.073, 'train_loss': 0.046726390319749636, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:58:20,450] Trial 45 finished with value: 0.7653782841199721 and parameters: {'learning_rate': 0.0003278865774301856, 'weight_decay': 0.0009460358719496141, 'num_train_epochs': 7}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05878017842769623, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.8181818181818182, 'eval_precision': 1.0, 'eval_f1': 0.9, 'eval_runtime': 4.301, 'eval_samples_per_second': 117.183, 'eval_steps_per_second': 14.648, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6497, 'learning_rate': 0.00015883755617365522, 'epoch': 1.98}\n",
      "{'loss': 0.372, 'learning_rate': 0.00010672549706156361, 'epoch': 3.95}\n",
      "{'loss': 0.2053, 'learning_rate': 5.461343794947201e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1237, 'learning_rate': 2.501378837380397e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.4246, 'train_samples_per_second': 719.923, 'train_steps_per_second': 90.258, 'train_loss': 0.33377230642253, 'epoch': 8.0}\n",
      "{'eval_loss': 0.18276353180408478, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.6363636363636364, 'eval_f1': 0.6086956521739131, 'eval_runtime': 3.7937, 'eval_samples_per_second': 133.115, 'eval_steps_per_second': 16.87, 'epoch': 8.0}\n",
      "{'loss': 0.2141, 'learning_rate': 0.00015883755617365522, 'epoch': 1.98}\n",
      "{'loss': 0.0825, 'learning_rate': 0.00010672549706156361, 'epoch': 3.95}\n",
      "{'loss': 0.0229, 'learning_rate': 5.461343794947201e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0065, 'learning_rate': 2.501378837380397e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 24.7602, 'train_samples_per_second': 652.013, 'train_steps_per_second': 81.744, 'train_loss': 0.08055806434595969, 'epoch': 8.0}\n",
      "{'eval_loss': 0.21172234416007996, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.8625, 'eval_samples_per_second': 130.743, 'eval_steps_per_second': 16.569, 'epoch': 8.0}\n",
      "{'loss': 0.1833, 'learning_rate': 0.00015883755617365522, 'epoch': 1.98}\n",
      "{'loss': 0.0739, 'learning_rate': 0.00010672549706156361, 'epoch': 3.95}\n",
      "{'loss': 0.0093, 'learning_rate': 5.461343794947201e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.501378837380397e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.3868, 'train_samples_per_second': 690.304, 'train_steps_per_second': 86.545, 'train_loss': 0.06587481023854182, 'epoch': 8.0}\n",
      "{'eval_loss': 0.023319333791732788, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.9166666666666666, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9166666666666666, 'eval_runtime': 4.7139, 'eval_samples_per_second': 107.131, 'eval_steps_per_second': 13.577, 'epoch': 8.0}\n",
      "{'loss': 0.0873, 'learning_rate': 0.00015883755617365522, 'epoch': 1.98}\n",
      "{'loss': 0.0089, 'learning_rate': 0.00010672549706156361, 'epoch': 3.95}\n",
      "{'loss': 0.0004, 'learning_rate': 5.461343794947201e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.501378837380397e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 20.9322, 'train_samples_per_second': 771.636, 'train_steps_per_second': 96.693, 'train_loss': 0.0238690605964308, 'epoch': 8.0}\n",
      "{'eval_loss': 0.023545484989881516, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.8529, 'eval_samples_per_second': 103.856, 'eval_steps_per_second': 12.982, 'epoch': 8.0}\n",
      "{'loss': 0.0892, 'learning_rate': 0.00015883755617365522, 'epoch': 1.98}\n",
      "{'loss': 0.0394, 'learning_rate': 0.00010672549706156361, 'epoch': 3.95}\n",
      "{'loss': 0.0, 'learning_rate': 5.461343794947201e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.501378837380397e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.3974, 'train_samples_per_second': 721.155, 'train_steps_per_second': 90.368, 'train_loss': 0.03177137871190411, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 16:00:59,213] Trial 46 finished with value: 0.7958420522359141 and parameters: {'learning_rate': 0.00021094961528574685, 'weight_decay': 0.003347546354257197, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.025308843702077866, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 4.7432, 'eval_samples_per_second': 106.257, 'eval_steps_per_second': 13.282, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6637, 'learning_rate': 8.444436523190577e-05, 'epoch': 1.98}\n",
      "{'loss': 0.4371, 'learning_rate': 6.068399234729525e-05, 'epoch': 3.95}\n",
      "{'loss': 0.3173, 'learning_rate': 3.692361946268474e-05, 'epoch': 5.93}\n",
      "{'loss': 0.2352, 'learning_rate': 1.3163246578074225e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 25.9968, 'train_samples_per_second': 698.623, 'train_steps_per_second': 87.588, 'train_loss': 0.3897846541909413, 'epoch': 9.0}\n",
      "{'eval_loss': 0.17921951413154602, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.4166666666666667, 'eval_precision': 0.5, 'eval_f1': 0.45454545454545453, 'eval_runtime': 4.4407, 'eval_samples_per_second': 113.72, 'eval_steps_per_second': 14.412, 'epoch': 9.0}\n",
      "{'loss': 0.2769, 'learning_rate': 8.444436523190577e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1384, 'learning_rate': 6.068399234729525e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0646, 'learning_rate': 3.692361946268474e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0543, 'learning_rate': 1.3163246578074225e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 26.7752, 'train_samples_per_second': 678.314, 'train_steps_per_second': 85.041, 'train_loss': 0.12393296283224355, 'epoch': 9.0}\n",
      "{'eval_loss': 0.14273595809936523, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.9966, 'eval_samples_per_second': 126.356, 'eval_steps_per_second': 16.013, 'epoch': 9.0}\n",
      "{'loss': 0.1929, 'learning_rate': 8.444436523190577e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0756, 'learning_rate': 6.068399234729525e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0558, 'learning_rate': 3.692361946268474e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0128, 'learning_rate': 1.3163246578074225e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 25.9775, 'train_samples_per_second': 699.143, 'train_steps_per_second': 87.653, 'train_loss': 0.07791052002837692, 'epoch': 9.0}\n",
      "{'eval_loss': 0.03629494830965996, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.9166666666666666, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9166666666666666, 'eval_runtime': 4.9083, 'eval_samples_per_second': 102.887, 'eval_steps_per_second': 13.039, 'epoch': 9.0}\n",
      "{'loss': 0.0793, 'learning_rate': 8.444436523190577e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0839, 'learning_rate': 6.068399234729525e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0006, 'learning_rate': 3.692361946268474e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0004, 'learning_rate': 1.3163246578074225e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 26.8691, 'train_samples_per_second': 676.28, 'train_steps_per_second': 84.744, 'train_loss': 0.0360566780340666, 'epoch': 9.0}\n",
      "{'eval_loss': 0.027311716228723526, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.4465, 'eval_samples_per_second': 113.349, 'eval_steps_per_second': 14.169, 'epoch': 9.0}\n",
      "{'loss': 0.0288, 'learning_rate': 8.444436523190577e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0626, 'learning_rate': 6.068399234729525e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0001, 'learning_rate': 3.692361946268474e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0001, 'learning_rate': 1.3163246578074225e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 25.8336, 'train_samples_per_second': 703.388, 'train_steps_per_second': 88.141, 'train_loss': 0.020106801053386004, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 16:03:57,252] Trial 47 finished with value: 0.7788801054018445 and parameters: {'learning_rate': 0.00010820473811651628, 'weight_decay': 0.0020261556456688135, 'num_train_epochs': 9}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03805989399552345, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.8181818181818182, 'eval_precision': 1.0, 'eval_f1': 0.9, 'eval_runtime': 4.4244, 'eval_samples_per_second': 113.913, 'eval_steps_per_second': 14.239, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6389, 'learning_rate': 0.00011317512238414081, 'epoch': 1.98}\n",
      "{'loss': 0.3908, 'learning_rate': 7.604417672005262e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2418, 'learning_rate': 3.8913231055964426e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1603, 'learning_rate': 1.782285391876233e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.0616, 'train_samples_per_second': 700.039, 'train_steps_per_second': 87.765, 'train_loss': 0.3543485681058861, 'epoch': 8.0}\n",
      "{'eval_loss': 0.17736200988292694, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5, 'eval_precision': 0.6666666666666666, 'eval_f1': 0.5714285714285715, 'eval_runtime': 3.5783, 'eval_samples_per_second': 141.13, 'eval_steps_per_second': 17.886, 'epoch': 8.0}\n",
      "{'loss': 0.2687, 'learning_rate': 0.00011317512238414081, 'epoch': 1.98}\n",
      "{'loss': 0.096, 'learning_rate': 7.604417672005262e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0294, 'learning_rate': 3.8913231055964426e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0199, 'learning_rate': 1.782285391876233e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 24.2239, 'train_samples_per_second': 666.449, 'train_steps_per_second': 83.554, 'train_loss': 0.10226804485890588, 'epoch': 8.0}\n",
      "{'eval_loss': 0.15321369469165802, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.6284, 'eval_samples_per_second': 139.18, 'eval_steps_per_second': 17.639, 'epoch': 8.0}\n",
      "{'loss': 0.1587, 'learning_rate': 0.00011317512238414081, 'epoch': 1.98}\n",
      "{'loss': 0.0228, 'learning_rate': 7.604417672005262e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0257, 'learning_rate': 3.8913231055964426e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0032, 'learning_rate': 1.782285391876233e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.7191, 'train_samples_per_second': 710.593, 'train_steps_per_second': 89.088, 'train_loss': 0.0521403970601766, 'epoch': 8.0}\n",
      "{'eval_loss': 0.00020983941794838756, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 4.385, 'eval_samples_per_second': 115.165, 'eval_steps_per_second': 14.595, 'epoch': 8.0}\n",
      "{'loss': 0.0853, 'learning_rate': 0.00011317512238414081, 'epoch': 1.98}\n",
      "{'loss': 0.0273, 'learning_rate': 7.604417672005262e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0198, 'learning_rate': 3.8913231055964426e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0043, 'learning_rate': 1.782285391876233e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 21.135, 'train_samples_per_second': 764.23, 'train_steps_per_second': 95.765, 'train_loss': 0.03376997397258618, 'epoch': 8.0}\n",
      "{'eval_loss': 0.020840419456362724, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.1333, 'eval_samples_per_second': 121.938, 'eval_steps_per_second': 15.242, 'epoch': 8.0}\n",
      "{'loss': 0.0324, 'learning_rate': 0.00011317512238414081, 'epoch': 1.98}\n",
      "{'loss': 0.0337, 'learning_rate': 7.604417672005262e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0061, 'learning_rate': 3.8913231055964426e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 1.782285391876233e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.3988, 'train_samples_per_second': 721.109, 'train_steps_per_second': 90.362, 'train_loss': 0.017833334135807472, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 16:06:32,499] Trial 48 finished with value: 0.829399585921325 and parameters: {'learning_rate': 0.000150306068048229, 'weight_decay': 0.0013936924090544142, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.012225878424942493, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.6991, 'eval_samples_per_second': 136.248, 'eval_steps_per_second': 17.031, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6708, 'learning_rate': 0.00024905828939058563, 'epoch': 1.98}\n",
      "{'loss': 0.386, 'learning_rate': 8.627509371046431e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 13.9557, 'train_samples_per_second': 723.0, 'train_steps_per_second': 90.644, 'train_loss': 0.4634969718842638, 'epoch': 5.0}\n",
      "{'eval_loss': 0.1445016860961914, 'eval_accuracy': 0.9782178217821782, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5384615384615384, 'eval_f1': 0.5599999999999999, 'eval_runtime': 4.7378, 'eval_samples_per_second': 106.589, 'eval_steps_per_second': 13.508, 'epoch': 5.0}\n",
      "{'loss': 0.3839, 'learning_rate': 0.00024905828939058563, 'epoch': 1.98}\n",
      "{'loss': 0.1678, 'learning_rate': 8.627509371046431e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 13.7763, 'train_samples_per_second': 732.418, 'train_steps_per_second': 91.824, 'train_loss': 0.2497690253578156, 'epoch': 5.0}\n",
      "{'eval_loss': 0.12307528406381607, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.566, 'eval_samples_per_second': 141.616, 'eval_steps_per_second': 17.947, 'epoch': 5.0}\n",
      "{'loss': 0.3396, 'learning_rate': 0.00024905828939058563, 'epoch': 1.98}\n",
      "{'loss': 0.223, 'learning_rate': 8.627509371046431e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 14.092, 'train_samples_per_second': 716.008, 'train_steps_per_second': 89.767, 'train_loss': 0.2613663202217916, 'epoch': 5.0}\n",
      "{'eval_loss': 0.05993935838341713, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.75, 'eval_precision': 1.0, 'eval_f1': 0.8571428571428571, 'eval_runtime': 4.13, 'eval_samples_per_second': 122.276, 'eval_steps_per_second': 15.496, 'epoch': 5.0}\n",
      "{'loss': 0.3349, 'learning_rate': 0.00024905828939058563, 'epoch': 1.98}\n",
      "{'loss': 0.2388, 'learning_rate': 8.627509371046431e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 14.3507, 'train_samples_per_second': 703.45, 'train_steps_per_second': 88.149, 'train_loss': 0.2544450360324543, 'epoch': 5.0}\n",
      "{'eval_loss': 0.08646654337644577, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 4.3651, 'eval_samples_per_second': 115.461, 'eval_steps_per_second': 14.433, 'epoch': 5.0}\n",
      "{'loss': 0.3282, 'learning_rate': 0.00024905828939058563, 'epoch': 1.98}\n",
      "{'loss': 0.2008, 'learning_rate': 8.627509371046431e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 14.051, 'train_samples_per_second': 718.454, 'train_steps_per_second': 90.029, 'train_loss': 0.23217447152722023, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 16:08:25,943] Trial 49 finished with value: 0.7786666666666667 and parameters: {'learning_rate': 0.000411841485070707, 'weight_decay': 0.0006967775337055864, 'num_train_epochs': 5}. Best is trial 25 with value: 0.8595837419636047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01356352586299181, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.4895, 'eval_samples_per_second': 144.435, 'eval_steps_per_second': 18.054, 'epoch': 5.0}\n",
      "0.8595837419636047\n",
      "{'learning_rate': 0.00025987619417987257, 'weight_decay': 0.0010315325907121007, 'num_train_epochs': 9}\n",
      "FrozenTrial(number=25, state=TrialState.COMPLETE, values=[0.8595837419636047], datetime_start=datetime.datetime(2023, 11, 9, 14, 52, 9, 762092), datetime_complete=datetime.datetime(2023, 11, 9, 14, 56, 1, 323781), params={'learning_rate': 0.00025987619417987257, 'weight_decay': 0.0010315325907121007, 'num_train_epochs': 9}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.01, log=True, low=4e-05, step=None), 'weight_decay': FloatDistribution(high=0.01, log=True, low=4e-05, step=None), 'num_train_epochs': IntDistribution(high=10, log=False, low=4, step=1)}, trial_id=25, value=None)\n"
     ]
    }
   ],
   "source": [
    "#https://medium.com/carbon-consulting/transformer-models-hyperparameter-optimization-with-the-optuna-299e185044a8\n",
    "import hyperopt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"DeepChem/ChemBERTa-77M-MTR\", num_labels=2, problem_type = \"single_label_classification\")\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"optuna-test\",\n",
    "        learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
    "        weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n",
    "        num_train_epochs=trial.suggest_int(\"num_train_epochs\", low=4, high=10),\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        disable_tqdm=True,\n",
    "    )\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle = True, random_state=62)\n",
    "\n",
    "    # lists for this cv\n",
    "    y_tests = []\n",
    "    y_preds = []\n",
    "    f1s = []\n",
    "\n",
    "    for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "        # fit model to cv's X[train]\n",
    "\n",
    "        train_df = pd.DataFrame(X[train], columns=['SMILES'])\n",
    "        test_df =  pd.DataFrame(X[test], columns=['SMILES'])\n",
    "\n",
    "        train_dataset = Dataset(train_df, y[train], tokenizer)\n",
    "        test_dataset = Dataset(test_df, y[test], tokenizer)\n",
    "\n",
    "\n",
    "        trainer = CustomTrainer(\n",
    "          model=model,\n",
    "          args=training_args,\n",
    "          train_dataset=train_dataset,\n",
    "          eval_dataset=test_dataset,\n",
    "          compute_metrics=compute_metrics,\n",
    "        )\n",
    "\n",
    "        # predict on cValidation set\n",
    "        result = trainer.train()\n",
    "        predictions = trainer.predict(test_dataset)\n",
    "        y_pred = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "        # save y_test, y_pred (and y_prob) to compute confmats (& curves)\n",
    "        y_tests.append(y[test])\n",
    "        y_preds.append(y_pred)\n",
    "        results = trainer.evaluate()\n",
    "        f1s.append(results['eval_f1'])\n",
    "\n",
    "\n",
    "    #final_score = metric.compute(predictions=y_pred, references=y_test)\n",
    "    return sum(f1s)/len(f1s)\n",
    "\n",
    "\n",
    "# We want to minimise the f1\n",
    "study = optuna.create_study(study_name=\"hyper-parameter-search\", direction=\"maximize\")\n",
    "study.optimize(func=objective, n_trials=50)\n",
    "print(study.best_value)\n",
    "print(study.best_params)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "hwgDeyjYOlx3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.00025987619417987257, 'weight_decay': 0.0010315325907121007, 'num_train_epochs': 9}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "AB7ZRaOBpVBS"
   },
   "outputs": [],
   "source": [
    "X = training_df[['SMILES']]\n",
    "y = training_df['senolytic']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "train_dataset = Dataset(X_train, y_train, tokenizer)\n",
    "test_dataset = Dataset(X_test, y_test, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My save to dict did not work so I have copied this from the terminal\n",
    "best_params =  {'learning_rate': 0.0002129544689531246, 'weight_decay': 0.003149550907030126, 'num_train_epochs': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "scITAOltPAtr"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# many more parameters to experiment with https://huggingface.co/docs/transformers/v4.33.2/en/main_classes/trainer#transformers.TrainingArguments\n",
    "training_args = TrainingArguments(output_dir=\"test_2\", load_best_model_at_end=True, evaluation_strategy='epoch',\n",
    "    logging_strategy=\"epoch\", save_strategy=\"epoch\",per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,optim=\"adamw_torch\", num_train_epochs=best_params['num_train_epochs'], learning_rate=best_params['learning_rate'],\n",
    "                                  weight_decay=best_params['weight_decay']) # switch optimizer to avoid warning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "wtAfs7GKE0dU"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Define a callback for printing validation loss\n",
    "class PrintValidationLossCallback(TrainerCallback):\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        if state is not None and hasattr(state, 'eval_loss'):\n",
    "            print(f\"Validation loss: {state.eval_loss:.4f}\")\n",
    "\n",
    "# Add the callback to the trainer\n",
    "trainer.add_callback(PrintValidationLossCallback())\n",
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "GEDQnTztZeuf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='999' max='999' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [999/999 00:53, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.827400</td>\n",
       "      <td>1.293019</td>\n",
       "      <td>0.978864</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.671100</td>\n",
       "      <td>1.047782</td>\n",
       "      <td>0.973580</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.542500</td>\n",
       "      <td>1.381071</td>\n",
       "      <td>0.982827</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.406600</td>\n",
       "      <td>1.007332</td>\n",
       "      <td>0.984148</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>1.181681</td>\n",
       "      <td>0.980185</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.516129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.345800</td>\n",
       "      <td>1.183158</td>\n",
       "      <td>0.981506</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>1.527709</td>\n",
       "      <td>0.981506</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.147000</td>\n",
       "      <td>1.428440</td>\n",
       "      <td>0.984148</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.133400</td>\n",
       "      <td>1.439301</td>\n",
       "      <td>0.984148</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=999, training_loss=0.3950687557369381, metrics={'train_runtime': 54.4648, 'train_samples_per_second': 291.821, 'train_steps_per_second': 18.342, 'total_flos': 74375638590240.0, 'train_loss': 0.3950687557369381, 'epoch': 9.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "8VxPSWR_oprj"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "trainer.save_model(\"./full_model_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "t6BCwFDVKM05"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "GqQG_UvsqAXV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(predictions.predictions, axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "athSKeXvraLC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "CuX5MHp_7j3k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# senolytics predicted\n",
    "y_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "5QG0sQUi7oKK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.8274,\n",
       "  'learning_rate': 0.0001892928612916663,\n",
       "  'epoch': 1.0,\n",
       "  'step': 111},\n",
       " {'eval_loss': 1.2930188179016113,\n",
       "  'eval_accuracy': 0.9788639365918098,\n",
       "  'eval_recall': 0.058823529411764705,\n",
       "  'eval_precision': 1.0,\n",
       "  'eval_f1': 0.1111111111111111,\n",
       "  'eval_runtime': 3.9837,\n",
       "  'eval_samples_per_second': 190.026,\n",
       "  'eval_steps_per_second': 3.012,\n",
       "  'epoch': 1.0,\n",
       "  'step': 111},\n",
       " {'loss': 0.6711,\n",
       "  'learning_rate': 0.00016563125363020802,\n",
       "  'epoch': 2.0,\n",
       "  'step': 222},\n",
       " {'eval_loss': 1.0477817058563232,\n",
       "  'eval_accuracy': 0.9735799207397622,\n",
       "  'eval_recall': 0.35294117647058826,\n",
       "  'eval_precision': 0.4,\n",
       "  'eval_f1': 0.37500000000000006,\n",
       "  'eval_runtime': 3.6406,\n",
       "  'eval_samples_per_second': 207.932,\n",
       "  'eval_steps_per_second': 3.296,\n",
       "  'epoch': 2.0,\n",
       "  'step': 222},\n",
       " {'loss': 0.5425,\n",
       "  'learning_rate': 0.00014196964596874972,\n",
       "  'epoch': 3.0,\n",
       "  'step': 333},\n",
       " {'eval_loss': 1.3810709714889526,\n",
       "  'eval_accuracy': 0.9828269484808454,\n",
       "  'eval_recall': 0.35294117647058826,\n",
       "  'eval_precision': 0.75,\n",
       "  'eval_f1': 0.48,\n",
       "  'eval_runtime': 4.0245,\n",
       "  'eval_samples_per_second': 188.098,\n",
       "  'eval_steps_per_second': 2.982,\n",
       "  'epoch': 3.0,\n",
       "  'step': 333},\n",
       " {'loss': 0.4066,\n",
       "  'learning_rate': 0.00011830803830729145,\n",
       "  'epoch': 4.0,\n",
       "  'step': 444},\n",
       " {'eval_loss': 1.0073319673538208,\n",
       "  'eval_accuracy': 0.9841479524438573,\n",
       "  'eval_recall': 0.47058823529411764,\n",
       "  'eval_precision': 0.7272727272727273,\n",
       "  'eval_f1': 0.5714285714285714,\n",
       "  'eval_runtime': 3.8915,\n",
       "  'eval_samples_per_second': 194.529,\n",
       "  'eval_steps_per_second': 3.084,\n",
       "  'epoch': 4.0,\n",
       "  'step': 444},\n",
       " {'loss': 0.341,\n",
       "  'learning_rate': 9.464643064583315e-05,\n",
       "  'epoch': 5.0,\n",
       "  'step': 555},\n",
       " {'eval_loss': 1.181680679321289,\n",
       "  'eval_accuracy': 0.9801849405548216,\n",
       "  'eval_recall': 0.47058823529411764,\n",
       "  'eval_precision': 0.5714285714285714,\n",
       "  'eval_f1': 0.5161290322580646,\n",
       "  'eval_runtime': 4.0946,\n",
       "  'eval_samples_per_second': 184.879,\n",
       "  'eval_steps_per_second': 2.931,\n",
       "  'epoch': 5.0,\n",
       "  'step': 555},\n",
       " {'loss': 0.3458,\n",
       "  'learning_rate': 7.098482298437486e-05,\n",
       "  'epoch': 6.0,\n",
       "  'step': 666},\n",
       " {'eval_loss': 1.1831581592559814,\n",
       "  'eval_accuracy': 0.9815059445178336,\n",
       "  'eval_recall': 0.5294117647058824,\n",
       "  'eval_precision': 0.6,\n",
       "  'eval_f1': 0.5625,\n",
       "  'eval_runtime': 3.5582,\n",
       "  'eval_samples_per_second': 212.751,\n",
       "  'eval_steps_per_second': 3.373,\n",
       "  'epoch': 6.0,\n",
       "  'step': 666},\n",
       " {'loss': 0.1408,\n",
       "  'learning_rate': 4.7323215322916575e-05,\n",
       "  'epoch': 7.0,\n",
       "  'step': 777},\n",
       " {'eval_loss': 1.527708888053894,\n",
       "  'eval_accuracy': 0.9815059445178336,\n",
       "  'eval_recall': 0.4117647058823529,\n",
       "  'eval_precision': 0.6363636363636364,\n",
       "  'eval_f1': 0.5,\n",
       "  'eval_runtime': 3.665,\n",
       "  'eval_samples_per_second': 206.551,\n",
       "  'eval_steps_per_second': 3.274,\n",
       "  'epoch': 7.0,\n",
       "  'step': 777},\n",
       " {'loss': 0.147,\n",
       "  'learning_rate': 2.3661607661458288e-05,\n",
       "  'epoch': 8.0,\n",
       "  'step': 888},\n",
       " {'eval_loss': 1.4284398555755615,\n",
       "  'eval_accuracy': 0.9841479524438573,\n",
       "  'eval_recall': 0.5294117647058824,\n",
       "  'eval_precision': 0.6923076923076923,\n",
       "  'eval_f1': 0.5999999999999999,\n",
       "  'eval_runtime': 3.2456,\n",
       "  'eval_samples_per_second': 233.242,\n",
       "  'eval_steps_per_second': 3.697,\n",
       "  'epoch': 8.0,\n",
       "  'step': 888},\n",
       " {'loss': 0.1334, 'learning_rate': 0.0, 'epoch': 9.0, 'step': 999},\n",
       " {'eval_loss': 1.439300537109375,\n",
       "  'eval_accuracy': 0.9841479524438573,\n",
       "  'eval_recall': 0.5294117647058824,\n",
       "  'eval_precision': 0.6923076923076923,\n",
       "  'eval_f1': 0.5999999999999999,\n",
       "  'eval_runtime': 3.853,\n",
       "  'eval_samples_per_second': 196.469,\n",
       "  'eval_steps_per_second': 3.114,\n",
       "  'epoch': 9.0,\n",
       "  'step': 999},\n",
       " {'train_runtime': 54.4648,\n",
       "  'train_samples_per_second': 291.821,\n",
       "  'train_steps_per_second': 18.342,\n",
       "  'total_flos': 74375638590240.0,\n",
       "  'train_loss': 0.3950687557369381,\n",
       "  'epoch': 9.0,\n",
       "  'step': 999}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "fV2PWhiFZbP_"
   },
   "outputs": [],
   "source": [
    "training_losses = [element['loss'] for element in trainer.state.log_history if 'loss' in element.keys()]\n",
    "val_losses = [element['eval_loss'] for element in trainer.state.log_history if 'eval_loss' in element.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "5qHIg_KbZ1px"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.title(\"Train and validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks([i for i in range(0,len(val_losses))])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "-hF5zaSDteh1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9841479524438573\n",
      "Precision: 0.7272727272727273\n",
      "Recall: 0.47058823529411764\n",
      "F1: 0.5714285714285714\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "pE2ZM8FXu_aO"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.PrecisionRecallDisplay.html\n",
    "from sklearn.metrics import (precision_recall_curve,\n",
    "                              PrecisionRecallDisplay)\n",
    "\n",
    "disp = PrecisionRecallDisplay.from_predictions(y_test, y_pred)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DG4kSuxgxb8X",
    "outputId": "e2e1b720-c53d-4dbb-ad40-b38ce46d0f1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 191, 271, 359, 554, 598, 618, 729]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/67432457/python-get-the-index-of-two-list-where-the-values-are-the-same\n",
    "print([i for i, v in enumerate(list(y_pred)) if v == list(y_test)[i] and v==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ESeeSJV6x1mi"
   },
   "outputs": [],
   "source": [
    "#X_test.iloc[213]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "peULwIvIyMEo",
    "outputId": "e6209437-c3fe-4ba2-88c7-c01f8a152d14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES    C[C@H]1[C@@H]([C@H]([C@H]([C@@H](O1)O[C@H]2CC[...\n",
      "Name: 2511, dtype: object\n",
      "SMILES    C[C@@H]1[C@H]([C@H](C[C@@H](O1)O[C@H]2CC[C@@]3...\n",
      "Name: 2500, dtype: object\n",
      "SMILES    ClC[C@@H]1CN(C(CCCC(N(C[C@H]2CCl)C3=C2C4=CC=CC...\n",
      "Name: 2496, dtype: object\n",
      "SMILES    C[C@]12CC[C@@H](C[C@H]1CC[C@@H]3[C@@H]2CC[C@]4...\n",
      "Name: 2510, dtype: object\n",
      "SMILES    CN(C)CC[C@H](CSC1=CC=CC=C1)NC2=C(C=C(C=C2)S(=O...\n",
      "Name: 2516, dtype: object\n",
      "SMILES    CC1(C)CCC(=C(C1)C2=CC=C(Cl)C=C2)CN3CCN(CC3)C4=...\n",
      "Name: 2507, dtype: object\n",
      "SMILES    CC1CC(C(C(C=C(C(C(C=CC=C(C(=O)NC2=CC(=O)C(=C(C...\n",
      "Name: 2495, dtype: object\n",
      "SMILES    CC1CC(C(C(C=C(C(C(C=CC=C(C(=O)NC2=CC(=O)C(=C(C...\n",
      "Name: 2494, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#where they equal\n",
    "correct_predictions_indices = [i for i, v in enumerate(list(y_pred)) if v == list(y_test)[i] and v==1]\n",
    "\n",
    "for prediction_index in correct_predictions_indices:\n",
    "    print(X_test.iloc[prediction_index])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "091723f2ddaa43b98f16a4756fd02390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8088374a3d6f4332b642708bbd768add",
      "max": 6771,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d97c6f2aac474568949ac75dcae64a78",
      "value": 6771
     }
    },
    "1bee975014d1451b9ff65d5fe1900ff3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7f77b287bc334e3dba59b9d4c3307e46",
       "IPY_MODEL_091723f2ddaa43b98f16a4756fd02390",
       "IPY_MODEL_5d939c494595405797930594beee593d"
      ],
      "layout": "IPY_MODEL_74135322bba54fa3b6578825dbfac89f"
     }
    },
    "35f2824b2c644032a227f956719fe2a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58da272eecb64352a162858fdfdb9a10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d939c494595405797930594beee593d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58da272eecb64352a162858fdfdb9a10",
      "placeholder": "​",
      "style": "IPY_MODEL_f5f0d29fc0ef4fcfb09f17906c822687",
      "value": " 6.77k/6.77k [00:00&lt;00:00, 224kB/s]"
     }
    },
    "74135322bba54fa3b6578825dbfac89f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f77b287bc334e3dba59b9d4c3307e46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9781d331577d4612bcabe465634f52a2",
      "placeholder": "​",
      "style": "IPY_MODEL_35f2824b2c644032a227f956719fe2a7",
      "value": "Downloading builder script: 100%"
     }
    },
    "8088374a3d6f4332b642708bbd768add": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9781d331577d4612bcabe465634f52a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d97c6f2aac474568949ac75dcae64a78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f5f0d29fc0ef4fcfb09f17906c822687": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
