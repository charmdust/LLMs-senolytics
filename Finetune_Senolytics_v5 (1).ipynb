{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kferES7hG0qd"
   },
   "source": [
    "Test out a custom trainer that takes class weights into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CGUasERv0h7o",
    "outputId": "33ec4fa0-140e-4da3-a29e-e8463b9aae3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 KB\u001b[0m \u001b[31m423.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 KB\u001b[0m \u001b[31m602.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.62.1\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 KB\u001b[0m \u001b[31m85.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/losullivan/.local/lib/python3.10/site-packages (from evaluate) (23.2)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 KB\u001b[0m \u001b[31m681.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/losullivan/.local/lib/python3.10/site-packages (from evaluate) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/losullivan/.local/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/losullivan/.local/lib/python3.10/site-packages (from evaluate) (1.26.1)\n",
      "Collecting huggingface-hub>=0.7.0\n",
      "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 KB\u001b[0m \u001b[31m603.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 KB\u001b[0m \u001b[31m252.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets>=2.0.0\n",
      "  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting dill\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 KB\u001b[0m \u001b[31m65.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=8.0.0\n",
      "  Downloading pyarrow-14.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets>=2.0.0->evaluate) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/losullivan/.local/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.8.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/losullivan/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/losullivan/.local/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->evaluate) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/losullivan/.local/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 KB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/losullivan/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: xxhash, tqdm, pyarrow, multidict, fsspec, frozenlist, filelock, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets, evaluate\n",
      "Successfully installed aiohttp-3.8.6 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.14.6 dill-0.3.7 evaluate-0.4.1 filelock-3.13.1 frozenlist-1.4.0 fsspec-2023.10.0 huggingface-hub-0.19.0 multidict-6.0.4 multiprocess-0.70.15 pyarrow-14.0.0 responses-0.18.0 tqdm-4.66.1 xxhash-3.4.1 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uihhshs2Crhn",
    "outputId": "18f3d6ef-2ec8-48d8-8f38-fcc19c2dca9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers[torch]\n",
      "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/losullivan/.local/lib/python3.10/site-packages (from transformers[torch]) (0.19.0)\n",
      "Requirement already satisfied: filelock in /home/losullivan/.local/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/losullivan/.local/lib/python3.10/site-packages (from transformers[torch]) (23.2)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers[torch]) (5.4.1)\n",
      "Requirement already satisfied: requests in /home/losullivan/.local/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/losullivan/.local/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\n",
      "Collecting tokenizers<0.15,>=0.14\n",
      "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/losullivan/.local/lib/python3.10/site-packages (from transformers[torch]) (1.26.1)\n",
      "Collecting torch!=1.12.0,>=1.10\n",
      "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting accelerate>=0.20.3\n",
      "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /home/losullivan/.local/lib/python3.10/site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/losullivan/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/losullivan/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.8.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m158.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m609.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.1.0\n",
      "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/losullivan/.local/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/losullivan/.local/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers[torch]) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers[torch]) (2020.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/losullivan/.local/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, triton, sympy, safetensors, regex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, accelerate\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.19.0\n",
      "    Uninstalling huggingface-hub-0.19.0:\n",
      "      Successfully uninstalled huggingface-hub-0.19.0\n",
      "Successfully installed accelerate-0.24.1 huggingface-hub-0.17.3 mpmath-1.3.0 networkx-3.2.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.52 nvidia-nvtx-cu12-12.1.105 regex-2023.10.3 safetensors-0.4.0 sympy-1.12 tokenizers-0.14.1 torch-2.1.0 transformers-4.35.0 triton-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esZVROGcDkS8",
    "outputId": "0ed70382-b6e6-488b-f9d1-1a7aaeb7910f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate in /home/losullivan/.local/lib/python3.10/site-packages (0.24.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/losullivan/.local/lib/python3.10/site-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/losullivan/.local/lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/losullivan/.local/lib/python3.10/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/losullivan/.local/lib/python3.10/site-packages (from accelerate) (1.26.1)\n",
      "Requirement already satisfied: psutil in /home/losullivan/.local/lib/python3.10/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: fsspec in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: filelock in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: sympy in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: typing-extensions in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/losullivan/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/losullivan/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.52)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/losullivan/.local/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: requests in /home/losullivan/.local/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/losullivan/.local/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->accelerate) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->accelerate) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->accelerate) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/losullivan/.local/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/losullivan/.local/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2J3_XID0GS7H",
    "outputId": "a1a0986e-7620-4f12-b551-8f1ea1d543a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting optuna\n",
      "  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 KB\u001b[0m \u001b[31m400.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/losullivan/.local/lib/python3.10/site-packages (from optuna) (4.66.1)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.12.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 KB\u001b[0m \u001b[31m484.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/losullivan/.local/lib/python3.10/site-packages (from optuna) (23.2)\n",
      "Requirement already satisfied: numpy in /home/losullivan/.local/lib/python3.10/site-packages (from optuna) (1.26.1)\n",
      "Collecting sqlalchemy>=1.3.0\n",
      "  Downloading SQLAlchemy-2.0.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/losullivan/.local/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.8.0)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.0.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (613 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.2/613.2 KB\u001b[0m \u001b[31m936.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "Successfully installed alembic-1.12.1 colorlog-6.7.0 greenlet-3.0.1 optuna-3.4.0 sqlalchemy-2.0.23\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y_YryaDyTfJr",
    "outputId": "747de117-afa8-48d4-e9a4-3ded951a21be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in /home/losullivan/.local/lib/python3.10/site-packages (2.31.0)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers in /home/losullivan/.local/lib/python3.10/site-packages (4.35.0)\n",
      "Requirement already satisfied: torch in /home/losullivan/.local/lib/python3.10/site-packages (2.1.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting umap-learn\n",
      "  Downloading umap-learn-0.5.4.tar.gz (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.8/90.8 KB\u001b[0m \u001b[31m176.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dill in /home/losullivan/.local/lib/python3.10/site-packages (0.3.7)\n",
      "Collecting ortools\n",
      "  Downloading ortools-9.7.2996-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/losullivan/.local/lib/python3.10/site-packages (from requests) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests) (1.26.5)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/losullivan/.local/lib/python3.10/site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/losullivan/.local/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: filelock in /home/losullivan/.local/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/losullivan/.local/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/losullivan/.local/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/losullivan/.local/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/losullivan/.local/lib/python3.10/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/losullivan/.local/lib/python3.10/site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/losullivan/.local/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: sympy in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: jinja2 in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: networkx in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions in /home/losullivan/.local/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/losullivan/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (9.0.1)\n",
      "Collecting numba>=0.51.2\n",
      "  Downloading numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scikit-learn>=0.22\n",
      "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.3.1\n",
      "  Downloading scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tbb>=2019.0\n",
      "  Downloading tbb-2021.10.0-py2.py3-none-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.7/310.7 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/losullivan/.local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: absl-py>=0.13 in /home/losullivan/.local/lib/python3.10/site-packages (from ortools) (2.0.0)\n",
      "Requirement already satisfied: protobuf>=4.23.3 in /home/losullivan/.local/lib/python3.10/site-packages (from ortools) (4.24.4)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0\n",
      "  Downloading llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/losullivan/.local/lib/python3.10/site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/losullivan/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/losullivan/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Building wheels for collected packages: bs4, umap-learn, pynndescent\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1272 sha256=4049afcc3fd70ef3a454e7b46dca0821922743ee94eaf1429c0a6d9d711e7145\n",
      "  Stored in directory: /home/losullivan/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
      "  Building wheel for umap-learn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for umap-learn: filename=umap_learn-0.5.4-py3-none-any.whl size=86793 sha256=53b6f1ddcfac4b979d1e150a909ab08c2fcd91d590549f39ae97c17507886f6a\n",
      "  Stored in directory: /home/losullivan/.cache/pip/wheels/fb/66/29/199acf5784d0f7b8add6d466175ab45506c96e386ed5dd0633\n",
      "  Building wheel for pynndescent (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55636 sha256=722814a118cf78d2c465bb78546588a65d310c9681d02498db7238d2efbf801f\n",
      "  Stored in directory: /home/losullivan/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
      "Successfully built bs4 umap-learn pynndescent\n",
      "Installing collected packages: tbb, threadpoolctl, scipy, ortools, llvmlite, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, numba, matplotlib, bs4, pynndescent, umap-learn, torchvision\n",
      "Successfully installed bs4-0.0.1 contourpy-1.2.0 cycler-0.12.1 fonttools-4.44.0 joblib-1.3.2 kiwisolver-1.4.5 llvmlite-0.41.1 matplotlib-3.8.1 numba-0.58.1 ortools-9.7.2996 pynndescent-0.5.10 scikit-learn-1.3.2 scipy-1.11.3 tbb-2021.10.0 threadpoolctl-3.2.0 torchvision-0.16.0 umap-learn-0.5.4\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.18.0-py3-none-any.whl (15.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: packaging in /home/losullivan/.local/lib/python3.10/site-packages (from plotly) (23.2)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.18.0 tenacity-8.2.3\n"
     ]
    }
   ],
   "source": [
    "# On Google Colab, you may need to restart the runtime after this\n",
    "!pip install requests bs4 transformers torch torchvision umap-learn matplotlib dill ortools\n",
    "!pip install --upgrade plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "QTxucFCA1Kud",
    "outputId": "457b9a7c-be54-438a-d439-7f3d2e68a97a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.0-py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib!=3.6.1,>=3.3 in /home/losullivan/.local/lib/python3.10/site-packages (from seaborn) (3.8.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/losullivan/.local/lib/python3.10/site-packages (from seaborn) (2.1.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/losullivan/.local/lib/python3.10/site-packages (from seaborn) (1.26.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/losullivan/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/losullivan/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.44.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/losullivan/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/losullivan/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/losullivan/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/losullivan/.local/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/losullivan/.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.2->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/losullivan/.local/lib/python3.10/site-packages (from hyperopt) (1.26.1)\n",
      "Requirement already satisfied: future in /usr/lib/python3/dist-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/losullivan/.local/lib/python3.10/site-packages (from hyperopt) (3.2.1)\n",
      "Requirement already satisfied: scipy in /home/losullivan/.local/lib/python3.10/site-packages (from hyperopt) (1.11.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from hyperopt) (1.16.0)\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cloudpickle\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: tqdm in /home/losullivan/.local/lib/python3.10/site-packages (from hyperopt) (4.66.1)\n",
      "Installing collected packages: py4j, cloudpickle, hyperopt\n",
      "Successfully installed cloudpickle-3.0.0 hyperopt-0.2.7 py4j-0.10.9.7\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ibDj9sQ01PBI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843
    },
    "id": "kA15Apw11PJm",
    "outputId": "bfb3e696-9215-41fd-ecae-40b007f00a0b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>senolytic</th>\n",
       "      <th>Library</th>\n",
       "      <th>Source</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>BalabanJ</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi0</th>\n",
       "      <th>Chi0n</th>\n",
       "      <th>Chi0v</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "      <th>qed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Azaguanine-8</td>\n",
       "      <td>0</td>\n",
       "      <td>Prestwick</td>\n",
       "      <td>Not identified</td>\n",
       "      <td>c12/N=C(\\NC(c1nn[nH]2)=O)/N</td>\n",
       "      <td>3.024307</td>\n",
       "      <td>441.024163</td>\n",
       "      <td>7.844935</td>\n",
       "      <td>5.327239</td>\n",
       "      <td>5.327239</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allantoin</td>\n",
       "      <td>0</td>\n",
       "      <td>Prestwick</td>\n",
       "      <td>Not identified</td>\n",
       "      <td>N1C(NC(C1=O)NC(=O)N)=O</td>\n",
       "      <td>2.534439</td>\n",
       "      <td>225.377060</td>\n",
       "      <td>8.430721</td>\n",
       "      <td>5.379445</td>\n",
       "      <td>5.379445</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.325138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acetazolamide</td>\n",
       "      <td>0</td>\n",
       "      <td>Prestwick</td>\n",
       "      <td>Not identified</td>\n",
       "      <td>c1(S(=O)(=O)N)sc(nn1)NC(=O)C</td>\n",
       "      <td>2.938691</td>\n",
       "      <td>422.352468</td>\n",
       "      <td>10.060478</td>\n",
       "      <td>6.513019</td>\n",
       "      <td>8.146012</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.631859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metformin hydrochloride</td>\n",
       "      <td>0</td>\n",
       "      <td>Prestwick</td>\n",
       "      <td>Not identified</td>\n",
       "      <td>C(NC(=N)N)(=N)N(C)C</td>\n",
       "      <td>3.644486</td>\n",
       "      <td>126.919685</td>\n",
       "      <td>7.439158</td>\n",
       "      <td>5.524564</td>\n",
       "      <td>5.524564</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atracurium besylate</td>\n",
       "      <td>0</td>\n",
       "      <td>Prestwick</td>\n",
       "      <td>Not identified</td>\n",
       "      <td>[N+]1(C(c2c(cc(c(c2)OC)OC)CC1)Cc1cc(c(cc1)OC)O...</td>\n",
       "      <td>0.987040</td>\n",
       "      <td>2158.836594</td>\n",
       "      <td>48.141042</td>\n",
       "      <td>41.328212</td>\n",
       "      <td>41.328212</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>Curcumin</td>\n",
       "      <td>1</td>\n",
       "      <td>GPNCL, ENZO</td>\n",
       "      <td>Source 12 - Yousefzadeh et al, 2018</td>\n",
       "      <td>COC1=C(C=CC(=C1)/C=C/C(=O)CC(=O)/C=C/C2=CC(=C(...</td>\n",
       "      <td>1.958861</td>\n",
       "      <td>822.040000</td>\n",
       "      <td>19.811190</td>\n",
       "      <td>15.008030</td>\n",
       "      <td>15.008030</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.548123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>Dasatinib</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown library, see publication source</td>\n",
       "      <td>Source 13 - Zhu et al, 2015</td>\n",
       "      <td>CC1=C(C(=CC=C1)Cl)NC(=O)C2=CN=C(S2)NC3=CC(=NC(...</td>\n",
       "      <td>1.431593</td>\n",
       "      <td>1111.432171</td>\n",
       "      <td>23.371668</td>\n",
       "      <td>18.507135</td>\n",
       "      <td>20.079560</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>Navitoclax</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown library, see publication source</td>\n",
       "      <td>Source 14 - Zhu et al, 2016</td>\n",
       "      <td>CC1(CCC(=C(C1)CN2CCN(CC2)C3=CC=C(C=C3)C(=O)NS(...</td>\n",
       "      <td>1.017180</td>\n",
       "      <td>2532.551918</td>\n",
       "      <td>46.408991</td>\n",
       "      <td>36.449290</td>\n",
       "      <td>39.654708</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>A1331852</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown library, see publication source</td>\n",
       "      <td>Source 15 - Zhu et al, 2017</td>\n",
       "      <td>O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=CC=C(C5=C(...</td>\n",
       "      <td>0.969918</td>\n",
       "      <td>2030.733706</td>\n",
       "      <td>32.569974</td>\n",
       "      <td>26.984648</td>\n",
       "      <td>27.801144</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>A1155463</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown library, see publication source</td>\n",
       "      <td>Source 15 - Zhu et al, 2017</td>\n",
       "      <td>O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=NC(C(O)=O)...</td>\n",
       "      <td>1.105426</td>\n",
       "      <td>1978.955255</td>\n",
       "      <td>32.915274</td>\n",
       "      <td>25.878524</td>\n",
       "      <td>27.511517</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.131321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2523 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name  senolytic  \\\n",
       "0                Azaguanine-8          0   \n",
       "1                   Allantoin          0   \n",
       "2               Acetazolamide          0   \n",
       "3     Metformin hydrochloride          0   \n",
       "4         Atracurium besylate          0   \n",
       "...                       ...        ...   \n",
       "2518                 Curcumin          1   \n",
       "2519                Dasatinib          1   \n",
       "2520               Navitoclax          1   \n",
       "2521                 A1331852          1   \n",
       "2522                 A1155463          1   \n",
       "\n",
       "                                      Library  \\\n",
       "0                                   Prestwick   \n",
       "1                                   Prestwick   \n",
       "2                                   Prestwick   \n",
       "3                                   Prestwick   \n",
       "4                                   Prestwick   \n",
       "...                                       ...   \n",
       "2518                              GPNCL, ENZO   \n",
       "2519  Unknown library, see publication source   \n",
       "2520  Unknown library, see publication source   \n",
       "2521  Unknown library, see publication source   \n",
       "2522  Unknown library, see publication source   \n",
       "\n",
       "                                   Source  \\\n",
       "0                          Not identified   \n",
       "1                          Not identified   \n",
       "2                          Not identified   \n",
       "3                          Not identified   \n",
       "4                          Not identified   \n",
       "...                                   ...   \n",
       "2518  Source 12 - Yousefzadeh et al, 2018   \n",
       "2519          Source 13 - Zhu et al, 2015   \n",
       "2520          Source 14 - Zhu et al, 2016   \n",
       "2521          Source 15 - Zhu et al, 2017   \n",
       "2522          Source 15 - Zhu et al, 2017   \n",
       "\n",
       "                                                 SMILES  BalabanJ  \\\n",
       "0                           c12/N=C(\\NC(c1nn[nH]2)=O)/N  3.024307   \n",
       "1                                N1C(NC(C1=O)NC(=O)N)=O  2.534439   \n",
       "2                          c1(S(=O)(=O)N)sc(nn1)NC(=O)C  2.938691   \n",
       "3                                   C(NC(=N)N)(=N)N(C)C  3.644486   \n",
       "4     [N+]1(C(c2c(cc(c(c2)OC)OC)CC1)Cc1cc(c(cc1)OC)O...  0.987040   \n",
       "...                                                 ...       ...   \n",
       "2518  COC1=C(C=CC(=C1)/C=C/C(=O)CC(=O)/C=C/C2=CC(=C(...  1.958861   \n",
       "2519  CC1=C(C(=CC=C1)Cl)NC(=O)C2=CN=C(S2)NC3=CC(=NC(...  1.431593   \n",
       "2520  CC1(CCC(=C(C1)CN2CCN(CC2)C3=CC=C(C=C3)C(=O)NS(...  1.017180   \n",
       "2521  O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=CC=C(C5=C(...  0.969918   \n",
       "2522  O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=NC(C(O)=O)...  1.105426   \n",
       "\n",
       "          BertzCT       Chi0      Chi0n      Chi0v  ...  fr_sulfonamd  \\\n",
       "0      441.024163   7.844935   5.327239   5.327239  ...             0   \n",
       "1      225.377060   8.430721   5.379445   5.379445  ...             0   \n",
       "2      422.352468  10.060478   6.513019   8.146012  ...             1   \n",
       "3      126.919685   7.439158   5.524564   5.524564  ...             0   \n",
       "4     2158.836594  48.141042  41.328212  41.328212  ...             0   \n",
       "...           ...        ...        ...        ...  ...           ...   \n",
       "2518   822.040000  19.811190  15.008030  15.008030  ...             0   \n",
       "2519  1111.432171  23.371668  18.507135  20.079560  ...             0   \n",
       "2520  2532.551918  46.408991  36.449290  39.654708  ...             1   \n",
       "2521  2030.733706  32.569974  26.984648  27.801144  ...             0   \n",
       "2522  1978.955255  32.915274  25.878524  27.511517  ...             0   \n",
       "\n",
       "      fr_sulfone  fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiocyan  \\\n",
       "0              0                  0             0            0            0   \n",
       "1              0                  0             0            0            0   \n",
       "2              0                  0             0            0            0   \n",
       "3              0                  0             0            0            0   \n",
       "4              0                  0             0            0            0   \n",
       "...          ...                ...           ...          ...          ...   \n",
       "2518           0                  0             0            0            0   \n",
       "2519           0                  0             0            1            0   \n",
       "2520           1                  0             0            0            0   \n",
       "2521           0                  0             0            1            0   \n",
       "2522           0                  0             0            2            0   \n",
       "\n",
       "      fr_thiophene  fr_unbrch_alkane  fr_urea       qed  \n",
       "0                0                 0        0  0.430316  \n",
       "1                0                 0        2  0.325138  \n",
       "2                0                 0        0  0.631859  \n",
       "3                0                 0        0  0.248785  \n",
       "4                0                 4        0  0.038349  \n",
       "...            ...               ...      ...       ...  \n",
       "2518             0                 0        0  0.548123  \n",
       "2519             0                 0        0  0.465717  \n",
       "2520             0                 0        0  0.104649  \n",
       "2521             0                 0        0  0.185260  \n",
       "2522             0                 1        0  0.131321  \n",
       "\n",
       "[2523 rows x 205 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Senolytoc dataset - labelled\n",
    "senolytics_df = pd.read_csv('list_of_compounds_for_training.csv')\n",
    "senolytics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "OrOR9_0E1cNU",
    "outputId": "5ab03543-5a76-409c-8e50-69e6aba570ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>senolytic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12/N=C(\\NC(c1nn[nH]2)=O)/N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1C(NC(C1=O)NC(=O)N)=O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1(S(=O)(=O)N)sc(nn1)NC(=O)C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C(NC(=N)N)(=N)N(C)C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[N+]1(C(c2c(cc(c(c2)OC)OC)CC1)Cc1cc(c(cc1)OC)O...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>COC1=C(C=CC(=C1)/C=C/C(=O)CC(=O)/C=C/C2=CC(=C(...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>CC1=C(C(=CC=C1)Cl)NC(=O)C2=CN=C(S2)NC3=CC(=NC(...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>CC1(CCC(=C(C1)CN2CCN(CC2)C3=CC=C(C=C3)C(=O)NS(...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=CC=C(C5=C(...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=NC(C(O)=O)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2523 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 SMILES  senolytic\n",
       "0                           c12/N=C(\\NC(c1nn[nH]2)=O)/N          0\n",
       "1                                N1C(NC(C1=O)NC(=O)N)=O          0\n",
       "2                          c1(S(=O)(=O)N)sc(nn1)NC(=O)C          0\n",
       "3                                   C(NC(=N)N)(=N)N(C)C          0\n",
       "4     [N+]1(C(c2c(cc(c(c2)OC)OC)CC1)Cc1cc(c(cc1)OC)O...          0\n",
       "...                                                 ...        ...\n",
       "2518  COC1=C(C=CC(=C1)/C=C/C(=O)CC(=O)/C=C/C2=CC(=C(...          1\n",
       "2519  CC1=C(C(=CC=C1)Cl)NC(=O)C2=CN=C(S2)NC3=CC(=NC(...          1\n",
       "2520  CC1(CCC(=C(C1)CN2CCN(CC2)C3=CC=C(C=C3)C(=O)NS(...          1\n",
       "2521  O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=CC=C(C5=C(...          1\n",
       "2522  O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=NC(C(O)=O)...          1\n",
       "\n",
       "[2523 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = senolytics_df[['SMILES', 'senolytic']]\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "OCBDQUq_SA8_",
    "outputId": "cf6c27fe-b6d2-42c4-b299-6b0977b5b4a9"
   },
   "outputs": [],
   "source": [
    "# # Subset for testing new code\n",
    "\n",
    "#training_df =  training_df.groupby('senolytic', group_keys=False).apply(lambda x: x.sample(frac=0.1))\n",
    "#training_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mex0yzEfSnnc",
    "outputId": "c9c972e6-6ddd-4efe-ea79-82a2f72909ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022988505747126436"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check sample is representative of the actual distribution\n",
    "sum(training_df['senolytic'])/len(training_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "252E9DAjMdp1"
   },
   "source": [
    "## Setup  \n",
    "from https://github.com/deepchem/deepchem/blob/master/examples/tutorials/Transfer_Learning_With_ChemBERTa_Transformers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CmtNWHoS5ScF"
   },
   "outputs": [],
   "source": [
    "# !curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
    "# import conda_installer\n",
    "# conda_installer.install()\n",
    "# !/root/miniconda/bin/conda info -e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yZeie3xmM7k2"
   },
   "outputs": [],
   "source": [
    "# #!pip install --pre deepchem\n",
    "# import deepchem\n",
    "# deepchem.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TFSNaQckNB_r"
   },
   "outputs": [],
   "source": [
    "#from rdkit import Chem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3QihT8zSfVL"
   },
   "source": [
    "Imports from https://github.com/seyonechithrananda/bert-loves-chemistry/blob/master/chemberta/visualization/ChemBERTA_dimensionaliy_reduction_BBBP.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x6sOAy1-RX7o"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from rdkit import Chem, DataStructs\n",
    "#from rdkit.Chem.rdchem import Mol\n",
    "#from rdkit.Chem.MolStandardize.rdMolStandardize import LargestFragmentChooser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCOQKbIPDLAt"
   },
   "source": [
    "## Finetune\n",
    "https://huggingface.co/docs/transformers/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtKRX78_524s",
    "outputId": "7888feb8-d87c-427f-9a83-43677acaa74c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 3428210 parameters.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepChem/ChemBERTa-77M-MTR\")\n",
    "config = AutoConfig.from_pretrained(\"DeepChem/ChemBERTa-77M-MTR\")\n",
    "config.num_hidden_layers += 1\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"DeepChem/ChemBERTa-77M-MTR\", num_labels=2, problem_type = \"single_label_classification\")\n",
    "\n",
    "print(f\"Model size: {model.num_parameters()} parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0jU4hDaB9ZeP"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = training_df[['SMILES']]\n",
    "y = training_df['senolytic']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y) # the data should be shuffled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1tJA6uNe9FrY"
   },
   "outputs": [],
   "source": [
    "# Dataset set up\n",
    "\n",
    "#smiles_train = X_train['SMILES'].astype(str).tolist()\n",
    "#smiles_test = X_test['SMILES'].astype(str).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BiniuqzuA2KI"
   },
   "outputs": [],
   "source": [
    "# # https://huggingface.co/transformers/v3.2.0/custom_datasets.html -> does not work!!\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "\n",
    "\n",
    "# class SenolyticsDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, encodings, labels):\n",
    "#         self.encodings = encodings\n",
    "#         self.labels = labels\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         #print(idx)\n",
    "#         input_ids = torch.tensor(self.encodings['input_ids'])\n",
    "#         if self.labels is not None and idx in self.labels.keys():\n",
    "#             target_ids = torch.tensor(self.labels[idx])\n",
    "#         else:\n",
    "#             # Handle the case where self.labels is None or idx is out of range\n",
    "#             target_ids = None\n",
    "#         return {\"input_ids\": input_ids, \"labels\": target_ids}\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "# #train_dataset = IMDbDataset(train_encodings, train_labels)\n",
    "# #val_dataset = IMDbDataset(val_encodings, val_labels)\n",
    "# #test_dataset = IMDbDataset(test_encodings, test_labels)\n",
    "\n",
    "# tokenized_train = tokenizer(smiles_train, padding=True, truncation=True, max_length=None, return_tensors='pt')\n",
    "# tokenized_test = tokenizer(smiles_test, padding=True, truncation=True, max_length=None, return_tensors='pt')\n",
    "\n",
    "# train_dataset = SenolyticsDataset(tokenized_train, y_train)\n",
    "# test_dataset = SenolyticsDataset(tokenized_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Yh4grRWQjsLj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#Current version\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, labels, tokenizer):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        # Tokenize the SMILES strings and store them\n",
    "        self.encodings = self.tokenize_smiles(dataframe['SMILES'].tolist())\n",
    "\n",
    "        # Store the labels\n",
    "        self.labels = labels.tolist()\n",
    "\n",
    "    def tokenize_smiles(self, smiles_list):\n",
    "        return self.tokenizer(\n",
    "            smiles_list,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=None,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        }\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rTFXIMO6jycF"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train, y_train, tokenizer)\n",
    "test_dataset = Dataset(X_test, y_test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wHP3C4JUyB9g",
    "outputId": "b5b926e7-f64b-49ac-9409-210adf4f5c04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset[-1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3Uy-yE46GZk7"
   },
   "outputs": [],
   "source": [
    "def optuna_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32, 64, 128]),\n",
    "        \"weight_decay\": trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qj8lOM-WBXp5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 13:28:20.261126: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-09 13:28:20.261155: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-09 13:28:20.261178: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-09 13:28:20.266512: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 13:28:20.874622: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# many more parameters to experiment with https://huggingface.co/docs/transformers/v4.33.2/en/main_classes/trainer#transformers.TrainingArguments\n",
    "training_args = TrainingArguments(output_dir=\"test_1\", load_best_model_at_end=True, evaluation_strategy='epoch',\n",
    "    logging_strategy=\"epoch\", save_strategy=\"epoch\",per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,optim=\"adamw_torch\", num_train_epochs=10) # switch optimizer to avoid warning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "1bee975014d1451b9ff65d5fe1900ff3",
      "7f77b287bc334e3dba59b9d4c3307e46",
      "091723f2ddaa43b98f16a4756fd02390",
      "5d939c494595405797930594beee593d",
      "74135322bba54fa3b6578825dbfac89f",
      "9781d331577d4612bcabe465634f52a2",
      "35f2824b2c644032a227f956719fe2a7",
      "8088374a3d6f4332b642708bbd768add",
      "d97c6f2aac474568949ac75dcae64a78",
      "58da272eecb64352a162858fdfdb9a10",
      "f5f0d29fc0ef4fcfb09f17906c822687"
     ]
    },
    "id": "-kEDerSWDgSQ",
    "outputId": "27dbcb00-5bda-487f-9804-33b7284e05a7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KWaaH8HzEqxl"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/67457480/how-to-get-the-accuracy-per-epoch-or-step-for-the-huggingface-transformers-train\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    metrics = [\"accuracy\", \"recall\", \"precision\", \"f1\"] #List of metrics to return\n",
    "    metric={}\n",
    "    for met in metrics:\n",
    "       metric[met] = evaluate.load(met)\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    metric_res={}\n",
    "    for met in metrics:\n",
    "       metric_res[met]=metric[met].compute(predictions=predictions, references=labels)[met]\n",
    "    return metric_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pd8k07IiLvnt",
    "outputId": "ee4e1598-d1dd-4d1c-dcb0-5c1de3765994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51188406 21.53658537]\n"
     ]
    }
   ],
   "source": [
    "# Class weights\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\",classes=np.unique(y_train),y=y_train)\n",
    "\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1Vgd0ucdLaeI"
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/main/main_classes/trainer\n",
    "\n",
    "from torch import nn\n",
    "from transformers import Trainer\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\").long()\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss with class_weights=balanced from above\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, device=model.device, dtype=torch.float))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aUdFmJL-iq4O"
   },
   "outputs": [],
   "source": [
    "import hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zEILHiN8ktsH",
    "outputId": "a7728741-ed0f-4cca-f9bf-34f59c99d12d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4FIGlc2GlkOl",
    "outputId": "0b529f3d-1e13-49fb-bbee-96e5f5e0c402"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "3cvzbNImqWMH"
   },
   "outputs": [],
   "source": [
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7HzwkE3BlmMS"
   },
   "outputs": [],
   "source": [
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "tz7rWAHSmjfP",
    "outputId": "b78a7ac2-9311-4960-add0-d91437b788b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12/N=C(\\NC(c1nn[nH]2)=O)/N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1C(NC(C1=O)NC(=O)N)=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1(S(=O)(=O)N)sc(nn1)NC(=O)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C(NC(=N)N)(=N)N(C)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[N+]1(C(c2c(cc(c(c2)OC)OC)CC1)Cc1cc(c(cc1)OC)O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>COC1=C(C=CC(=C1)/C=C/C(=O)CC(=O)/C=C/C2=CC(=C(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>CC1=C(C(=CC=C1)Cl)NC(=O)C2=CN=C(S2)NC3=CC(=NC(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>CC1(CCC(=C(C1)CN2CCN(CC2)C3=CC=C(C=C3)C(=O)NS(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=CC=C(C5=C(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=NC(C(O)=O)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2523 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0                           c12/N=C(\\NC(c1nn[nH]2)=O)/N\n",
       "1                                N1C(NC(C1=O)NC(=O)N)=O\n",
       "2                          c1(S(=O)(=O)N)sc(nn1)NC(=O)C\n",
       "3                                   C(NC(=N)N)(=N)N(C)C\n",
       "4     [N+]1(C(c2c(cc(c(c2)OC)OC)CC1)Cc1cc(c(cc1)OC)O...\n",
       "...                                                 ...\n",
       "2518  COC1=C(C=CC(=C1)/C=C/C(=O)CC(=O)/C=C/C2=CC(=C(...\n",
       "2519  CC1=C(C(=CC=C1)Cl)NC(=O)C2=CN=C(S2)NC3=CC(=NC(...\n",
       "2520  CC1(CCC(=C(C1)CN2CCN(CC2)C3=CC=C(C=C3)C(=O)NS(...\n",
       "2521  O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=CC=C(C5=C(...\n",
       "2522  O=C(NC1=NC(C=CC=C2)=C2S1)C3=C(CN(C4=NC(C(O)=O)...\n",
       "\n",
       "[2523 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "cgCjsT4-KDXS",
    "outputId": "34685464-af17-486b-f7c8-b1b6fff548ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 13:28:23,696] A new study created in memory with name: hyper-parameter-search\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8468, 'learning_rate': 0.0006796748158941389, 'epoch': 1.98}\n",
      "{'loss': 0.7282, 'learning_rate': 0.00023544291008097628, 'epoch': 3.95}\n",
      "{'train_runtime': 19.6422, 'train_samples_per_second': 513.691, 'train_steps_per_second': 64.402, 'train_loss': 0.769074258314291, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1714782565832138, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.6728, 'eval_samples_per_second': 137.496, 'eval_steps_per_second': 17.425, 'epoch': 5.0}\n",
      "{'loss': 0.8099, 'learning_rate': 0.0006796748158941389, 'epoch': 1.98}\n",
      "{'loss': 0.7113, 'learning_rate': 0.00023544291008097628, 'epoch': 3.95}\n",
      "{'train_runtime': 23.9679, 'train_samples_per_second': 420.98, 'train_steps_per_second': 52.779, 'train_loss': 0.7342029677078187, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16774167120456696, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.8012, 'eval_samples_per_second': 132.852, 'eval_steps_per_second': 16.837, 'epoch': 5.0}\n",
      "{'loss': 0.8188, 'learning_rate': 0.0006796748158941389, 'epoch': 1.98}\n",
      "{'loss': 0.722, 'learning_rate': 0.00023544291008097628, 'epoch': 3.95}\n",
      "{'train_runtime': 22.0637, 'train_samples_per_second': 457.312, 'train_steps_per_second': 57.334, 'train_loss': 0.7551237928066329, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1726067215204239, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 4.016, 'eval_samples_per_second': 125.747, 'eval_steps_per_second': 15.936, 'epoch': 5.0}\n",
      "{'loss': 0.7846, 'learning_rate': 0.0006796748158941389, 'epoch': 1.98}\n",
      "{'loss': 0.766, 'learning_rate': 0.00023544291008097628, 'epoch': 3.95}\n",
      "{'train_runtime': 20.8086, 'train_samples_per_second': 485.136, 'train_steps_per_second': 60.792, 'train_loss': 0.7613969403293293, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16085176169872284, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.7385, 'eval_samples_per_second': 134.812, 'eval_steps_per_second': 16.851, 'epoch': 5.0}\n",
      "{'loss': 0.7734, 'learning_rate': 0.0006796748158941389, 'epoch': 1.98}\n",
      "{'loss': 0.7481, 'learning_rate': 0.00023544291008097628, 'epoch': 3.95}\n",
      "{'train_runtime': 24.6573, 'train_samples_per_second': 409.413, 'train_steps_per_second': 51.303, 'train_loss': 0.7418275252632472, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-09 13:30:56,210] Trial 0 finished with value: 0.0 and parameters: {'learning_rate': 0.0011239067217073018, 'weight_decay': 0.00010895279260432418, 'num_train_epochs': 5}. Best is trial 0 with value: 0.0.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1570032387971878, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.3276, 'eval_samples_per_second': 151.462, 'eval_steps_per_second': 18.933, 'epoch': 5.0}\n",
      "{'loss': 0.7599, 'learning_rate': 0.00042533396629276305, 'epoch': 1.98}\n",
      "{'loss': 0.6813, 'learning_rate': 9.968764834986634e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 18.9424, 'train_samples_per_second': 426.133, 'train_steps_per_second': 53.425, 'train_loss': 0.7165090745616808, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17606176435947418, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.7976, 'eval_samples_per_second': 132.98, 'eval_steps_per_second': 16.853, 'epoch': 4.0}\n",
      "{'loss': 0.7537, 'learning_rate': 0.00042533396629276305, 'epoch': 1.98}\n",
      "{'loss': 0.6837, 'learning_rate': 9.968764834986634e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 13.9097, 'train_samples_per_second': 580.316, 'train_steps_per_second': 72.755, 'train_loss': 0.7142877903851595, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17070737481117249, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 4.2151, 'eval_samples_per_second': 119.807, 'eval_steps_per_second': 15.183, 'epoch': 4.0}\n",
      "{'loss': 0.755, 'learning_rate': 0.00042533396629276305, 'epoch': 1.98}\n",
      "{'loss': 0.6754, 'learning_rate': 9.968764834986634e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 20.4821, 'train_samples_per_second': 394.1, 'train_steps_per_second': 49.409, 'train_loss': 0.7110565123350724, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16750973463058472, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.6955, 'eval_samples_per_second': 136.652, 'eval_steps_per_second': 17.318, 'epoch': 4.0}\n",
      "{'loss': 0.6817, 'learning_rate': 0.00042533396629276305, 'epoch': 1.98}\n",
      "{'loss': 0.6409, 'learning_rate': 9.968764834986634e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 18.3938, 'train_samples_per_second': 439.06, 'train_steps_per_second': 55.018, 'train_loss': 0.6629796103526481, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14235882461071014, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.7271, 'eval_samples_per_second': 135.225, 'eval_steps_per_second': 16.903, 'epoch': 4.0}\n",
      "{'loss': 0.6143, 'learning_rate': 0.00042533396629276305, 'epoch': 1.98}\n",
      "{'loss': 0.5865, 'learning_rate': 9.968764834986634e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 13.8243, 'train_samples_per_second': 584.19, 'train_steps_per_second': 73.205, 'train_loss': 0.6002428032192788, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-09 13:33:01,477] Trial 1 finished with value: 0.0 and parameters: {'learning_rate': 0.0008406991677505396, 'weight_decay': 6.211302157539118e-05, 'num_train_epochs': 4}. Best is trial 0 with value: 0.0.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16640886664390564, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.3324, 'eval_samples_per_second': 151.24, 'eval_steps_per_second': 18.905, 'epoch': 4.0}\n",
      "{'loss': 1.7201, 'learning_rate': 0.004977183341380332, 'epoch': 1.98}\n",
      "{'loss': 1.0517, 'learning_rate': 0.00011665273456360152, 'epoch': 3.95}\n",
      "{'train_runtime': 18.3422, 'train_samples_per_second': 440.078, 'train_steps_per_second': 55.173, 'train_loss': 1.3738797460148928, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20205111801624298, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.7073, 'eval_samples_per_second': 136.218, 'eval_steps_per_second': 17.263, 'epoch': 4.0}\n",
      "{'loss': 1.4075, 'learning_rate': 0.004977183341380332, 'epoch': 1.98}\n",
      "{'loss': 1.0013, 'learning_rate': 0.00011665273456360152, 'epoch': 3.95}\n",
      "{'train_runtime': 20.2421, 'train_samples_per_second': 398.772, 'train_steps_per_second': 49.995, 'train_loss': 1.1948053610654688, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21323513984680176, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 4.0348, 'eval_samples_per_second': 125.161, 'eval_steps_per_second': 15.862, 'epoch': 4.0}\n",
      "{'loss': 1.3191, 'learning_rate': 0.004977183341380332, 'epoch': 1.98}\n",
      "{'loss': 1.0226, 'learning_rate': 0.00011665273456360152, 'epoch': 3.95}\n",
      "{'train_runtime': 20.5508, 'train_samples_per_second': 392.783, 'train_steps_per_second': 49.244, 'train_loss': 1.1617943241662188, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22868575155735016, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.9448, 'eval_samples_per_second': 128.015, 'eval_steps_per_second': 16.224, 'epoch': 4.0}\n",
      "{'loss': 1.7214, 'learning_rate': 0.004977183341380332, 'epoch': 1.98}\n",
      "{'loss': 1.0061, 'learning_rate': 0.00011665273456360152, 'epoch': 3.95}\n",
      "{'train_runtime': 16.9882, 'train_samples_per_second': 475.389, 'train_steps_per_second': 59.571, 'train_loss': 1.3563945500747017, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16840432584285736, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.9006, 'eval_samples_per_second': 129.212, 'eval_steps_per_second': 16.151, 'epoch': 4.0}\n",
      "{'loss': 1.5788, 'learning_rate': 0.004977183341380332, 'epoch': 1.98}\n",
      "{'loss': 1.0133, 'learning_rate': 0.00011665273456360152, 'epoch': 3.95}\n",
      "{'train_runtime': 15.4945, 'train_samples_per_second': 521.216, 'train_steps_per_second': 65.313, 'train_loss': 1.2894292857807144, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-09 13:35:13,790] Trial 2 finished with value: 0.0 and parameters: {'learning_rate': 0.009837713948197062, 'weight_decay': 0.004338118853316637, 'num_train_epochs': 4}. Best is trial 0 with value: 0.0.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1652437448501587, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.7144, 'eval_samples_per_second': 135.69, 'eval_steps_per_second': 16.961, 'epoch': 4.0}\n",
      "{'loss': 0.7477, 'learning_rate': 0.0004998555500147949, 'epoch': 1.98}\n",
      "{'loss': 0.5281, 'learning_rate': 0.0003032168600011069, 'epoch': 3.95}\n",
      "{'loss': 0.3859, 'learning_rate': 0.0001065781699874189, 'epoch': 5.93}\n",
      "{'train_runtime': 30.2017, 'train_samples_per_second': 467.721, 'train_steps_per_second': 58.639, 'train_loss': 0.5140614092249038, 'epoch': 7.0}\n",
      "{'eval_loss': 0.17168667912483215, 'eval_accuracy': 0.9782178217821782, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5384615384615384, 'eval_f1': 0.5599999999999999, 'eval_runtime': 3.922, 'eval_samples_per_second': 128.76, 'eval_steps_per_second': 16.318, 'epoch': 7.0}\n",
      "{'loss': 0.5427, 'learning_rate': 0.0004998555500147949, 'epoch': 1.98}\n",
      "{'loss': 0.4223, 'learning_rate': 0.0003032168600011069, 'epoch': 3.95}\n",
      "{'loss': 0.2617, 'learning_rate': 0.0001065781699874189, 'epoch': 5.93}\n",
      "{'train_runtime': 35.1749, 'train_samples_per_second': 401.593, 'train_steps_per_second': 50.348, 'train_loss': 0.3911752296934553, 'epoch': 7.0}\n",
      "{'eval_loss': 0.12292348593473434, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.6215, 'eval_samples_per_second': 139.444, 'eval_steps_per_second': 17.672, 'epoch': 7.0}\n",
      "{'loss': 0.5515, 'learning_rate': 0.0004998555500147949, 'epoch': 1.98}\n",
      "{'loss': 0.4277, 'learning_rate': 0.0003032168600011069, 'epoch': 3.95}\n",
      "{'loss': 0.2805, 'learning_rate': 0.0001065781699874189, 'epoch': 5.93}\n",
      "{'train_runtime': 31.3587, 'train_samples_per_second': 450.465, 'train_steps_per_second': 56.476, 'train_loss': 0.3994525799570886, 'epoch': 7.0}\n",
      "{'eval_loss': 0.09374646842479706, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.6666666666666666, 'eval_precision': 0.8888888888888888, 'eval_f1': 0.761904761904762, 'eval_runtime': 4.2229, 'eval_samples_per_second': 119.587, 'eval_steps_per_second': 15.156, 'epoch': 7.0}\n",
      "{'loss': 0.4707, 'learning_rate': 0.0004998555500147949, 'epoch': 1.98}\n",
      "{'loss': 0.416, 'learning_rate': 0.0003032168600011069, 'epoch': 3.95}\n",
      "{'loss': 0.2946, 'learning_rate': 0.0001065781699874189, 'epoch': 5.93}\n",
      "{'train_runtime': 25.8892, 'train_samples_per_second': 545.903, 'train_steps_per_second': 68.407, 'train_loss': 0.3762272469139853, 'epoch': 7.0}\n",
      "{'eval_loss': 0.06754235923290253, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.8181818181818182, 'eval_precision': 1.0, 'eval_f1': 0.9, 'eval_runtime': 4.0457, 'eval_samples_per_second': 124.575, 'eval_steps_per_second': 15.572, 'epoch': 7.0}\n",
      "{'loss': 0.3791, 'learning_rate': 0.0004998555500147949, 'epoch': 1.98}\n",
      "{'loss': 0.3563, 'learning_rate': 0.0003032168600011069, 'epoch': 3.95}\n",
      "{'loss': 0.2648, 'learning_rate': 0.0001065781699874189, 'epoch': 5.93}\n",
      "{'train_runtime': 28.9316, 'train_samples_per_second': 488.496, 'train_steps_per_second': 61.213, 'train_loss': 0.32114808886553325, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 13:38:26,516] Trial 3 finished with value: 0.6686946778711484 and parameters: {'learning_rate': 0.0006964942400284829, 'weight_decay': 0.00011317227506005459, 'num_train_epochs': 7}. Best is trial 3 with value: 0.6686946778711484.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12149006128311157, 'eval_accuracy': 0.9861111111111112, 'eval_recall': 0.36363636363636365, 'eval_precision': 1.0, 'eval_f1': 0.5333333333333333, 'eval_runtime': 3.839, 'eval_samples_per_second': 131.283, 'eval_steps_per_second': 16.41, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6617, 'learning_rate': 9.971228557013705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.4227, 'learning_rate': 6.04863667777936e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2901, 'learning_rate': 2.1260447985450148e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 31.1641, 'train_samples_per_second': 453.278, 'train_steps_per_second': 56.828, 'train_loss': 0.42072809651233195, 'epoch': 7.0}\n",
      "{'eval_loss': 0.17521801590919495, 'eval_accuracy': 0.9722772277227723, 'eval_recall': 0.4166666666666667, 'eval_precision': 0.4166666666666667, 'eval_f1': 0.4166666666666667, 'eval_runtime': 3.9566, 'eval_samples_per_second': 127.635, 'eval_steps_per_second': 16.175, 'epoch': 7.0}\n",
      "{'loss': 0.3169, 'learning_rate': 9.971228557013705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1635, 'learning_rate': 6.04863667777936e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0948, 'learning_rate': 2.1260447985450148e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 35.1009, 'train_samples_per_second': 402.44, 'train_steps_per_second': 50.455, 'train_loss': 0.17319878395636293, 'epoch': 7.0}\n",
      "{'eval_loss': 0.1466241031885147, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.8613, 'eval_samples_per_second': 130.784, 'eval_steps_per_second': 16.575, 'epoch': 7.0}\n",
      "{'loss': 0.189, 'learning_rate': 9.971228557013705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0899, 'learning_rate': 6.04863667777936e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0269, 'learning_rate': 2.1260447985450148e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 35.4565, 'train_samples_per_second': 398.404, 'train_steps_per_second': 49.949, 'train_loss': 0.08696553028619336, 'epoch': 7.0}\n",
      "{'eval_loss': 0.008585195057094097, 'eval_accuracy': 0.998019801980198, 'eval_recall': 1.0, 'eval_precision': 0.9230769230769231, 'eval_f1': 0.9600000000000001, 'eval_runtime': 3.5092, 'eval_samples_per_second': 143.907, 'eval_steps_per_second': 18.238, 'epoch': 7.0}\n",
      "{'loss': 0.1426, 'learning_rate': 9.971228557013705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0265, 'learning_rate': 6.04863667777936e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0008, 'learning_rate': 2.1260447985450148e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 27.3473, 'train_samples_per_second': 516.797, 'train_steps_per_second': 64.76, 'train_loss': 0.04847367867650722, 'epoch': 7.0}\n",
      "{'eval_loss': 0.01520561520010233, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.0117, 'eval_samples_per_second': 125.631, 'eval_steps_per_second': 15.704, 'epoch': 7.0}\n",
      "{'loss': 0.0623, 'learning_rate': 9.971228557013705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0061, 'learning_rate': 6.04863667777936e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0, 'learning_rate': 2.1260447985450148e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 29.8389, 'train_samples_per_second': 473.643, 'train_steps_per_second': 59.352, 'train_loss': 0.019308210958910495, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 13:41:45,514] Trial 4 finished with value: 0.7904472049689442 and parameters: {'learning_rate': 0.0001389382043624805, 'weight_decay': 0.0005920457471593741, 'num_train_epochs': 7}. Best is trial 4 with value: 0.7904472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015922710299491882, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.588, 'eval_samples_per_second': 140.469, 'eval_steps_per_second': 17.559, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9673, 'learning_rate': 0.0021292159138506608, 'epoch': 1.98}\n",
      "{'loss': 0.8487, 'learning_rate': 0.0016047784966460644, 'epoch': 3.95}\n",
      "{'loss': 0.8085, 'learning_rate': 0.0010803410794414682, 'epoch': 5.93}\n",
      "{'loss': 0.7649, 'learning_rate': 0.0005559036622368721, 'epoch': 7.91}\n",
      "{'loss': 0.7568, 'learning_rate': 3.1466245032275774e-05, 'epoch': 9.88}\n",
      "{'train_runtime': 44.1363, 'train_samples_per_second': 457.22, 'train_steps_per_second': 57.322, 'train_loss': 0.834870159767362, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18168622255325317, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.7886, 'eval_samples_per_second': 133.295, 'eval_steps_per_second': 16.893, 'epoch': 10.0}\n",
      "{'loss': 0.9117, 'learning_rate': 0.0021292159138506608, 'epoch': 1.98}\n",
      "{'loss': 0.8216, 'learning_rate': 0.0016047784966460644, 'epoch': 3.95}\n",
      "{'loss': 0.7949, 'learning_rate': 0.0010803410794414682, 'epoch': 5.93}\n",
      "{'loss': 0.7709, 'learning_rate': 0.0005559036622368721, 'epoch': 7.91}\n",
      "{'loss': 0.7777, 'learning_rate': 3.1466245032275774e-05, 'epoch': 9.88}\n",
      "{'train_runtime': 43.5587, 'train_samples_per_second': 463.283, 'train_steps_per_second': 58.082, 'train_loss': 0.8214957648115195, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18500664830207825, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.1006, 'eval_samples_per_second': 162.871, 'eval_steps_per_second': 20.641, 'epoch': 10.0}\n",
      "{'loss': 0.9087, 'learning_rate': 0.0021292159138506608, 'epoch': 1.98}\n",
      "{'loss': 0.8208, 'learning_rate': 0.0016047784966460644, 'epoch': 3.95}\n",
      "{'loss': 0.7826, 'learning_rate': 0.0010803410794414682, 'epoch': 5.93}\n",
      "{'loss': 0.7769, 'learning_rate': 0.0005559036622368721, 'epoch': 7.91}\n",
      "{'loss': 0.7836, 'learning_rate': 3.1466245032275774e-05, 'epoch': 9.88}\n",
      "{'train_runtime': 46.75, 'train_samples_per_second': 431.657, 'train_steps_per_second': 54.118, 'train_loss': 0.8206471454484661, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18742457032203674, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.8061, 'eval_samples_per_second': 132.68, 'eval_steps_per_second': 16.815, 'epoch': 10.0}\n",
      "{'loss': 0.9256, 'learning_rate': 0.0021292159138506608, 'epoch': 1.98}\n",
      "{'loss': 0.8554, 'learning_rate': 0.0016047784966460644, 'epoch': 3.95}\n",
      "{'loss': 0.8433, 'learning_rate': 0.0010803410794414682, 'epoch': 5.93}\n",
      "{'loss': 0.8388, 'learning_rate': 0.0005559036622368721, 'epoch': 7.91}\n",
      "{'loss': 0.7874, 'learning_rate': 3.1466245032275774e-05, 'epoch': 9.88}\n",
      "{'train_runtime': 41.7312, 'train_samples_per_second': 483.811, 'train_steps_per_second': 60.626, 'train_loss': 0.8517875912632396, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16402067244052887, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 4.0175, 'eval_samples_per_second': 125.45, 'eval_steps_per_second': 15.681, 'epoch': 10.0}\n",
      "{'loss': 0.9148, 'learning_rate': 0.0021292159138506608, 'epoch': 1.98}\n",
      "{'loss': 0.8532, 'learning_rate': 0.0016047784966460644, 'epoch': 3.95}\n",
      "{'loss': 0.8446, 'learning_rate': 0.0010803410794414682, 'epoch': 5.93}\n",
      "{'loss': 0.8152, 'learning_rate': 0.0005559036622368721, 'epoch': 7.91}\n",
      "{'loss': 0.7898, 'learning_rate': 3.1466245032275774e-05, 'epoch': 9.88}\n",
      "{'train_runtime': 45.5827, 'train_samples_per_second': 442.931, 'train_steps_per_second': 55.504, 'train_loss': 0.8468288466864424, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-09 13:46:06,159] Trial 5 finished with value: 0.0 and parameters: {'learning_rate': 0.002653653331055257, 'weight_decay': 0.00011103349355139717, 'num_train_epochs': 10}. Best is trial 4 with value: 0.7904472049689442.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16372345387935638, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.5469, 'eval_samples_per_second': 142.096, 'eval_steps_per_second': 17.762, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9831, 'learning_rate': 0.0018072492456530412, 'epoch': 1.98}\n",
      "{'loss': 0.7713, 'learning_rate': 4.235740419499316e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 15.129, 'train_samples_per_second': 533.544, 'train_steps_per_second': 66.891, 'train_loss': 0.8714065118269487, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19555993378162384, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.5076, 'eval_samples_per_second': 143.975, 'eval_steps_per_second': 18.246, 'epoch': 4.0}\n",
      "{'loss': 1.0579, 'learning_rate': 0.0018072492456530412, 'epoch': 1.98}\n",
      "{'loss': 0.7964, 'learning_rate': 4.235740419499316e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 18.7239, 'train_samples_per_second': 431.107, 'train_steps_per_second': 54.049, 'train_loss': 0.9213712488709702, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19575633108615875, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 4.2338, 'eval_samples_per_second': 119.277, 'eval_steps_per_second': 15.116, 'epoch': 4.0}\n",
      "{'loss': 0.9797, 'learning_rate': 0.0018072492456530412, 'epoch': 1.98}\n",
      "{'loss': 0.7727, 'learning_rate': 4.235740419499316e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 16.0218, 'train_samples_per_second': 503.814, 'train_steps_per_second': 63.164, 'train_loss': 0.8705772684496853, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19574424624443054, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 4.6168, 'eval_samples_per_second': 109.383, 'eval_steps_per_second': 13.862, 'epoch': 4.0}\n",
      "{'loss': 0.9625, 'learning_rate': 0.0018072492456530412, 'epoch': 1.98}\n",
      "{'loss': 0.8, 'learning_rate': 4.235740419499316e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 19.8625, 'train_samples_per_second': 406.596, 'train_steps_per_second': 50.95, 'train_loss': 0.8787929484024349, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15323176980018616, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.6564, 'eval_samples_per_second': 137.841, 'eval_steps_per_second': 17.23, 'epoch': 4.0}\n",
      "{'loss': 0.9382, 'learning_rate': 0.0018072492456530412, 'epoch': 1.98}\n",
      "{'loss': 0.8069, 'learning_rate': 4.235740419499316e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 18.4323, 'train_samples_per_second': 438.144, 'train_steps_per_second': 54.904, 'train_loss': 0.870221519658688, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-09 13:48:15,723] Trial 6 finished with value: 0.0 and parameters: {'learning_rate': 0.0035721410871110896, 'weight_decay': 5.262022790373369e-05, 'num_train_epochs': 4}. Best is trial 4 with value: 0.7904472049689442.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15443342924118042, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.5436, 'eval_samples_per_second': 142.229, 'eval_steps_per_second': 17.779, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6944, 'learning_rate': 4.121185240284236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.5251, 'learning_rate': 2.9615945705362792e-05, 'epoch': 3.95}\n",
      "{'loss': 0.473, 'learning_rate': 1.8020039007883234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.4332, 'learning_rate': 6.424132310403675e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 39.5066, 'train_samples_per_second': 459.721, 'train_steps_per_second': 57.636, 'train_loss': 0.5165906092761429, 'epoch': 9.0}\n",
      "{'eval_loss': 0.15878678858280182, 'eval_accuracy': 0.9742574257425742, 'eval_recall': 0.25, 'eval_precision': 0.42857142857142855, 'eval_f1': 0.3157894736842105, 'eval_runtime': 3.7743, 'eval_samples_per_second': 133.801, 'eval_steps_per_second': 16.957, 'epoch': 9.0}\n",
      "{'loss': 0.4129, 'learning_rate': 4.121185240284236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.2828, 'learning_rate': 2.9615945705362792e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2175, 'learning_rate': 1.8020039007883234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.2143, 'learning_rate': 6.424132310403675e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 39.8733, 'train_samples_per_second': 455.493, 'train_steps_per_second': 57.106, 'train_loss': 0.2684677636670501, 'epoch': 9.0}\n",
      "{'eval_loss': 0.18856164813041687, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.9402, 'eval_samples_per_second': 128.165, 'eval_steps_per_second': 16.243, 'epoch': 9.0}\n",
      "{'loss': 0.289, 'learning_rate': 4.121185240284236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1883, 'learning_rate': 2.9615945705362792e-05, 'epoch': 3.95}\n",
      "{'loss': 0.1408, 'learning_rate': 1.8020039007883234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1161, 'learning_rate': 6.424132310403675e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 38.9084, 'train_samples_per_second': 466.788, 'train_steps_per_second': 58.522, 'train_loss': 0.17764395478005257, 'epoch': 9.0}\n",
      "{'eval_loss': 0.05951077118515968, 'eval_accuracy': 0.9920792079207921, 'eval_recall': 0.6666666666666666, 'eval_precision': 1.0, 'eval_f1': 0.8, 'eval_runtime': 4.1632, 'eval_samples_per_second': 121.302, 'eval_steps_per_second': 15.373, 'epoch': 9.0}\n",
      "{'loss': 0.1662, 'learning_rate': 4.121185240284236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.118, 'learning_rate': 2.9615945705362792e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0571, 'learning_rate': 1.8020039007883234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0367, 'learning_rate': 6.424132310403675e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 37.039, 'train_samples_per_second': 490.591, 'train_steps_per_second': 61.476, 'train_loss': 0.08715530650156027, 'epoch': 9.0}\n",
      "{'eval_loss': 0.05519088730216026, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 4.1064, 'eval_samples_per_second': 122.736, 'eval_steps_per_second': 15.342, 'epoch': 9.0}\n",
      "{'loss': 0.1081, 'learning_rate': 4.121185240284236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0515, 'learning_rate': 2.9615945705362792e-05, 'epoch': 3.95}\n",
      "{'loss': 0.014, 'learning_rate': 1.8020039007883234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0006, 'learning_rate': 6.424132310403675e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 39.4027, 'train_samples_per_second': 461.161, 'train_steps_per_second': 57.788, 'train_loss': 0.03874691065644611, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 13:52:10,987] Trial 7 finished with value: 0.7027097154651335 and parameters: {'learning_rate': 5.280775910032191e-05, 'weight_decay': 0.001724352569900053, 'num_train_epochs': 9}. Best is trial 4 with value: 0.7904472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03245764598250389, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.5136, 'eval_samples_per_second': 143.442, 'eval_steps_per_second': 17.93, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6479, 'learning_rate': 0.00015408527752748243, 'epoch': 1.98}\n",
      "{'loss': 0.3836, 'learning_rate': 0.00010353236495284907, 'epoch': 3.95}\n",
      "{'loss': 0.2173, 'learning_rate': 5.297945237821574e-05, 'epoch': 5.93}\n",
      "{'loss': 0.161, 'learning_rate': 2.4265398035824e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.5114, 'train_samples_per_second': 481.747, 'train_steps_per_second': 60.397, 'train_loss': 0.3483138712741464, 'epoch': 8.0}\n",
      "{'eval_loss': 0.20036013424396515, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5, 'eval_precision': 0.6, 'eval_f1': 0.5454545454545454, 'eval_runtime': 3.1449, 'eval_samples_per_second': 160.578, 'eval_steps_per_second': 20.35, 'epoch': 8.0}\n",
      "{'loss': 0.2786, 'learning_rate': 0.00015408527752748243, 'epoch': 1.98}\n",
      "{'loss': 0.0811, 'learning_rate': 0.00010353236495284907, 'epoch': 3.95}\n",
      "{'loss': 0.05, 'learning_rate': 5.297945237821574e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0212, 'learning_rate': 2.4265398035824e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.3857, 'train_samples_per_second': 469.497, 'train_steps_per_second': 58.862, 'train_loss': 0.10644657118936168, 'epoch': 8.0}\n",
      "{'eval_loss': 0.1974656730890274, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.6837, 'eval_samples_per_second': 137.091, 'eval_steps_per_second': 17.374, 'epoch': 8.0}\n",
      "{'loss': 0.1825, 'learning_rate': 0.00015408527752748243, 'epoch': 1.98}\n",
      "{'loss': 0.048, 'learning_rate': 0.00010353236495284907, 'epoch': 3.95}\n",
      "{'loss': 0.0158, 'learning_rate': 5.297945237821574e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0031, 'learning_rate': 2.4265398035824e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.5517, 'train_samples_per_second': 467.242, 'train_steps_per_second': 58.579, 'train_loss': 0.061597684729881606, 'epoch': 8.0}\n",
      "{'eval_loss': 0.002429034560918808, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 3.351, 'eval_samples_per_second': 150.703, 'eval_steps_per_second': 19.099, 'epoch': 8.0}\n",
      "{'loss': 0.0925, 'learning_rate': 0.00015408527752748243, 'epoch': 1.98}\n",
      "{'loss': 0.0299, 'learning_rate': 0.00010353236495284907, 'epoch': 3.95}\n",
      "{'loss': 0.0013, 'learning_rate': 5.297945237821574e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.4265398035824e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 31.2681, 'train_samples_per_second': 516.564, 'train_steps_per_second': 64.73, 'train_loss': 0.030559926511522652, 'epoch': 8.0}\n",
      "{'eval_loss': 0.006014170590788126, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.0466, 'eval_samples_per_second': 124.551, 'eval_steps_per_second': 15.569, 'epoch': 8.0}\n",
      "{'loss': 0.058, 'learning_rate': 0.00015408527752748243, 'epoch': 1.98}\n",
      "{'loss': 0.0462, 'learning_rate': 0.00010353236495284907, 'epoch': 3.95}\n",
      "{'loss': 0.0002, 'learning_rate': 5.297945237821574e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0053, 'learning_rate': 2.4265398035824e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.4995, 'train_samples_per_second': 468.181, 'train_steps_per_second': 58.668, 'train_loss': 0.027092721922103505, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 13:55:38,183] Trial 8 finished with value: 0.7998604975587073 and parameters: {'learning_rate': 0.00020463819010211576, 'weight_decay': 0.004502646111135673, 'num_train_epochs': 8}. Best is trial 8 with value: 0.7998604975587073.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.024608569219708443, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.9906, 'eval_samples_per_second': 126.296, 'eval_steps_per_second': 15.787, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6533, 'learning_rate': 0.00016839508637919742, 'epoch': 1.98}\n",
      "{'loss': 0.3203, 'learning_rate': 3.9467598370124395e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 20.2087, 'train_samples_per_second': 399.433, 'train_steps_per_second': 50.078, 'train_loss': 0.4810036306118541, 'epoch': 4.0}\n",
      "{'eval_loss': 0.1345600038766861, 'eval_accuracy': 0.9742574257425742, 'eval_recall': 0.4166666666666667, 'eval_precision': 0.45454545454545453, 'eval_f1': 0.43478260869565216, 'eval_runtime': 3.6309, 'eval_samples_per_second': 139.085, 'eval_steps_per_second': 17.627, 'epoch': 4.0}\n",
      "{'loss': 0.3793, 'learning_rate': 0.00016839508637919742, 'epoch': 1.98}\n",
      "{'loss': 0.1328, 'learning_rate': 3.9467598370124395e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 20.0538, 'train_samples_per_second': 402.516, 'train_steps_per_second': 50.464, 'train_loss': 0.253023150408265, 'epoch': 4.0}\n",
      "{'eval_loss': 0.1393509954214096, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.9085, 'eval_samples_per_second': 129.204, 'eval_steps_per_second': 16.374, 'epoch': 4.0}\n",
      "{'loss': 0.2749, 'learning_rate': 0.00016839508637919742, 'epoch': 1.98}\n",
      "{'loss': 0.0828, 'learning_rate': 3.9467598370124395e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 15.535, 'train_samples_per_second': 519.602, 'train_steps_per_second': 65.143, 'train_loss': 0.17677056999589968, 'epoch': 4.0}\n",
      "{'eval_loss': 0.044678427278995514, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.8333333333333334, 'eval_precision': 1.0, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.8471, 'eval_samples_per_second': 131.269, 'eval_steps_per_second': 16.636, 'epoch': 4.0}\n",
      "{'loss': 0.1858, 'learning_rate': 0.00016839508637919742, 'epoch': 1.98}\n",
      "{'loss': 0.0343, 'learning_rate': 3.9467598370124395e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 19.1432, 'train_samples_per_second': 421.874, 'train_steps_per_second': 52.865, 'train_loss': 0.10878008023825135, 'epoch': 4.0}\n",
      "{'eval_loss': 0.05372210964560509, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.9401, 'eval_samples_per_second': 127.915, 'eval_steps_per_second': 15.989, 'epoch': 4.0}\n",
      "{'loss': 0.1558, 'learning_rate': 0.00016839508637919742, 'epoch': 1.98}\n",
      "{'loss': 0.0068, 'learning_rate': 3.9467598370124395e-06, 'epoch': 3.95}\n",
      "{'train_runtime': 14.6882, 'train_samples_per_second': 549.828, 'train_steps_per_second': 68.899, 'train_loss': 0.08030496678235038, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 13:57:45,965] Trial 9 finished with value: 0.7578392621870883 and parameters: {'learning_rate': 0.0003328434129213824, 'weight_decay': 0.0007399547168076419, 'num_train_epochs': 4}. Best is trial 8 with value: 0.7998604975587073.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.046343956142663956, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.8333333333333334, 'eval_f1': 0.8695652173913043, 'eval_runtime': 3.417, 'eval_samples_per_second': 147.497, 'eval_steps_per_second': 18.437, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6297, 'learning_rate': 0.00015341386326090496, 'epoch': 1.98}\n",
      "{'loss': 0.3702, 'learning_rate': 0.00010308123095745845, 'epoch': 3.95}\n",
      "{'loss': 0.2106, 'learning_rate': 5.2748598654011946e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1288, 'learning_rate': 2.415966350565432e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.5827, 'train_samples_per_second': 480.724, 'train_steps_per_second': 60.269, 'train_loss': 0.33089697020489117, 'epoch': 8.0}\n",
      "{'eval_loss': 0.17716334760189056, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.7777777777777778, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.4811, 'eval_samples_per_second': 145.07, 'eval_steps_per_second': 18.385, 'epoch': 8.0}\n",
      "{'loss': 0.2637, 'learning_rate': 0.00015341386326090496, 'epoch': 1.98}\n",
      "{'loss': 0.1078, 'learning_rate': 0.00010308123095745845, 'epoch': 3.95}\n",
      "{'loss': 0.044, 'learning_rate': 5.2748598654011946e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0122, 'learning_rate': 2.415966350565432e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.8022, 'train_samples_per_second': 450.922, 'train_steps_per_second': 56.533, 'train_loss': 0.10568381913048064, 'epoch': 8.0}\n",
      "{'eval_loss': 0.21333934366703033, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.94, 'eval_samples_per_second': 128.172, 'eval_steps_per_second': 16.244, 'epoch': 8.0}\n",
      "{'loss': 0.1677, 'learning_rate': 0.00015341386326090496, 'epoch': 1.98}\n",
      "{'loss': 0.0504, 'learning_rate': 0.00010308123095745845, 'epoch': 3.95}\n",
      "{'loss': 0.0073, 'learning_rate': 5.2748598654011946e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0004, 'learning_rate': 2.415966350565432e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 37.3111, 'train_samples_per_second': 432.686, 'train_steps_per_second': 54.247, 'train_loss': 0.057013431932085114, 'epoch': 8.0}\n",
      "{'eval_loss': 0.01917157508432865, 'eval_accuracy': 0.998019801980198, 'eval_recall': 1.0, 'eval_precision': 0.9230769230769231, 'eval_f1': 0.9600000000000001, 'eval_runtime': 3.9753, 'eval_samples_per_second': 127.035, 'eval_steps_per_second': 16.1, 'epoch': 8.0}\n",
      "{'loss': 0.0896, 'learning_rate': 0.00015341386326090496, 'epoch': 1.98}\n",
      "{'loss': 0.0222, 'learning_rate': 0.00010308123095745845, 'epoch': 3.95}\n",
      "{'loss': 0.0001, 'learning_rate': 5.2748598654011946e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0337, 'learning_rate': 2.415966350565432e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.6303, 'train_samples_per_second': 466.413, 'train_steps_per_second': 58.446, 'train_loss': 0.03596421795105501, 'epoch': 8.0}\n",
      "{'eval_loss': 0.010405230335891247, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.8312, 'eval_samples_per_second': 131.552, 'eval_steps_per_second': 16.444, 'epoch': 8.0}\n",
      "{'loss': 0.0707, 'learning_rate': 0.00015341386326090496, 'epoch': 1.98}\n",
      "{'loss': 0.0533, 'learning_rate': 0.00010308123095745845, 'epoch': 3.95}\n",
      "{'loss': 0.0119, 'learning_rate': 5.2748598654011946e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0001, 'learning_rate': 2.415966350565432e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 36.9635, 'train_samples_per_second': 436.971, 'train_steps_per_second': 54.757, 'train_loss': 0.033611059487635146, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:01:21,739] Trial 10 finished with value: 0.8404472049689442 and parameters: {'learning_rate': 0.00020374649556435147, 'weight_decay': 0.009203660948980062, 'num_train_epochs': 8}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01284811645746231, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.106, 'eval_samples_per_second': 162.267, 'eval_steps_per_second': 20.283, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6526, 'learning_rate': 0.00015723757010401913, 'epoch': 1.98}\n",
      "{'loss': 0.3812, 'learning_rate': 0.00010565044080480025, 'epoch': 3.95}\n",
      "{'loss': 0.223, 'learning_rate': 5.406331150558138e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1568, 'learning_rate': 2.4761822063625057e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.6974, 'train_samples_per_second': 452.246, 'train_steps_per_second': 56.699, 'train_loss': 0.34940997891039716, 'epoch': 8.0}\n",
      "{'eval_loss': 0.19442370533943176, 'eval_accuracy': 0.9841584158415841, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.7, 'eval_f1': 0.6363636363636365, 'eval_runtime': 3.4589, 'eval_samples_per_second': 145.999, 'eval_steps_per_second': 18.503, 'epoch': 8.0}\n",
      "{'loss': 0.2808, 'learning_rate': 0.00015723757010401913, 'epoch': 1.98}\n",
      "{'loss': 0.0774, 'learning_rate': 0.00010565044080480025, 'epoch': 3.95}\n",
      "{'loss': 0.0425, 'learning_rate': 5.406331150558138e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0049, 'learning_rate': 2.4761822063625057e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 37.7724, 'train_samples_per_second': 427.403, 'train_steps_per_second': 53.584, 'train_loss': 0.10017371397413012, 'epoch': 8.0}\n",
      "{'eval_loss': 0.13901343941688538, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.4578, 'eval_samples_per_second': 146.046, 'eval_steps_per_second': 18.509, 'epoch': 8.0}\n",
      "{'loss': 0.1772, 'learning_rate': 0.00015723757010401913, 'epoch': 1.98}\n",
      "{'loss': 0.0429, 'learning_rate': 0.00010565044080480025, 'epoch': 3.95}\n",
      "{'loss': 0.0215, 'learning_rate': 5.406331150558138e-05, 'epoch': 5.93}\n",
      "{'loss': 0.003, 'learning_rate': 2.4761822063625057e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 40.2318, 'train_samples_per_second': 401.274, 'train_steps_per_second': 50.308, 'train_loss': 0.0610192481119171, 'epoch': 8.0}\n",
      "{'eval_loss': 0.015950394794344902, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.9166666666666666, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9166666666666666, 'eval_runtime': 3.9037, 'eval_samples_per_second': 129.366, 'eval_steps_per_second': 16.395, 'epoch': 8.0}\n",
      "{'loss': 0.1221, 'learning_rate': 0.00015723757010401913, 'epoch': 1.98}\n",
      "{'loss': 0.0281, 'learning_rate': 0.00010565044080480025, 'epoch': 3.95}\n",
      "{'loss': 0.0004, 'learning_rate': 5.406331150558138e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0001, 'learning_rate': 2.4761822063625057e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 38.2878, 'train_samples_per_second': 421.857, 'train_steps_per_second': 52.863, 'train_loss': 0.03721450434891213, 'epoch': 8.0}\n",
      "{'eval_loss': 0.014855530112981796, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.6177, 'eval_samples_per_second': 139.317, 'eval_steps_per_second': 17.415, 'epoch': 8.0}\n",
      "{'loss': 0.0623, 'learning_rate': 0.00015723757010401913, 'epoch': 1.98}\n",
      "{'loss': 0.0286, 'learning_rate': 0.00010565044080480025, 'epoch': 3.95}\n",
      "{'loss': 0.001, 'learning_rate': 5.406331150558138e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.4761822063625057e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 39.552, 'train_samples_per_second': 408.374, 'train_steps_per_second': 51.173, 'train_loss': 0.022711157301298652, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:05:12,825] Trial 11 finished with value: 0.8257199322416714 and parameters: {'learning_rate': 0.000208824699403238, 'weight_decay': 0.009913735492424547, 'num_train_epochs': 8}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.022750306874513626, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.5917, 'eval_samples_per_second': 140.322, 'eval_steps_per_second': 17.54, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6661, 'learning_rate': 7.170172608725825e-05, 'epoch': 1.98}\n",
      "{'loss': 0.4598, 'learning_rate': 4.8177537738420235e-05, 'epoch': 3.95}\n",
      "{'loss': 0.354, 'learning_rate': 2.4653349389582234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.2855, 'learning_rate': 1.1291610407442244e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.8027, 'train_samples_per_second': 450.915, 'train_steps_per_second': 56.532, 'train_loss': 0.43866688766969525, 'epoch': 8.0}\n",
      "{'eval_loss': 0.16839510202407837, 'eval_accuracy': 0.9782178217821782, 'eval_recall': 0.3333333333333333, 'eval_precision': 0.5714285714285714, 'eval_f1': 0.4210526315789474, 'eval_runtime': 3.9142, 'eval_samples_per_second': 129.017, 'eval_steps_per_second': 16.351, 'epoch': 8.0}\n",
      "{'loss': 0.311, 'learning_rate': 7.170172608725825e-05, 'epoch': 1.98}\n",
      "{'loss': 0.17, 'learning_rate': 4.8177537738420235e-05, 'epoch': 3.95}\n",
      "{'loss': 0.1127, 'learning_rate': 2.4653349389582234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0842, 'learning_rate': 1.1291610407442244e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 36.3023, 'train_samples_per_second': 444.71, 'train_steps_per_second': 55.754, 'train_loss': 0.1675688740263579, 'epoch': 8.0}\n",
      "{'eval_loss': 0.15547725558280945, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.9055, 'eval_samples_per_second': 129.304, 'eval_steps_per_second': 16.387, 'epoch': 8.0}\n",
      "{'loss': 0.22, 'learning_rate': 7.170172608725825e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1052, 'learning_rate': 4.8177537738420235e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0616, 'learning_rate': 2.4653349389582234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0109, 'learning_rate': 1.1291610407442244e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.6514, 'train_samples_per_second': 452.829, 'train_steps_per_second': 56.772, 'train_loss': 0.09944504534774147, 'epoch': 8.0}\n",
      "{'eval_loss': 0.0688643530011177, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.75, 'eval_precision': 1.0, 'eval_f1': 0.8571428571428571, 'eval_runtime': 3.6596, 'eval_samples_per_second': 137.993, 'eval_steps_per_second': 17.488, 'epoch': 8.0}\n",
      "{'loss': 0.1216, 'learning_rate': 7.170172608725825e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0655, 'learning_rate': 4.8177537738420235e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0141, 'learning_rate': 2.4653349389582234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0014, 'learning_rate': 1.1291610407442244e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 32.4558, 'train_samples_per_second': 497.661, 'train_steps_per_second': 62.362, 'train_loss': 0.050049644300178275, 'epoch': 8.0}\n",
      "{'eval_loss': 0.02360892854630947, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.7971, 'eval_samples_per_second': 132.733, 'eval_steps_per_second': 16.592, 'epoch': 8.0}\n",
      "{'loss': 0.0205, 'learning_rate': 7.170172608725825e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0159, 'learning_rate': 4.8177537738420235e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0009, 'learning_rate': 2.4653349389582234e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0001, 'learning_rate': 1.1291610407442244e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.0662, 'train_samples_per_second': 460.615, 'train_steps_per_second': 57.719, 'train_loss': 0.00924692739456415, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:08:47,965] Trial 12 finished with value: 0.7464086862121592 and parameters: {'learning_rate': 9.522591443609626e-05, 'weight_decay': 0.009815474609681843, 'num_train_epochs': 8}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02589944750070572, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 4.2204, 'eval_samples_per_second': 119.42, 'eval_steps_per_second': 14.927, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6624, 'learning_rate': 0.0002021501874607177, 'epoch': 1.98}\n",
      "{'loss': 0.3589, 'learning_rate': 0.00010286227613423552, 'epoch': 3.95}\n",
      "{'loss': 0.1714, 'learning_rate': 3.5743648077533574e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 24.7315, 'train_samples_per_second': 489.579, 'train_steps_per_second': 61.379, 'train_loss': 0.39724014304843347, 'epoch': 6.0}\n",
      "{'eval_loss': 0.16912882030010223, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5, 'eval_f1': 0.5384615384615384, 'eval_runtime': 3.4955, 'eval_samples_per_second': 144.471, 'eval_steps_per_second': 18.309, 'epoch': 6.0}\n",
      "{'loss': 0.296, 'learning_rate': 0.0002021501874607177, 'epoch': 1.98}\n",
      "{'loss': 0.1259, 'learning_rate': 0.00010286227613423552, 'epoch': 3.95}\n",
      "{'loss': 0.0671, 'learning_rate': 3.5743648077533574e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 24.6526, 'train_samples_per_second': 491.144, 'train_steps_per_second': 61.576, 'train_loss': 0.1656474765581576, 'epoch': 6.0}\n",
      "{'eval_loss': 0.12470228970050812, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 3.6534, 'eval_samples_per_second': 138.228, 'eval_steps_per_second': 17.518, 'epoch': 6.0}\n",
      "{'loss': 0.2015, 'learning_rate': 0.0002021501874607177, 'epoch': 1.98}\n",
      "{'loss': 0.0957, 'learning_rate': 0.00010286227613423552, 'epoch': 3.95}\n",
      "{'loss': 0.0247, 'learning_rate': 3.5743648077533574e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 24.0442, 'train_samples_per_second': 503.572, 'train_steps_per_second': 63.134, 'train_loss': 0.10653824521147687, 'epoch': 6.0}\n",
      "{'eval_loss': 0.08505552262067795, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.75, 'eval_precision': 0.8181818181818182, 'eval_f1': 0.7826086956521738, 'eval_runtime': 3.8009, 'eval_samples_per_second': 132.864, 'eval_steps_per_second': 16.838, 'epoch': 6.0}\n",
      "{'loss': 0.1854, 'learning_rate': 0.0002021501874607177, 'epoch': 1.98}\n",
      "{'loss': 0.0492, 'learning_rate': 0.00010286227613423552, 'epoch': 3.95}\n",
      "{'loss': 0.013, 'learning_rate': 3.5743648077533574e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 24.9916, 'train_samples_per_second': 484.723, 'train_steps_per_second': 60.74, 'train_loss': 0.08153613075944202, 'epoch': 6.0}\n",
      "{'eval_loss': 0.02502698451280594, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 4.1784, 'eval_samples_per_second': 120.62, 'eval_steps_per_second': 15.077, 'epoch': 6.0}\n",
      "{'loss': 0.0754, 'learning_rate': 0.0002021501874607177, 'epoch': 1.98}\n",
      "{'loss': 0.0031, 'learning_rate': 0.00010286227613423552, 'epoch': 3.95}\n",
      "{'loss': 0.0007, 'learning_rate': 3.5743648077533574e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 27.2533, 'train_samples_per_second': 444.496, 'train_steps_per_second': 55.7, 'train_loss': 0.026075250070360496, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:11:33,121] Trial 13 finished with value: 0.7838768401697462 and parameters: {'learning_rate': 0.00030143809878719984, 'weight_decay': 0.009497965446382798, 'num_train_epochs': 6}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.020827215164899826, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.4166, 'eval_samples_per_second': 147.515, 'eval_steps_per_second': 18.439, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6942, 'learning_rate': 3.2101063859814236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.5563, 'learning_rate': 2.306868798479616e-05, 'epoch': 3.95}\n",
      "{'loss': 0.4904, 'learning_rate': 1.4036312109778087e-05, 'epoch': 5.93}\n",
      "{'loss': 0.4653, 'learning_rate': 5.003936234760013e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 39.9145, 'train_samples_per_second': 455.022, 'train_steps_per_second': 57.047, 'train_loss': 0.5377086895727828, 'epoch': 9.0}\n",
      "{'eval_loss': 0.14611737430095673, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.16666666666666666, 'eval_precision': 1.0, 'eval_f1': 0.2857142857142857, 'eval_runtime': 3.6301, 'eval_samples_per_second': 139.116, 'eval_steps_per_second': 17.631, 'epoch': 9.0}\n",
      "{'loss': 0.448, 'learning_rate': 3.2101063859814236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.3447, 'learning_rate': 2.306868798479616e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2956, 'learning_rate': 1.4036312109778087e-05, 'epoch': 5.93}\n",
      "{'loss': 0.259, 'learning_rate': 5.003936234760013e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 38.4909, 'train_samples_per_second': 471.852, 'train_steps_per_second': 59.157, 'train_loss': 0.3216487598042243, 'epoch': 9.0}\n",
      "{'eval_loss': 0.19331330060958862, 'eval_accuracy': 0.9841584158415841, 'eval_recall': 0.3333333333333333, 'eval_precision': 1.0, 'eval_f1': 0.5, 'eval_runtime': 3.8056, 'eval_samples_per_second': 132.701, 'eval_steps_per_second': 16.818, 'epoch': 9.0}\n",
      "{'loss': 0.3584, 'learning_rate': 3.2101063859814236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.2634, 'learning_rate': 2.306868798479616e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2069, 'learning_rate': 1.4036312109778087e-05, 'epoch': 5.93}\n",
      "{'loss': 0.181, 'learning_rate': 5.003936234760013e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 38.7096, 'train_samples_per_second': 469.186, 'train_steps_per_second': 58.823, 'train_loss': 0.24056808980976116, 'epoch': 9.0}\n",
      "{'eval_loss': 0.08788919448852539, 'eval_accuracy': 0.9920792079207921, 'eval_recall': 0.6666666666666666, 'eval_precision': 1.0, 'eval_f1': 0.8, 'eval_runtime': 3.2189, 'eval_samples_per_second': 156.884, 'eval_steps_per_second': 19.882, 'epoch': 9.0}\n",
      "{'loss': 0.2602, 'learning_rate': 3.2101063859814236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1672, 'learning_rate': 2.306868798479616e-05, 'epoch': 3.95}\n",
      "{'loss': 0.1028, 'learning_rate': 1.4036312109778087e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0821, 'learning_rate': 5.003936234760013e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 36.841, 'train_samples_per_second': 493.227, 'train_steps_per_second': 61.806, 'train_loss': 0.14061210675882466, 'epoch': 9.0}\n",
      "{'eval_loss': 0.05078360438346863, 'eval_accuracy': 0.9920634920634921, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.8181818181818182, 'eval_f1': 0.8181818181818182, 'eval_runtime': 3.631, 'eval_samples_per_second': 138.804, 'eval_steps_per_second': 17.35, 'epoch': 9.0}\n",
      "{'loss': 0.1426, 'learning_rate': 3.2101063859814236e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0719, 'learning_rate': 2.306868798479616e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0207, 'learning_rate': 1.4036312109778087e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0199, 'learning_rate': 5.003936234760013e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 39.2815, 'train_samples_per_second': 462.584, 'train_steps_per_second': 57.966, 'train_loss': 0.061151164846039156, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:15:24,933] Trial 14 finished with value: 0.6522077922077922 and parameters: {'learning_rate': 4.113343973483231e-05, 'weight_decay': 0.004203794060988996, 'num_train_epochs': 9}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03946886956691742, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 3.4747, 'eval_samples_per_second': 145.048, 'eval_steps_per_second': 18.131, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6586, 'learning_rate': 0.00027487618702159153, 'epoch': 1.98}\n",
      "{'loss': 0.4024, 'learning_rate': 0.00018469371096463893, 'epoch': 3.95}\n",
      "{'loss': 0.2333, 'learning_rate': 9.451123490768632e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1726, 'learning_rate': 4.328758850733725e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.8853, 'train_samples_per_second': 449.878, 'train_steps_per_second': 56.402, 'train_loss': 0.3639991006596757, 'epoch': 8.0}\n",
      "{'eval_loss': 0.17473319172859192, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.6363636363636364, 'eval_f1': 0.6086956521739131, 'eval_runtime': 3.8846, 'eval_samples_per_second': 130.002, 'eval_steps_per_second': 16.476, 'epoch': 8.0}\n",
      "{'loss': 0.2783, 'learning_rate': 0.00027487618702159153, 'epoch': 1.98}\n",
      "{'loss': 0.2056, 'learning_rate': 0.00018469371096463893, 'epoch': 3.95}\n",
      "{'loss': 0.0699, 'learning_rate': 9.451123490768632e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0327, 'learning_rate': 4.328758850733725e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 37.3364, 'train_samples_per_second': 432.392, 'train_steps_per_second': 54.21, 'train_loss': 0.1448965860366119, 'epoch': 8.0}\n",
      "{'eval_loss': 0.16422085464000702, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 3.7324, 'eval_samples_per_second': 135.303, 'eval_steps_per_second': 17.147, 'epoch': 8.0}\n",
      "{'loss': 0.2432, 'learning_rate': 0.00027487618702159153, 'epoch': 1.98}\n",
      "{'loss': 0.1872, 'learning_rate': 0.00018469371096463893, 'epoch': 3.95}\n",
      "{'loss': 0.0386, 'learning_rate': 9.451123490768632e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0109, 'learning_rate': 4.328758850733725e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 40.3894, 'train_samples_per_second': 399.709, 'train_steps_per_second': 50.112, 'train_loss': 0.12032686709886484, 'epoch': 8.0}\n",
      "{'eval_loss': 0.037823386490345, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.8333333333333334, 'eval_precision': 1.0, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.3601, 'eval_samples_per_second': 150.293, 'eval_steps_per_second': 19.047, 'epoch': 8.0}\n",
      "{'loss': 0.1883, 'learning_rate': 0.00027487618702159153, 'epoch': 1.98}\n",
      "{'loss': 0.0307, 'learning_rate': 0.00018469371096463893, 'epoch': 3.95}\n",
      "{'loss': 0.0022, 'learning_rate': 9.451123490768632e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 4.328758850733725e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.3299, 'train_samples_per_second': 470.494, 'train_steps_per_second': 58.957, 'train_loss': 0.05464205763668209, 'epoch': 8.0}\n",
      "{'eval_loss': 0.021903444081544876, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.76, 'eval_samples_per_second': 134.042, 'eval_steps_per_second': 16.755, 'epoch': 8.0}\n",
      "{'loss': 0.0759, 'learning_rate': 0.00027487618702159153, 'epoch': 1.98}\n",
      "{'loss': 0.0693, 'learning_rate': 0.00018469371096463893, 'epoch': 3.95}\n",
      "{'loss': 0.0136, 'learning_rate': 9.451123490768632e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 4.328758850733725e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 38.5137, 'train_samples_per_second': 419.383, 'train_steps_per_second': 52.553, 'train_loss': 0.039232471736173655, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:19:10,465] Trial 15 finished with value: 0.8327062716078736 and parameters: {'learning_rate': 0.00036505866307854414, 'weight_decay': 0.002134010915556437, 'num_train_epochs': 8}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016550738364458084, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.6532, 'eval_samples_per_second': 137.962, 'eval_steps_per_second': 17.245, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.66, 'learning_rate': 0.00032508782135666546, 'epoch': 1.98}\n",
      "{'loss': 0.4059, 'learning_rate': 0.0002450169293968956, 'epoch': 3.95}\n",
      "{'loss': 0.2227, 'learning_rate': 0.00016494603743712582, 'epoch': 5.93}\n",
      "{'loss': 0.1948, 'learning_rate': 8.487514547735602e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0898, 'learning_rate': 4.804253517586189e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 46.1034, 'train_samples_per_second': 437.712, 'train_steps_per_second': 54.877, 'train_loss': 0.31571815551034077, 'epoch': 10.0}\n",
      "{'eval_loss': 0.20997507870197296, 'eval_accuracy': 0.9841584158415841, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.7, 'eval_f1': 0.6363636363636365, 'eval_runtime': 3.3472, 'eval_samples_per_second': 150.871, 'eval_steps_per_second': 19.12, 'epoch': 10.0}\n",
      "{'loss': 0.3337, 'learning_rate': 0.00032508782135666546, 'epoch': 1.98}\n",
      "{'loss': 0.1822, 'learning_rate': 0.0002450169293968956, 'epoch': 3.95}\n",
      "{'loss': 0.1176, 'learning_rate': 0.00016494603743712582, 'epoch': 5.93}\n",
      "{'loss': 0.0634, 'learning_rate': 8.487514547735602e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0036, 'learning_rate': 4.804253517586189e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 43.2901, 'train_samples_per_second': 466.158, 'train_steps_per_second': 58.443, 'train_loss': 0.13845254353186845, 'epoch': 10.0}\n",
      "{'eval_loss': 0.18586106598377228, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 3.4982, 'eval_samples_per_second': 144.359, 'eval_steps_per_second': 18.295, 'epoch': 10.0}\n",
      "{'loss': 0.2851, 'learning_rate': 0.00032508782135666546, 'epoch': 1.98}\n",
      "{'loss': 0.1226, 'learning_rate': 0.0002450169293968956, 'epoch': 3.95}\n",
      "{'loss': 0.0614, 'learning_rate': 0.00016494603743712582, 'epoch': 5.93}\n",
      "{'loss': 0.051, 'learning_rate': 8.487514547735602e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0234, 'learning_rate': 4.804253517586189e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 44.8181, 'train_samples_per_second': 450.265, 'train_steps_per_second': 56.45, 'train_loss': 0.10956883449328275, 'epoch': 10.0}\n",
      "{'eval_loss': 0.06555552780628204, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.9166666666666666, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9166666666666666, 'eval_runtime': 3.7384, 'eval_samples_per_second': 135.083, 'eval_steps_per_second': 17.119, 'epoch': 10.0}\n",
      "{'loss': 0.1414, 'learning_rate': 0.00032508782135666546, 'epoch': 1.98}\n",
      "{'loss': 0.1017, 'learning_rate': 0.0002450169293968956, 'epoch': 3.95}\n",
      "{'loss': 0.0279, 'learning_rate': 0.00016494603743712582, 'epoch': 5.93}\n",
      "{'loss': 0.0128, 'learning_rate': 8.487514547735602e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0002, 'learning_rate': 4.804253517586189e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 41.2972, 'train_samples_per_second': 488.896, 'train_steps_per_second': 61.263, 'train_loss': 0.056149629352815825, 'epoch': 10.0}\n",
      "{'eval_loss': 0.05859491974115372, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.5575, 'eval_samples_per_second': 141.671, 'eval_steps_per_second': 17.709, 'epoch': 10.0}\n",
      "{'loss': 0.1773, 'learning_rate': 0.00032508782135666546, 'epoch': 1.98}\n",
      "{'loss': 0.0399, 'learning_rate': 0.0002450169293968956, 'epoch': 3.95}\n",
      "{'loss': 0.0165, 'learning_rate': 0.00016494603743712582, 'epoch': 5.93}\n",
      "{'loss': 0.0201, 'learning_rate': 8.487514547735602e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0054, 'learning_rate': 4.804253517586189e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 43.2675, 'train_samples_per_second': 466.631, 'train_steps_per_second': 58.473, 'train_loss': 0.05121207340236702, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:23:27,177] Trial 16 finished with value: 0.8302688539530644 and parameters: {'learning_rate': 0.0004051587133164353, 'weight_decay': 0.0023954614932576545, 'num_train_epochs': 10}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.013354039750993252, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.3295, 'eval_samples_per_second': 151.376, 'eval_steps_per_second': 18.922, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6568, 'learning_rate': 6.791451752331709e-05, 'epoch': 1.98}\n",
      "{'loss': 0.457, 'learning_rate': 3.455768180459553e-05, 'epoch': 3.95}\n",
      "{'loss': 0.3703, 'learning_rate': 1.2008460858739758e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 26.5712, 'train_samples_per_second': 455.681, 'train_steps_per_second': 57.129, 'train_loss': 0.4949110983545758, 'epoch': 6.0}\n",
      "{'eval_loss': 0.13922736048698425, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.25, 'eval_precision': 1.0, 'eval_f1': 0.4, 'eval_runtime': 3.29, 'eval_samples_per_second': 153.495, 'eval_steps_per_second': 19.453, 'epoch': 6.0}\n",
      "{'loss': 0.3682, 'learning_rate': 6.791451752331709e-05, 'epoch': 1.98}\n",
      "{'loss': 0.196, 'learning_rate': 3.455768180459553e-05, 'epoch': 3.95}\n",
      "{'loss': 0.1317, 'learning_rate': 1.2008460858739758e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 28.2371, 'train_samples_per_second': 428.798, 'train_steps_per_second': 53.759, 'train_loss': 0.23214354376862015, 'epoch': 6.0}\n",
      "{'eval_loss': 0.20200684666633606, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.698, 'eval_samples_per_second': 136.56, 'eval_steps_per_second': 17.307, 'epoch': 6.0}\n",
      "{'loss': 0.2407, 'learning_rate': 6.791451752331709e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1525, 'learning_rate': 3.455768180459553e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0808, 'learning_rate': 1.2008460858739758e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 27.0165, 'train_samples_per_second': 448.171, 'train_steps_per_second': 56.188, 'train_loss': 0.15967464918204446, 'epoch': 6.0}\n",
      "{'eval_loss': 0.025004543364048004, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.8333333333333334, 'eval_precision': 1.0, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.8954, 'eval_samples_per_second': 129.641, 'eval_steps_per_second': 16.43, 'epoch': 6.0}\n",
      "{'loss': 0.1927, 'learning_rate': 6.791451752331709e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0735, 'learning_rate': 3.455768180459553e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0284, 'learning_rate': 1.2008460858739758e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 22.3932, 'train_samples_per_second': 540.967, 'train_steps_per_second': 67.788, 'train_loss': 0.09702683103866556, 'epoch': 6.0}\n",
      "{'eval_loss': 0.04051058739423752, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 3.6426, 'eval_samples_per_second': 138.364, 'eval_steps_per_second': 17.296, 'epoch': 6.0}\n",
      "{'loss': 0.0851, 'learning_rate': 6.791451752331709e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0234, 'learning_rate': 3.455768180459553e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0042, 'learning_rate': 1.2008460858739758e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 27.0367, 'train_samples_per_second': 448.057, 'train_steps_per_second': 56.146, 'train_loss': 0.03713670087916648, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:26:17,574] Trial 17 finished with value: 0.7413700025464731 and parameters: {'learning_rate': 0.00010127135324203863, 'weight_decay': 0.0012032819459177556, 'num_train_epochs': 6}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.019221531227231026, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 4.0035, 'eval_samples_per_second': 125.891, 'eval_steps_per_second': 15.736, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7144, 'learning_rate': 0.0003702298234416611, 'epoch': 1.98}\n",
      "{'loss': 0.4847, 'learning_rate': 0.0002660571100365792, 'epoch': 3.95}\n",
      "{'loss': 0.3848, 'learning_rate': 0.00016188439663149728, 'epoch': 5.93}\n",
      "{'loss': 0.2878, 'learning_rate': 5.7711683226415375e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 40.4292, 'train_samples_per_second': 449.23, 'train_steps_per_second': 56.321, 'train_loss': 0.43862463876140395, 'epoch': 9.0}\n",
      "{'eval_loss': 0.15095873177051544, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5833333333333334, 'eval_f1': 0.5833333333333334, 'eval_runtime': 4.0476, 'eval_samples_per_second': 124.764, 'eval_steps_per_second': 15.812, 'epoch': 9.0}\n",
      "{'loss': 0.4553, 'learning_rate': 0.0003702298234416611, 'epoch': 1.98}\n",
      "{'loss': 0.2292, 'learning_rate': 0.0002660571100365792, 'epoch': 3.95}\n",
      "{'loss': 0.2424, 'learning_rate': 0.00016188439663149728, 'epoch': 5.93}\n",
      "{'loss': 0.1931, 'learning_rate': 5.7711683226415375e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.6962, 'train_samples_per_second': 457.525, 'train_steps_per_second': 57.361, 'train_loss': 0.26274579148256944, 'epoch': 9.0}\n",
      "{'eval_loss': 0.13551901280879974, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.5, 'eval_precision': 0.8571428571428571, 'eval_f1': 0.631578947368421, 'eval_runtime': 4.1926, 'eval_samples_per_second': 120.45, 'eval_steps_per_second': 15.265, 'epoch': 9.0}\n",
      "{'loss': 0.5083, 'learning_rate': 0.0003702298234416611, 'epoch': 1.98}\n",
      "{'loss': 0.5628, 'learning_rate': 0.0002660571100365792, 'epoch': 3.95}\n",
      "{'loss': 0.3077, 'learning_rate': 0.00016188439663149728, 'epoch': 5.93}\n",
      "{'loss': 0.2917, 'learning_rate': 5.7711683226415375e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 38.35, 'train_samples_per_second': 473.585, 'train_steps_per_second': 59.374, 'train_loss': 0.3923083319180254, 'epoch': 9.0}\n",
      "{'eval_loss': 0.04829233139753342, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.75, 'eval_precision': 1.0, 'eval_f1': 0.8571428571428571, 'eval_runtime': 3.9059, 'eval_samples_per_second': 129.291, 'eval_steps_per_second': 16.385, 'epoch': 9.0}\n",
      "{'loss': 0.2996, 'learning_rate': 0.0003702298234416611, 'epoch': 1.98}\n",
      "{'loss': 0.3648, 'learning_rate': 0.0002660571100365792, 'epoch': 3.95}\n",
      "{'loss': 0.2259, 'learning_rate': 0.00016188439663149728, 'epoch': 5.93}\n",
      "{'loss': 0.1804, 'learning_rate': 5.7711683226415375e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 34.9634, 'train_samples_per_second': 519.716, 'train_steps_per_second': 65.125, 'train_loss': 0.2526481906520624, 'epoch': 9.0}\n",
      "{'eval_loss': 0.11274825781583786, 'eval_accuracy': 0.9880952380952381, 'eval_recall': 0.7272727272727273, 'eval_precision': 0.7272727272727273, 'eval_f1': 0.7272727272727273, 'eval_runtime': 4.0149, 'eval_samples_per_second': 125.533, 'eval_steps_per_second': 15.692, 'epoch': 9.0}\n",
      "{'loss': 0.2842, 'learning_rate': 0.0003702298234416611, 'epoch': 1.98}\n",
      "{'loss': 0.2742, 'learning_rate': 0.0002660571100365792, 'epoch': 3.95}\n",
      "{'loss': 0.1889, 'learning_rate': 0.00016188439663149728, 'epoch': 5.93}\n",
      "{'loss': 0.1763, 'learning_rate': 5.7711683226415375e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.4257, 'train_samples_per_second': 460.893, 'train_steps_per_second': 57.754, 'train_loss': 0.22211226612839932, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:30:10,656] Trial 18 finished with value: 0.7503417634996582 and parameters: {'learning_rate': 0.000474402536846743, 'weight_decay': 0.0031315784244297013, 'num_train_epochs': 9}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015229472890496254, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.6326, 'eval_samples_per_second': 138.743, 'eval_steps_per_second': 17.343, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6443, 'learning_rate': 0.00012233315152878024, 'epoch': 1.98}\n",
      "{'loss': 0.3757, 'learning_rate': 6.224810657358366e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2299, 'learning_rate': 2.1630616183870767e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 26.237, 'train_samples_per_second': 461.486, 'train_steps_per_second': 57.857, 'train_loss': 0.41403279552660754, 'epoch': 6.0}\n",
      "{'eval_loss': 0.1641356498003006, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5, 'eval_precision': 0.6, 'eval_f1': 0.5454545454545454, 'eval_runtime': 4.2049, 'eval_samples_per_second': 120.098, 'eval_steps_per_second': 15.22, 'epoch': 6.0}\n",
      "{'loss': 0.3146, 'learning_rate': 0.00012233315152878024, 'epoch': 1.98}\n",
      "{'loss': 0.1049, 'learning_rate': 6.224810657358366e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0529, 'learning_rate': 2.1630616183870767e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 24.0208, 'train_samples_per_second': 504.063, 'train_steps_per_second': 63.195, 'train_loss': 0.1564699650910218, 'epoch': 6.0}\n",
      "{'eval_loss': 0.19549410045146942, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.5532, 'eval_samples_per_second': 142.126, 'eval_steps_per_second': 18.012, 'epoch': 6.0}\n",
      "{'loss': 0.1878, 'learning_rate': 0.00012233315152878024, 'epoch': 1.98}\n",
      "{'loss': 0.0497, 'learning_rate': 6.224810657358366e-05, 'epoch': 3.95}\n",
      "{'loss': 0.006, 'learning_rate': 2.1630616183870767e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 24.3597, 'train_samples_per_second': 497.05, 'train_steps_per_second': 62.316, 'train_loss': 0.08020211441616609, 'epoch': 6.0}\n",
      "{'eval_loss': 0.024717560037970543, 'eval_accuracy': 0.998019801980198, 'eval_recall': 0.9166666666666666, 'eval_precision': 1.0, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.3006, 'eval_samples_per_second': 117.426, 'eval_steps_per_second': 14.882, 'epoch': 6.0}\n",
      "{'loss': 0.12, 'learning_rate': 0.00012233315152878024, 'epoch': 1.98}\n",
      "{'loss': 0.0582, 'learning_rate': 6.224810657358366e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0018, 'learning_rate': 2.1630616183870767e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 22.4854, 'train_samples_per_second': 538.749, 'train_steps_per_second': 67.51, 'train_loss': 0.0592812174782275, 'epoch': 6.0}\n",
      "{'eval_loss': 0.021112293004989624, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.567, 'eval_samples_per_second': 141.297, 'eval_steps_per_second': 17.662, 'epoch': 6.0}\n",
      "{'loss': 0.0356, 'learning_rate': 0.00012233315152878024, 'epoch': 1.98}\n",
      "{'loss': 0.0091, 'learning_rate': 6.224810657358366e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0004, 'learning_rate': 2.1630616183870767e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 24.1467, 'train_samples_per_second': 501.683, 'train_steps_per_second': 62.866, 'train_loss': 0.014841633396244728, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:32:52,091] Trial 19 finished with value: 0.7998228540428028 and parameters: {'learning_rate': 0.00018241819648397682, 'weight_decay': 0.006001920138610421, 'num_train_epochs': 6}. Best is trial 10 with value: 0.8404472049689442.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.010614769533276558, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.8244, 'eval_samples_per_second': 131.786, 'eval_steps_per_second': 16.473, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6863, 'learning_rate': 5.218766172768199e-05, 'epoch': 1.98}\n",
      "{'loss': 0.5007, 'learning_rate': 3.506572546531913e-05, 'epoch': 3.95}\n",
      "{'loss': 0.4293, 'learning_rate': 1.7943789202956276e-05, 'epoch': 5.93}\n",
      "{'loss': 0.3686, 'learning_rate': 8.218529405934171e-07, 'epoch': 7.91}\n",
      "{'train_runtime': 33.7304, 'train_samples_per_second': 478.619, 'train_steps_per_second': 60.005, 'train_loss': 0.4937177573739304, 'epoch': 8.0}\n",
      "{'eval_loss': 0.15084871649742126, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.4166666666666667, 'eval_precision': 0.7142857142857143, 'eval_f1': 0.5263157894736842, 'eval_runtime': 4.5122, 'eval_samples_per_second': 111.919, 'eval_steps_per_second': 14.184, 'epoch': 8.0}\n",
      "{'loss': 0.3766, 'learning_rate': 5.218766172768199e-05, 'epoch': 1.98}\n",
      "{'loss': 0.2265, 'learning_rate': 3.506572546531913e-05, 'epoch': 3.95}\n",
      "{'loss': 0.1788, 'learning_rate': 1.7943789202956276e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1586, 'learning_rate': 8.218529405934171e-07, 'epoch': 7.91}\n",
      "{'train_runtime': 33.8728, 'train_samples_per_second': 476.606, 'train_steps_per_second': 59.753, 'train_loss': 0.23277901227884143, 'epoch': 8.0}\n",
      "{'eval_loss': 0.18467608094215393, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 4.0114, 'eval_samples_per_second': 125.891, 'eval_steps_per_second': 15.954, 'epoch': 8.0}\n",
      "{'loss': 0.2741, 'learning_rate': 5.218766172768199e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1717, 'learning_rate': 3.506572546531913e-05, 'epoch': 3.95}\n",
      "{'loss': 0.099, 'learning_rate': 1.7943789202956276e-05, 'epoch': 5.93}\n",
      "{'loss': 0.066, 'learning_rate': 8.218529405934171e-07, 'epoch': 7.91}\n",
      "{'train_runtime': 34.5702, 'train_samples_per_second': 466.992, 'train_steps_per_second': 58.548, 'train_loss': 0.15217486789575208, 'epoch': 8.0}\n",
      "{'eval_loss': 0.07058849185705185, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.75, 'eval_precision': 1.0, 'eval_f1': 0.8571428571428571, 'eval_runtime': 4.2083, 'eval_samples_per_second': 120.002, 'eval_steps_per_second': 15.208, 'epoch': 8.0}\n",
      "{'loss': 0.1751, 'learning_rate': 5.218766172768199e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0502, 'learning_rate': 3.506572546531913e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0404, 'learning_rate': 1.7943789202956276e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0164, 'learning_rate': 8.218529405934171e-07, 'epoch': 7.91}\n",
      "{'train_runtime': 31.6128, 'train_samples_per_second': 510.933, 'train_steps_per_second': 64.025, 'train_loss': 0.06967272908742765, 'epoch': 8.0}\n",
      "{'eval_loss': 0.0261500533670187, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 3.6886, 'eval_samples_per_second': 136.637, 'eval_steps_per_second': 17.08, 'epoch': 8.0}\n",
      "{'loss': 0.059, 'learning_rate': 5.218766172768199e-05, 'epoch': 1.98}\n",
      "{'loss': 0.034, 'learning_rate': 3.506572546531913e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0256, 'learning_rate': 1.7943789202956276e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0007, 'learning_rate': 8.218529405934171e-07, 'epoch': 7.91}\n",
      "{'train_runtime': 37.3299, 'train_samples_per_second': 432.683, 'train_steps_per_second': 54.219, 'train_loss': 0.029479509244548233, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:36:25,033] Trial 20 finished with value: 0.7562435500515996 and parameters: {'learning_rate': 6.930959799004485e-05, 'weight_decay': 0.0021692706436994454, 'num_train_epochs': 8}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.026104094460606575, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.436, 'eval_samples_per_second': 146.683, 'eval_steps_per_second': 18.335, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.71, 'learning_rate': 0.0003406747060794259, 'epoch': 1.98}\n",
      "{'loss': 0.4683, 'learning_rate': 0.00025676467995148843, 'epoch': 3.95}\n",
      "{'loss': 0.3099, 'learning_rate': 0.00017285465382355105, 'epoch': 5.93}\n",
      "{'loss': 0.2217, 'learning_rate': 8.894462769561366e-05, 'epoch': 7.91}\n",
      "{'loss': 0.1333, 'learning_rate': 5.034601567676244e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 44.2409, 'train_samples_per_second': 456.139, 'train_steps_per_second': 57.187, 'train_loss': 0.36941252207096387, 'epoch': 10.0}\n",
      "{'eval_loss': 0.16696679592132568, 'eval_accuracy': 0.9841584158415841, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.7, 'eval_f1': 0.6363636363636365, 'eval_runtime': 3.4264, 'eval_samples_per_second': 147.383, 'eval_steps_per_second': 18.678, 'epoch': 10.0}\n",
      "{'loss': 0.3601, 'learning_rate': 0.0003406747060794259, 'epoch': 1.98}\n",
      "{'loss': 0.239, 'learning_rate': 0.00025676467995148843, 'epoch': 3.95}\n",
      "{'loss': 0.1612, 'learning_rate': 0.00017285465382355105, 'epoch': 5.93}\n",
      "{'loss': 0.1792, 'learning_rate': 8.894462769561366e-05, 'epoch': 7.91}\n",
      "{'loss': 0.1338, 'learning_rate': 5.034601567676244e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 43.8947, 'train_samples_per_second': 459.737, 'train_steps_per_second': 57.638, 'train_loss': 0.21456956901097957, 'epoch': 10.0}\n",
      "{'eval_loss': 0.12333620339632034, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 4.0043, 'eval_samples_per_second': 126.116, 'eval_steps_per_second': 15.983, 'epoch': 10.0}\n",
      "{'loss': 0.3417, 'learning_rate': 0.0003406747060794259, 'epoch': 1.98}\n",
      "{'loss': 0.258, 'learning_rate': 0.00025676467995148843, 'epoch': 3.95}\n",
      "{'loss': 0.194, 'learning_rate': 0.00017285465382355105, 'epoch': 5.93}\n",
      "{'loss': 0.1841, 'learning_rate': 8.894462769561366e-05, 'epoch': 7.91}\n",
      "{'loss': 0.1461, 'learning_rate': 5.034601567676244e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 43.8798, 'train_samples_per_second': 459.893, 'train_steps_per_second': 57.658, 'train_loss': 0.2270381147211248, 'epoch': 10.0}\n",
      "{'eval_loss': 0.06200822815299034, 'eval_accuracy': 0.9920792079207921, 'eval_recall': 0.6666666666666666, 'eval_precision': 1.0, 'eval_f1': 0.8, 'eval_runtime': 3.5509, 'eval_samples_per_second': 142.216, 'eval_steps_per_second': 18.023, 'epoch': 10.0}\n",
      "{'loss': 0.312, 'learning_rate': 0.0003406747060794259, 'epoch': 1.98}\n",
      "{'loss': 0.2441, 'learning_rate': 0.00025676467995148843, 'epoch': 3.95}\n",
      "{'loss': 0.1509, 'learning_rate': 0.00017285465382355105, 'epoch': 5.93}\n",
      "{'loss': 0.1382, 'learning_rate': 8.894462769561366e-05, 'epoch': 7.91}\n",
      "{'loss': 0.1264, 'learning_rate': 5.034601567676244e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 39.5823, 'train_samples_per_second': 510.077, 'train_steps_per_second': 63.917, 'train_loss': 0.19435958881152007, 'epoch': 10.0}\n",
      "{'eval_loss': 0.08802943676710129, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 3.5105, 'eval_samples_per_second': 143.571, 'eval_steps_per_second': 17.946, 'epoch': 10.0}\n",
      "{'loss': 0.2416, 'learning_rate': 0.0003406747060794259, 'epoch': 1.98}\n",
      "{'loss': 0.2136, 'learning_rate': 0.00025676467995148843, 'epoch': 3.95}\n",
      "{'loss': 0.1563, 'learning_rate': 0.00017285465382355105, 'epoch': 5.93}\n",
      "{'loss': 0.1529, 'learning_rate': 8.894462769561366e-05, 'epoch': 7.91}\n",
      "{'loss': 0.1124, 'learning_rate': 5.034601567676244e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 43.1764, 'train_samples_per_second': 467.616, 'train_steps_per_second': 58.597, 'train_loss': 0.17439589641782136, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:40:39,685] Trial 21 finished with value: 0.7833389798607191 and parameters: {'learning_rate': 0.0004245847322073633, 'weight_decay': 0.002617403917231295, 'num_train_epochs': 10}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01750561036169529, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.4634, 'eval_samples_per_second': 145.521, 'eval_steps_per_second': 18.19, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6482, 'learning_rate': 0.0002266083620943772, 'epoch': 1.98}\n",
      "{'loss': 0.3793, 'learning_rate': 0.00017079349458344685, 'epoch': 3.95}\n",
      "{'loss': 0.1903, 'learning_rate': 0.00011497862707251651, 'epoch': 5.93}\n",
      "{'loss': 0.1454, 'learning_rate': 5.916375956158617e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0577, 'learning_rate': 3.3488920506558203e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 42.9067, 'train_samples_per_second': 470.322, 'train_steps_per_second': 58.965, 'train_loss': 0.28257428647972377, 'epoch': 10.0}\n",
      "{'eval_loss': 0.20991645753383636, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5, 'eval_precision': 0.6666666666666666, 'eval_f1': 0.5714285714285715, 'eval_runtime': 3.6619, 'eval_samples_per_second': 137.905, 'eval_steps_per_second': 17.477, 'epoch': 10.0}\n",
      "{'loss': 0.2503, 'learning_rate': 0.0002266083620943772, 'epoch': 1.98}\n",
      "{'loss': 0.1224, 'learning_rate': 0.00017079349458344685, 'epoch': 3.95}\n",
      "{'loss': 0.0388, 'learning_rate': 0.00011497862707251651, 'epoch': 5.93}\n",
      "{'loss': 0.0083, 'learning_rate': 5.916375956158617e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0052, 'learning_rate': 3.3488920506558203e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 45.4019, 'train_samples_per_second': 444.475, 'train_steps_per_second': 55.725, 'train_loss': 0.08401351540483784, 'epoch': 10.0}\n",
      "{'eval_loss': 0.1784883588552475, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.875, 'eval_f1': 0.7000000000000001, 'eval_runtime': 4.1359, 'eval_samples_per_second': 122.1, 'eval_steps_per_second': 15.474, 'epoch': 10.0}\n",
      "{'loss': 0.1704, 'learning_rate': 0.0002266083620943772, 'epoch': 1.98}\n",
      "{'loss': 0.0783, 'learning_rate': 0.00017079349458344685, 'epoch': 3.95}\n",
      "{'loss': 0.031, 'learning_rate': 0.00011497862707251651, 'epoch': 5.93}\n",
      "{'loss': 0.0068, 'learning_rate': 5.916375956158617e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0026, 'learning_rate': 3.3488920506558203e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 45.2597, 'train_samples_per_second': 445.871, 'train_steps_per_second': 55.9, 'train_loss': 0.05713115640991393, 'epoch': 10.0}\n",
      "{'eval_loss': 0.00411819014698267, 'eval_accuracy': 0.998019801980198, 'eval_recall': 1.0, 'eval_precision': 0.9230769230769231, 'eval_f1': 0.9600000000000001, 'eval_runtime': 3.5326, 'eval_samples_per_second': 142.953, 'eval_steps_per_second': 18.117, 'epoch': 10.0}\n",
      "{'loss': 0.1043, 'learning_rate': 0.0002266083620943772, 'epoch': 1.98}\n",
      "{'loss': 0.0596, 'learning_rate': 0.00017079349458344685, 'epoch': 3.95}\n",
      "{'loss': 0.0019, 'learning_rate': 0.00011497862707251651, 'epoch': 5.93}\n",
      "{'loss': 0.0071, 'learning_rate': 5.916375956158617e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0004, 'learning_rate': 3.3488920506558203e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 39.5515, 'train_samples_per_second': 510.474, 'train_steps_per_second': 63.967, 'train_loss': 0.03423269742294795, 'epoch': 10.0}\n",
      "{'eval_loss': 0.015917226672172546, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.8657, 'eval_samples_per_second': 130.379, 'eval_steps_per_second': 16.297, 'epoch': 10.0}\n",
      "{'loss': 0.0851, 'learning_rate': 0.0002266083620943772, 'epoch': 1.98}\n",
      "{'loss': 0.0181, 'learning_rate': 0.00017079349458344685, 'epoch': 3.95}\n",
      "{'loss': 0.0203, 'learning_rate': 0.00011497862707251651, 'epoch': 5.93}\n",
      "{'loss': 0.0168, 'learning_rate': 5.916375956158617e-05, 'epoch': 7.91}\n",
      "{'loss': 0.0001, 'learning_rate': 3.3488920506558203e-06, 'epoch': 9.88}\n",
      "{'train_runtime': 45.9399, 'train_samples_per_second': 439.487, 'train_steps_per_second': 55.072, 'train_loss': 0.027756635705170153, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:44:58,465] Trial 22 finished with value: 0.8280662525879918 and parameters: {'learning_rate': 0.00028242322960530755, 'weight_decay': 0.0014598004623382166, 'num_train_epochs': 10}. Best is trial 10 with value: 0.8404472049689442.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02137482352554798, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.7112, 'eval_samples_per_second': 135.806, 'eval_steps_per_second': 16.976, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6868, 'learning_rate': 0.00039473897963830375, 'epoch': 1.98}\n",
      "{'loss': 0.4324, 'learning_rate': 0.0002836700489578581, 'epoch': 3.95}\n",
      "{'loss': 0.239, 'learning_rate': 0.00017260111827741248, 'epoch': 5.93}\n",
      "{'loss': 0.1847, 'learning_rate': 6.153218759696687e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 41.7559, 'train_samples_per_second': 434.957, 'train_steps_per_second': 54.531, 'train_loss': 0.3498755091892087, 'epoch': 9.0}\n",
      "{'eval_loss': 0.17893925309181213, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.5, 'eval_precision': 0.8571428571428571, 'eval_f1': 0.631578947368421, 'eval_runtime': 3.6786, 'eval_samples_per_second': 137.28, 'eval_steps_per_second': 17.398, 'epoch': 9.0}\n",
      "{'loss': 0.3538, 'learning_rate': 0.00039473897963830375, 'epoch': 1.98}\n",
      "{'loss': 0.2313, 'learning_rate': 0.0002836700489578581, 'epoch': 3.95}\n",
      "{'loss': 0.1525, 'learning_rate': 0.00017260111827741248, 'epoch': 5.93}\n",
      "{'loss': 0.1253, 'learning_rate': 6.153218759696687e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 40.2384, 'train_samples_per_second': 451.36, 'train_steps_per_second': 56.588, 'train_loss': 0.19594230702114984, 'epoch': 9.0}\n",
      "{'eval_loss': 0.12490839511156082, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.4136, 'eval_samples_per_second': 147.937, 'eval_steps_per_second': 18.748, 'epoch': 9.0}\n",
      "{'loss': 0.4266, 'learning_rate': 0.00039473897963830375, 'epoch': 1.98}\n",
      "{'loss': 0.2865, 'learning_rate': 0.0002836700489578581, 'epoch': 3.95}\n",
      "{'loss': 0.195, 'learning_rate': 0.00017260111827741248, 'epoch': 5.93}\n",
      "{'loss': 0.1279, 'learning_rate': 6.153218759696687e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.5713, 'train_samples_per_second': 458.968, 'train_steps_per_second': 57.542, 'train_loss': 0.23926318105396913, 'epoch': 9.0}\n",
      "{'eval_loss': 0.05850444734096527, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 3.9586, 'eval_samples_per_second': 127.572, 'eval_steps_per_second': 16.167, 'epoch': 9.0}\n",
      "{'loss': 0.3161, 'learning_rate': 0.00039473897963830375, 'epoch': 1.98}\n",
      "{'loss': 0.2092, 'learning_rate': 0.0002836700489578581, 'epoch': 3.95}\n",
      "{'loss': 0.0543, 'learning_rate': 0.00017260111827741248, 'epoch': 5.93}\n",
      "{'loss': 0.0368, 'learning_rate': 6.153218759696687e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 35.5935, 'train_samples_per_second': 510.515, 'train_steps_per_second': 63.972, 'train_loss': 0.13731724764623293, 'epoch': 9.0}\n",
      "{'eval_loss': 0.06525465846061707, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.8181818181818182, 'eval_precision': 1.0, 'eval_f1': 0.9, 'eval_runtime': 4.3807, 'eval_samples_per_second': 115.051, 'eval_steps_per_second': 14.381, 'epoch': 9.0}\n",
      "{'loss': 0.2437, 'learning_rate': 0.00039473897963830375, 'epoch': 1.98}\n",
      "{'loss': 0.1248, 'learning_rate': 0.0002836700489578581, 'epoch': 3.95}\n",
      "{'loss': 0.0792, 'learning_rate': 0.00017260111827741248, 'epoch': 5.93}\n",
      "{'loss': 0.097, 'learning_rate': 6.153218759696687e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 43.0957, 'train_samples_per_second': 421.643, 'train_steps_per_second': 52.836, 'train_loss': 0.12605262106324583, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:48:58,804] Trial 23 finished with value: 0.7670175438596492 and parameters: {'learning_rate': 0.0005058079103187494, 'weight_decay': 0.005868233964609601, 'num_train_epochs': 9}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.026206234470009804, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.8181818181818182, 'eval_precision': 1.0, 'eval_f1': 0.9, 'eval_runtime': 3.3309, 'eval_samples_per_second': 151.31, 'eval_steps_per_second': 18.914, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6518, 'learning_rate': 9.256232541200551e-05, 'epoch': 1.98}\n",
      "{'loss': 0.4069, 'learning_rate': 5.6149136815622546e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2805, 'learning_rate': 1.973594821923957e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 32.3537, 'train_samples_per_second': 436.611, 'train_steps_per_second': 54.739, 'train_loss': 0.40884442062851806, 'epoch': 7.0}\n",
      "{'eval_loss': 0.163301020860672, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.4166666666666667, 'eval_precision': 0.625, 'eval_f1': 0.5, 'eval_runtime': 4.3677, 'eval_samples_per_second': 115.621, 'eval_steps_per_second': 14.653, 'epoch': 7.0}\n",
      "{'loss': 0.2926, 'learning_rate': 9.256232541200551e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1418, 'learning_rate': 5.6149136815622546e-05, 'epoch': 3.95}\n",
      "{'loss': 0.062, 'learning_rate': 1.973594821923957e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 30.6333, 'train_samples_per_second': 461.133, 'train_steps_per_second': 57.813, 'train_loss': 0.15324895870611535, 'epoch': 7.0}\n",
      "{'eval_loss': 0.16195447742938995, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.802, 'eval_samples_per_second': 132.824, 'eval_steps_per_second': 16.833, 'epoch': 7.0}\n",
      "{'loss': 0.189, 'learning_rate': 9.256232541200551e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0495, 'learning_rate': 5.6149136815622546e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0182, 'learning_rate': 1.973594821923957e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 28.7986, 'train_samples_per_second': 490.51, 'train_steps_per_second': 61.496, 'train_loss': 0.07721367830075092, 'epoch': 7.0}\n",
      "{'eval_loss': 0.02778732031583786, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.8333333333333334, 'eval_precision': 1.0, 'eval_f1': 0.9090909090909091, 'eval_runtime': 4.1192, 'eval_samples_per_second': 122.595, 'eval_steps_per_second': 15.537, 'epoch': 7.0}\n",
      "{'loss': 0.1055, 'learning_rate': 9.256232541200551e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0291, 'learning_rate': 5.6149136815622546e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0145, 'learning_rate': 1.973594821923957e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 28.5999, 'train_samples_per_second': 494.163, 'train_steps_per_second': 61.923, 'train_loss': 0.0420869899145104, 'epoch': 7.0}\n",
      "{'eval_loss': 0.029479434713721275, 'eval_accuracy': 0.996031746031746, 'eval_recall': 1.0, 'eval_precision': 0.8461538461538461, 'eval_f1': 0.9166666666666666, 'eval_runtime': 3.8301, 'eval_samples_per_second': 131.591, 'eval_steps_per_second': 16.449, 'epoch': 7.0}\n",
      "{'loss': 0.0412, 'learning_rate': 9.256232541200551e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0158, 'learning_rate': 5.6149136815622546e-05, 'epoch': 3.95}\n",
      "{'loss': 0.002, 'learning_rate': 1.973594821923957e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 29.7058, 'train_samples_per_second': 475.766, 'train_steps_per_second': 59.618, 'train_loss': 0.01666012807643511, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:52:09,761] Trial 24 finished with value: 0.7732747644512351 and parameters: {'learning_rate': 0.00012897551400838848, 'weight_decay': 0.002463675633151658, 'num_train_epochs': 7}. Best is trial 10 with value: 0.8404472049689442.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03471343591809273, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.9559, 'eval_samples_per_second': 127.406, 'eval_steps_per_second': 15.926, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.687, 'learning_rate': 0.00020281071456198225, 'epoch': 1.98}\n",
      "{'loss': 0.3812, 'learning_rate': 0.0001457452349440919, 'epoch': 3.95}\n",
      "{'loss': 0.212, 'learning_rate': 8.867975532620158e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1629, 'learning_rate': 3.161427570831124e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.2792, 'train_samples_per_second': 462.382, 'train_steps_per_second': 57.97, 'train_loss': 0.33011305117533823, 'epoch': 9.0}\n",
      "{'eval_loss': 0.17361803352832794, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.6363636363636364, 'eval_f1': 0.6086956521739131, 'eval_runtime': 3.9637, 'eval_samples_per_second': 127.408, 'eval_steps_per_second': 16.147, 'epoch': 9.0}\n",
      "{'loss': 0.3027, 'learning_rate': 0.00020281071456198225, 'epoch': 1.98}\n",
      "{'loss': 0.1004, 'learning_rate': 0.0001457452349440919, 'epoch': 3.95}\n",
      "{'loss': 0.0339, 'learning_rate': 8.867975532620158e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0035, 'learning_rate': 3.161427570831124e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 38.9519, 'train_samples_per_second': 466.267, 'train_steps_per_second': 58.457, 'train_loss': 0.09676906007080681, 'epoch': 9.0}\n",
      "{'eval_loss': 0.17920945584774017, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 4.0217, 'eval_samples_per_second': 125.567, 'eval_steps_per_second': 15.913, 'epoch': 9.0}\n",
      "{'loss': 0.1592, 'learning_rate': 0.00020281071456198225, 'epoch': 1.98}\n",
      "{'loss': 0.1043, 'learning_rate': 0.0001457452349440919, 'epoch': 3.95}\n",
      "{'loss': 0.0612, 'learning_rate': 8.867975532620158e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0199, 'learning_rate': 3.161427570831124e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.1791, 'train_samples_per_second': 463.563, 'train_steps_per_second': 58.118, 'train_loss': 0.07569858819233204, 'epoch': 9.0}\n",
      "{'eval_loss': 0.0007958991336636245, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 3.7843, 'eval_samples_per_second': 133.446, 'eval_steps_per_second': 16.912, 'epoch': 9.0}\n",
      "{'loss': 0.1067, 'learning_rate': 0.00020281071456198225, 'epoch': 1.98}\n",
      "{'loss': 0.0229, 'learning_rate': 0.0001457452349440919, 'epoch': 3.95}\n",
      "{'loss': 0.0092, 'learning_rate': 8.867975532620158e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0114, 'learning_rate': 3.161427570831124e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 34.3184, 'train_samples_per_second': 529.482, 'train_steps_per_second': 66.349, 'train_loss': 0.033039116845038775, 'epoch': 9.0}\n",
      "{'eval_loss': 8.418921424890868e-06, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 4.1196, 'eval_samples_per_second': 122.341, 'eval_steps_per_second': 15.293, 'epoch': 9.0}\n",
      "{'loss': 0.1184, 'learning_rate': 0.00020281071456198225, 'epoch': 1.98}\n",
      "{'loss': 0.0557, 'learning_rate': 0.0001457452349440919, 'epoch': 3.95}\n",
      "{'loss': 0.0032, 'learning_rate': 8.867975532620158e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0003, 'learning_rate': 3.161427570831124e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.3191, 'train_samples_per_second': 462.142, 'train_steps_per_second': 57.911, 'train_loss': 0.039043038990225876, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:56:01,323] Trial 25 finished with value: 0.8595837419636047 and parameters: {'learning_rate': 0.00025987619417987257, 'weight_decay': 0.0010315325907121007, 'num_train_epochs': 9}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.021524859592318535, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.7437, 'eval_samples_per_second': 134.625, 'eval_steps_per_second': 16.828, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6528, 'learning_rate': 0.0001812590659824179, 'epoch': 1.98}\n",
      "{'loss': 0.3824, 'learning_rate': 0.00012179086848162461, 'epoch': 3.95}\n",
      "{'loss': 0.2018, 'learning_rate': 6.232267098083135e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1131, 'learning_rate': 2.854473480038077e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.3478, 'train_samples_per_second': 470.015, 'train_steps_per_second': 58.927, 'train_loss': 0.33406305860860547, 'epoch': 8.0}\n",
      "{'eval_loss': 0.2243821918964386, 'eval_accuracy': 0.9782178217821782, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5384615384615384, 'eval_f1': 0.5599999999999999, 'eval_runtime': 4.233, 'eval_samples_per_second': 119.302, 'eval_steps_per_second': 15.119, 'epoch': 8.0}\n",
      "{'loss': 0.2547, 'learning_rate': 0.0001812590659824179, 'epoch': 1.98}\n",
      "{'loss': 0.0835, 'learning_rate': 0.00012179086848162461, 'epoch': 3.95}\n",
      "{'loss': 0.0264, 'learning_rate': 6.232267098083135e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0242, 'learning_rate': 2.854473480038077e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.5676, 'train_samples_per_second': 453.896, 'train_steps_per_second': 56.906, 'train_loss': 0.09605921117226288, 'epoch': 8.0}\n",
      "{'eval_loss': 0.1395559161901474, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 4.1838, 'eval_samples_per_second': 120.705, 'eval_steps_per_second': 15.297, 'epoch': 8.0}\n",
      "{'loss': 0.1481, 'learning_rate': 0.0001812590659824179, 'epoch': 1.98}\n",
      "{'loss': 0.0465, 'learning_rate': 0.00012179086848162461, 'epoch': 3.95}\n",
      "{'loss': 0.0187, 'learning_rate': 6.232267098083135e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0006, 'learning_rate': 2.854473480038077e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 36.6763, 'train_samples_per_second': 440.175, 'train_steps_per_second': 55.185, 'train_loss': 0.05284852936153904, 'epoch': 8.0}\n",
      "{'eval_loss': 3.543898856150918e-05, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 4.687, 'eval_samples_per_second': 107.745, 'eval_steps_per_second': 13.655, 'epoch': 8.0}\n",
      "{'loss': 0.1195, 'learning_rate': 0.0001812590659824179, 'epoch': 1.98}\n",
      "{'loss': 0.0571, 'learning_rate': 0.00012179086848162461, 'epoch': 3.95}\n",
      "{'loss': 0.0148, 'learning_rate': 6.232267098083135e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0002, 'learning_rate': 2.854473480038077e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.1781, 'train_samples_per_second': 459.15, 'train_steps_per_second': 57.536, 'train_loss': 0.047332830567978344, 'epoch': 8.0}\n",
      "{'eval_loss': 0.018668752163648605, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.7459, 'eval_samples_per_second': 134.547, 'eval_steps_per_second': 16.818, 'epoch': 8.0}\n",
      "{'loss': 0.0707, 'learning_rate': 0.0001812590659824179, 'epoch': 1.98}\n",
      "{'loss': 0.0498, 'learning_rate': 0.00012179086848162461, 'epoch': 3.95}\n",
      "{'loss': 0.0001, 'learning_rate': 6.232267098083135e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.854473480038077e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 40.8192, 'train_samples_per_second': 395.696, 'train_steps_per_second': 49.585, 'train_loss': 0.02979805420534241, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 14:59:46,914] Trial 26 finished with value: 0.8411489593549091 and parameters: {'learning_rate': 0.00024072726348321118, 'weight_decay': 0.0008559505656596687, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.013256501406431198, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.4266, 'eval_samples_per_second': 147.085, 'eval_steps_per_second': 18.386, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6757, 'learning_rate': 6.285623955782027e-05, 'epoch': 1.98}\n",
      "{'loss': 0.4815, 'learning_rate': 4.517018453311001e-05, 'epoch': 3.95}\n",
      "{'loss': 0.3963, 'learning_rate': 2.7484129508399745e-05, 'epoch': 5.93}\n",
      "{'loss': 0.3215, 'learning_rate': 9.798074483689485e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 45.0615, 'train_samples_per_second': 403.049, 'train_steps_per_second': 50.531, 'train_loss': 0.44908691258822087, 'epoch': 9.0}\n",
      "{'eval_loss': 0.16710777580738068, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.4166666666666667, 'eval_precision': 0.625, 'eval_f1': 0.5, 'eval_runtime': 3.3766, 'eval_samples_per_second': 149.56, 'eval_steps_per_second': 18.954, 'epoch': 9.0}\n",
      "{'loss': 0.3185, 'learning_rate': 6.285623955782027e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1813, 'learning_rate': 4.517018453311001e-05, 'epoch': 3.95}\n",
      "{'loss': 0.1313, 'learning_rate': 2.7484129508399745e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1026, 'learning_rate': 9.798074483689485e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 45.9063, 'train_samples_per_second': 395.632, 'train_steps_per_second': 49.601, 'train_loss': 0.16957830011085506, 'epoch': 9.0}\n",
      "{'eval_loss': 0.18143512308597565, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.8591, 'eval_samples_per_second': 130.859, 'eval_steps_per_second': 16.584, 'epoch': 9.0}\n",
      "{'loss': 0.223, 'learning_rate': 6.285623955782027e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0934, 'learning_rate': 4.517018453311001e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0546, 'learning_rate': 2.7484129508399745e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0301, 'learning_rate': 9.798074483689485e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 46.8192, 'train_samples_per_second': 387.918, 'train_steps_per_second': 48.634, 'train_loss': 0.09179449479308734, 'epoch': 9.0}\n",
      "{'eval_loss': 0.011989705264568329, 'eval_accuracy': 0.998019801980198, 'eval_recall': 0.9166666666666666, 'eval_precision': 1.0, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.6232, 'eval_samples_per_second': 139.378, 'eval_steps_per_second': 17.664, 'epoch': 9.0}\n",
      "{'loss': 0.1215, 'learning_rate': 6.285623955782027e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0577, 'learning_rate': 4.517018453311001e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0116, 'learning_rate': 2.7484129508399745e-05, 'epoch': 5.93}\n",
      "{'loss': 0.002, 'learning_rate': 9.798074483689485e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 40.5818, 'train_samples_per_second': 447.763, 'train_steps_per_second': 56.109, 'train_loss': 0.042347404758781716, 'epoch': 9.0}\n",
      "{'eval_loss': 0.026887496933341026, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.233, 'eval_samples_per_second': 155.891, 'eval_steps_per_second': 19.486, 'epoch': 9.0}\n",
      "{'loss': 0.0373, 'learning_rate': 6.285623955782027e-05, 'epoch': 1.98}\n",
      "{'loss': 0.066, 'learning_rate': 4.517018453311001e-05, 'epoch': 3.95}\n",
      "{'loss': 0.01, 'learning_rate': 2.7484129508399745e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 9.798074483689485e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 46.3286, 'train_samples_per_second': 392.22, 'train_steps_per_second': 49.149, 'train_loss': 0.026031901388108847, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:04:09,403] Trial 27 finished with value: 0.7969320534537927 and parameters: {'learning_rate': 8.054229458253053e-05, 'weight_decay': 0.0004550302766717642, 'num_train_epochs': 9}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03537813946604729, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.3708, 'eval_samples_per_second': 149.519, 'eval_steps_per_second': 18.69, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6355, 'learning_rate': 0.00012210104169115303, 'epoch': 1.98}\n",
      "{'loss': 0.3762, 'learning_rate': 8.204164481085348e-05, 'epoch': 3.95}\n",
      "{'loss': 0.224, 'learning_rate': 4.1982247930553934e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1573, 'learning_rate': 1.9228510502543783e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 40.6011, 'train_samples_per_second': 397.625, 'train_steps_per_second': 49.851, 'train_loss': 0.3452305281350735, 'epoch': 8.0}\n",
      "{'eval_loss': 0.18303821980953217, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5, 'eval_precision': 0.6, 'eval_f1': 0.5454545454545454, 'eval_runtime': 4.0497, 'eval_samples_per_second': 124.702, 'eval_steps_per_second': 15.804, 'epoch': 8.0}\n",
      "{'loss': 0.3018, 'learning_rate': 0.00012210104169115303, 'epoch': 1.98}\n",
      "{'loss': 0.0903, 'learning_rate': 8.204164481085348e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0351, 'learning_rate': 4.1982247930553934e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0111, 'learning_rate': 1.9228510502543783e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.5438, 'train_samples_per_second': 454.2, 'train_steps_per_second': 56.944, 'train_loss': 0.10828670415578211, 'epoch': 8.0}\n",
      "{'eval_loss': 0.16533122956752777, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 4.0053, 'eval_samples_per_second': 126.084, 'eval_steps_per_second': 15.979, 'epoch': 8.0}\n",
      "{'loss': 0.128, 'learning_rate': 0.00012210104169115303, 'epoch': 1.98}\n",
      "{'loss': 0.0399, 'learning_rate': 8.204164481085348e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0287, 'learning_rate': 4.1982247930553934e-05, 'epoch': 5.93}\n",
      "{'loss': 0.001, 'learning_rate': 1.9228510502543783e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.5422, 'train_samples_per_second': 454.221, 'train_steps_per_second': 56.946, 'train_loss': 0.04880201291890397, 'epoch': 8.0}\n",
      "{'eval_loss': 5.7136381656164303e-05, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 4.1009, 'eval_samples_per_second': 123.143, 'eval_steps_per_second': 15.606, 'epoch': 8.0}\n",
      "{'loss': 0.0776, 'learning_rate': 0.00012210104169115303, 'epoch': 1.98}\n",
      "{'loss': 0.0674, 'learning_rate': 8.204164481085348e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0277, 'learning_rate': 4.1982247930553934e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0009, 'learning_rate': 1.9228510502543783e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 31.6965, 'train_samples_per_second': 509.584, 'train_steps_per_second': 63.856, 'train_loss': 0.04289542914239064, 'epoch': 8.0}\n",
      "{'eval_loss': 0.02525922656059265, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.7039, 'eval_samples_per_second': 136.075, 'eval_steps_per_second': 17.009, 'epoch': 8.0}\n",
      "{'loss': 0.0238, 'learning_rate': 0.00012210104169115303, 'epoch': 1.98}\n",
      "{'loss': 0.0393, 'learning_rate': 8.204164481085348e-05, 'epoch': 3.95}\n",
      "{'loss': 0.015, 'learning_rate': 4.1982247930553934e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0002, 'learning_rate': 1.9228510502543783e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.4847, 'train_samples_per_second': 482.37, 'train_steps_per_second': 60.446, 'train_loss': 0.01935130377673095, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:07:46,340] Trial 28 finished with value: 0.8382398684458181 and parameters: {'learning_rate': 0.0001621604385714526, 'weight_decay': 0.0010302890161730603, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.022622711956501007, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.6123, 'eval_samples_per_second': 139.523, 'eval_steps_per_second': 17.44, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6531, 'learning_rate': 0.00015258875096570525, 'epoch': 1.98}\n",
      "{'loss': 0.3826, 'learning_rate': 9.25617049524459e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2255, 'learning_rate': 3.2534658939186565e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 35.1122, 'train_samples_per_second': 402.31, 'train_steps_per_second': 50.438, 'train_loss': 0.382750504169001, 'epoch': 7.0}\n",
      "{'eval_loss': 0.18413634598255157, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.6363636363636364, 'eval_f1': 0.6086956521739131, 'eval_runtime': 3.3715, 'eval_samples_per_second': 149.787, 'eval_steps_per_second': 18.983, 'epoch': 7.0}\n",
      "{'loss': 0.2962, 'learning_rate': 0.00015258875096570525, 'epoch': 1.98}\n",
      "{'loss': 0.1039, 'learning_rate': 9.25617049524459e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0439, 'learning_rate': 3.2534658939186565e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 32.6095, 'train_samples_per_second': 433.186, 'train_steps_per_second': 54.309, 'train_loss': 0.12561674253675373, 'epoch': 7.0}\n",
      "{'eval_loss': 0.1558654010295868, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.7884, 'eval_samples_per_second': 133.301, 'eval_steps_per_second': 16.894, 'epoch': 7.0}\n",
      "{'loss': 0.1642, 'learning_rate': 0.00015258875096570525, 'epoch': 1.98}\n",
      "{'loss': 0.0403, 'learning_rate': 9.25617049524459e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0071, 'learning_rate': 3.2534658939186565e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 29.867, 'train_samples_per_second': 472.963, 'train_steps_per_second': 59.296, 'train_loss': 0.05994760537470619, 'epoch': 7.0}\n",
      "{'eval_loss': 0.01432446576654911, 'eval_accuracy': 0.998019801980198, 'eval_recall': 1.0, 'eval_precision': 0.9230769230769231, 'eval_f1': 0.9600000000000001, 'eval_runtime': 4.0223, 'eval_samples_per_second': 125.55, 'eval_steps_per_second': 15.911, 'epoch': 7.0}\n",
      "{'loss': 0.1063, 'learning_rate': 0.00015258875096570525, 'epoch': 1.98}\n",
      "{'loss': 0.017, 'learning_rate': 9.25617049524459e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0198, 'learning_rate': 3.2534658939186565e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 26.8089, 'train_samples_per_second': 527.176, 'train_steps_per_second': 66.06, 'train_loss': 0.04138120791792264, 'epoch': 7.0}\n",
      "{'eval_loss': 0.023163840174674988, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.159, 'eval_samples_per_second': 121.183, 'eval_steps_per_second': 15.148, 'epoch': 7.0}\n",
      "{'loss': 0.0787, 'learning_rate': 0.00015258875096570525, 'epoch': 1.98}\n",
      "{'loss': 0.0511, 'learning_rate': 9.25617049524459e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0028, 'learning_rate': 3.2534658939186565e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 29.7149, 'train_samples_per_second': 475.62, 'train_steps_per_second': 59.6, 'train_loss': 0.03745042073647142, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:11:00,573] Trial 29 finished with value: 0.8288530020703935 and parameters: {'learning_rate': 0.00021261579697896458, 'weight_decay': 0.0003399680087934945, 'num_train_epochs': 7}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.023858852684497833, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.8559, 'eval_samples_per_second': 130.709, 'eval_steps_per_second': 16.339, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7596, 'learning_rate': 0.0004976334802805095, 'epoch': 1.98}\n",
      "{'loss': 0.6885, 'learning_rate': 0.0003576128049061399, 'epoch': 3.95}\n",
      "{'loss': 0.4747, 'learning_rate': 0.0002175921295317703, 'epoch': 5.93}\n",
      "{'loss': 0.4098, 'learning_rate': 7.757145415740074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 40.1509, 'train_samples_per_second': 452.343, 'train_steps_per_second': 56.711, 'train_loss': 0.5537934401708577, 'epoch': 9.0}\n",
      "{'eval_loss': 0.17693516612052917, 'eval_accuracy': 0.9782178217821782, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5384615384615384, 'eval_f1': 0.5599999999999999, 'eval_runtime': 3.6772, 'eval_samples_per_second': 137.331, 'eval_steps_per_second': 17.404, 'epoch': 9.0}\n",
      "{'loss': 0.6414, 'learning_rate': 0.0004976334802805095, 'epoch': 1.98}\n",
      "{'loss': 0.4986, 'learning_rate': 0.0003576128049061399, 'epoch': 3.95}\n",
      "{'loss': 0.3802, 'learning_rate': 0.0002175921295317703, 'epoch': 5.93}\n",
      "{'loss': 0.3251, 'learning_rate': 7.757145415740074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 42.314, 'train_samples_per_second': 429.219, 'train_steps_per_second': 53.812, 'train_loss': 0.43152080463850034, 'epoch': 9.0}\n",
      "{'eval_loss': 0.1797298789024353, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.3333333333333333, 'eval_precision': 0.6666666666666666, 'eval_f1': 0.4444444444444444, 'eval_runtime': 3.7388, 'eval_samples_per_second': 135.068, 'eval_steps_per_second': 17.118, 'epoch': 9.0}\n",
      "{'loss': 0.5731, 'learning_rate': 0.0004976334802805095, 'epoch': 1.98}\n",
      "{'loss': 0.4772, 'learning_rate': 0.0003576128049061399, 'epoch': 3.95}\n",
      "{'loss': 0.412, 'learning_rate': 0.0002175921295317703, 'epoch': 5.93}\n",
      "{'loss': 0.4112, 'learning_rate': 7.757145415740074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 43.3035, 'train_samples_per_second': 419.412, 'train_steps_per_second': 52.582, 'train_loss': 0.45491408464099214, 'epoch': 9.0}\n",
      "{'eval_loss': 0.08810976147651672, 'eval_accuracy': 0.9920792079207921, 'eval_recall': 0.6666666666666666, 'eval_precision': 1.0, 'eval_f1': 0.8, 'eval_runtime': 3.4296, 'eval_samples_per_second': 147.248, 'eval_steps_per_second': 18.661, 'epoch': 9.0}\n",
      "{'loss': 0.5094, 'learning_rate': 0.0004976334802805095, 'epoch': 1.98}\n",
      "{'loss': 0.4643, 'learning_rate': 0.0003576128049061399, 'epoch': 3.95}\n",
      "{'loss': 0.3241, 'learning_rate': 0.0002175921295317703, 'epoch': 5.93}\n",
      "{'loss': 0.3078, 'learning_rate': 7.757145415740074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 43.1157, 'train_samples_per_second': 421.447, 'train_steps_per_second': 52.811, 'train_loss': 0.38546119324722256, 'epoch': 9.0}\n",
      "{'eval_loss': 0.14589688181877136, 'eval_accuracy': 0.9861111111111112, 'eval_recall': 0.45454545454545453, 'eval_precision': 0.8333333333333334, 'eval_f1': 0.5882352941176471, 'eval_runtime': 4.1005, 'eval_samples_per_second': 122.912, 'eval_steps_per_second': 15.364, 'epoch': 9.0}\n",
      "{'loss': 0.3936, 'learning_rate': 0.0004976334802805095, 'epoch': 1.98}\n",
      "{'loss': 0.3977, 'learning_rate': 0.0003576128049061399, 'epoch': 3.95}\n",
      "{'loss': 0.3086, 'learning_rate': 0.0002175921295317703, 'epoch': 5.93}\n",
      "{'loss': 0.3013, 'learning_rate': 7.757145415740074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 46.7135, 'train_samples_per_second': 388.988, 'train_steps_per_second': 48.744, 'train_loss': 0.33420997153890725, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:15:15,758] Trial 30 finished with value: 0.5785359477124182 and parameters: {'learning_rate': 0.000637654155654879, 'weight_decay': 0.0009381305031932445, 'num_train_epochs': 9}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13738617300987244, 'eval_accuracy': 0.9801587301587301, 'eval_recall': 0.45454545454545453, 'eval_precision': 0.5555555555555556, 'eval_f1': 0.5, 'eval_runtime': 3.5806, 'eval_samples_per_second': 140.758, 'eval_steps_per_second': 17.595, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6474, 'learning_rate': 0.00010256490410621743, 'epoch': 1.98}\n",
      "{'loss': 0.3971, 'learning_rate': 6.891500118423008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.259, 'learning_rate': 3.526509826224274e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1748, 'learning_rate': 1.6151953402553923e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 36.6457, 'train_samples_per_second': 440.543, 'train_steps_per_second': 55.232, 'train_loss': 0.36565201384983514, 'epoch': 8.0}\n",
      "{'eval_loss': 0.17006607353687286, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5, 'eval_precision': 0.6, 'eval_f1': 0.5454545454545454, 'eval_runtime': 3.8287, 'eval_samples_per_second': 131.899, 'eval_steps_per_second': 16.716, 'epoch': 8.0}\n",
      "{'loss': 0.297, 'learning_rate': 0.00010256490410621743, 'epoch': 1.98}\n",
      "{'loss': 0.1234, 'learning_rate': 6.891500118423008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0348, 'learning_rate': 3.526509826224274e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0306, 'learning_rate': 1.6151953402553923e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 35.261, 'train_samples_per_second': 457.844, 'train_steps_per_second': 57.401, 'train_loss': 0.12002336852581023, 'epoch': 8.0}\n",
      "{'eval_loss': 0.14833495020866394, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.5245, 'eval_samples_per_second': 143.283, 'eval_steps_per_second': 18.159, 'epoch': 8.0}\n",
      "{'loss': 0.1157, 'learning_rate': 0.00010256490410621743, 'epoch': 1.98}\n",
      "{'loss': 0.0292, 'learning_rate': 6.891500118423008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0071, 'learning_rate': 3.526509826224274e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0067, 'learning_rate': 1.6151953402553923e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.7877, 'train_samples_per_second': 477.808, 'train_steps_per_second': 59.904, 'train_loss': 0.03920772606060608, 'epoch': 8.0}\n",
      "{'eval_loss': 0.0022448429372161627, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 4.6293, 'eval_samples_per_second': 109.089, 'eval_steps_per_second': 13.825, 'epoch': 8.0}\n",
      "{'loss': 0.0805, 'learning_rate': 0.00010256490410621743, 'epoch': 1.98}\n",
      "{'loss': 0.0184, 'learning_rate': 6.891500118423008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0011, 'learning_rate': 3.526509826224274e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0125, 'learning_rate': 1.6151953402553923e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 32.2314, 'train_samples_per_second': 501.127, 'train_steps_per_second': 62.796, 'train_loss': 0.02779604022354128, 'epoch': 8.0}\n",
      "{'eval_loss': 0.028173105791211128, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.1136, 'eval_samples_per_second': 122.522, 'eval_steps_per_second': 15.315, 'epoch': 8.0}\n",
      "{'loss': 0.0173, 'learning_rate': 0.00010256490410621743, 'epoch': 1.98}\n",
      "{'loss': 0.0466, 'learning_rate': 6.891500118423008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0005, 'learning_rate': 3.526509826224274e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0002, 'learning_rate': 1.6151953402553923e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.9462, 'train_samples_per_second': 475.811, 'train_steps_per_second': 59.624, 'train_loss': 0.015924374035075347, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:18:49,232] Trial 31 finished with value: 0.8242047807265198 and parameters: {'learning_rate': 0.00013621480702820477, 'weight_decay': 0.0011007519511578529, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0320654958486557, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.5297, 'eval_samples_per_second': 142.787, 'eval_steps_per_second': 17.848, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6606, 'learning_rate': 0.0001770327159640033, 'epoch': 1.98}\n",
      "{'loss': 0.359, 'learning_rate': 0.00010738963336604762, 'epoch': 3.95}\n",
      "{'loss': 0.2142, 'learning_rate': 3.774655076809197e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 31.6311, 'train_samples_per_second': 446.586, 'train_steps_per_second': 55.989, 'train_loss': 0.37075520261810835, 'epoch': 7.0}\n",
      "{'eval_loss': 0.16970349848270416, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5, 'eval_precision': 0.6666666666666666, 'eval_f1': 0.5714285714285715, 'eval_runtime': 3.5336, 'eval_samples_per_second': 142.912, 'eval_steps_per_second': 18.112, 'epoch': 7.0}\n",
      "{'loss': 0.2723, 'learning_rate': 0.0001770327159640033, 'epoch': 1.98}\n",
      "{'loss': 0.1028, 'learning_rate': 0.00010738963336604762, 'epoch': 3.95}\n",
      "{'loss': 0.0502, 'learning_rate': 3.774655076809197e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 33.3136, 'train_samples_per_second': 424.032, 'train_steps_per_second': 53.162, 'train_loss': 0.1257699673489485, 'epoch': 7.0}\n",
      "{'eval_loss': 0.1272544413805008, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.7697, 'eval_samples_per_second': 133.964, 'eval_steps_per_second': 16.978, 'epoch': 7.0}\n",
      "{'loss': 0.1845, 'learning_rate': 0.0001770327159640033, 'epoch': 1.98}\n",
      "{'loss': 0.0745, 'learning_rate': 0.00010738963336604762, 'epoch': 3.95}\n",
      "{'loss': 0.0326, 'learning_rate': 3.774655076809197e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 35.9221, 'train_samples_per_second': 393.24, 'train_steps_per_second': 49.301, 'train_loss': 0.08244773619327082, 'epoch': 7.0}\n",
      "{'eval_loss': 0.034939005970954895, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.8333333333333334, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.8695652173913043, 'eval_runtime': 3.6271, 'eval_samples_per_second': 139.228, 'eval_steps_per_second': 17.645, 'epoch': 7.0}\n",
      "{'loss': 0.1326, 'learning_rate': 0.0001770327159640033, 'epoch': 1.98}\n",
      "{'loss': 0.0147, 'learning_rate': 0.00010738963336604762, 'epoch': 3.95}\n",
      "{'loss': 0.0005, 'learning_rate': 3.774655076809197e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 30.3584, 'train_samples_per_second': 465.539, 'train_steps_per_second': 58.336, 'train_loss': 0.04171855942273059, 'epoch': 7.0}\n",
      "{'eval_loss': 0.022952839732170105, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.062, 'eval_samples_per_second': 124.078, 'eval_steps_per_second': 15.51, 'epoch': 7.0}\n",
      "{'loss': 0.0773, 'learning_rate': 0.0001770327159640033, 'epoch': 1.98}\n",
      "{'loss': 0.0641, 'learning_rate': 0.00010738963336604762, 'epoch': 3.95}\n",
      "{'loss': 0.0193, 'learning_rate': 3.774655076809197e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 29.6847, 'train_samples_per_second': 476.104, 'train_steps_per_second': 59.66, 'train_loss': 0.04535925177565946, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:22:09,172] Trial 32 finished with value: 0.7728364389233955 and parameters: {'learning_rate': 0.00024667579856195893, 'weight_decay': 0.0008142509932181491, 'num_train_epochs': 7}. Best is trial 25 with value: 0.8595837419636047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07266197353601456, 'eval_accuracy': 0.9920634920634921, 'eval_recall': 0.7272727272727273, 'eval_precision': 0.8888888888888888, 'eval_f1': 0.7999999999999999, 'eval_runtime': 3.4998, 'eval_samples_per_second': 144.008, 'eval_steps_per_second': 18.001, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.654, 'learning_rate': 0.00012368467683240657, 'epoch': 1.98}\n",
      "{'loss': 0.3987, 'learning_rate': 8.310571461705008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.238, 'learning_rate': 4.2526752401693594e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1593, 'learning_rate': 1.947790186337111e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.9898, 'train_samples_per_second': 474.966, 'train_steps_per_second': 59.547, 'train_loss': 0.35834459632105037, 'epoch': 8.0}\n",
      "{'eval_loss': 0.18634122610092163, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5833333333333334, 'eval_f1': 0.5833333333333334, 'eval_runtime': 3.7368, 'eval_samples_per_second': 135.141, 'eval_steps_per_second': 17.127, 'epoch': 8.0}\n",
      "{'loss': 0.2667, 'learning_rate': 0.00012368467683240657, 'epoch': 1.98}\n",
      "{'loss': 0.1024, 'learning_rate': 8.310571461705008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0392, 'learning_rate': 4.2526752401693594e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0063, 'learning_rate': 1.947790186337111e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.2343, 'train_samples_per_second': 485.763, 'train_steps_per_second': 60.901, 'train_loss': 0.1024024827295837, 'epoch': 8.0}\n",
      "{'eval_loss': 0.16576167941093445, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.8126, 'eval_samples_per_second': 132.454, 'eval_steps_per_second': 16.786, 'epoch': 8.0}\n",
      "{'loss': 0.175, 'learning_rate': 0.00012368467683240657, 'epoch': 1.98}\n",
      "{'loss': 0.0672, 'learning_rate': 8.310571461705008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0086, 'learning_rate': 4.2526752401693594e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0021, 'learning_rate': 1.947790186337111e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.1826, 'train_samples_per_second': 472.287, 'train_steps_per_second': 59.211, 'train_loss': 0.06250302632942772, 'epoch': 8.0}\n",
      "{'eval_loss': 0.0004216424422338605, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 4.8873, 'eval_samples_per_second': 103.328, 'eval_steps_per_second': 13.095, 'epoch': 8.0}\n",
      "{'loss': 0.0785, 'learning_rate': 0.00012368467683240657, 'epoch': 1.98}\n",
      "{'loss': 0.0306, 'learning_rate': 8.310571461705008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0013, 'learning_rate': 4.2526752401693594e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 1.947790186337111e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 33.2567, 'train_samples_per_second': 485.677, 'train_steps_per_second': 60.86, 'train_loss': 0.027285915036577804, 'epoch': 8.0}\n",
      "{'eval_loss': 0.02395235188305378, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.0152, 'eval_samples_per_second': 125.523, 'eval_steps_per_second': 15.69, 'epoch': 8.0}\n",
      "{'loss': 0.02, 'learning_rate': 0.00012368467683240657, 'epoch': 1.98}\n",
      "{'loss': 0.029, 'learning_rate': 8.310571461705008e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0003, 'learning_rate': 4.2526752401693594e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 1.947790186337111e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 34.4826, 'train_samples_per_second': 468.41, 'train_steps_per_second': 58.696, 'train_loss': 0.012173378940958502, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:25:37,984] Trial 33 finished with value: 0.8317805383022774 and parameters: {'learning_rate': 0.00016426363904776305, 'weight_decay': 0.0012992515988882083, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.018556322902441025, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.3624, 'eval_samples_per_second': 149.892, 'eval_steps_per_second': 18.736, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6621, 'learning_rate': 0.00021980008925462195, 'epoch': 1.98}\n",
      "{'loss': 0.3696, 'learning_rate': 0.0001579542565999731, 'epoch': 3.95}\n",
      "{'loss': 0.1782, 'learning_rate': 9.610842394532429e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1457, 'learning_rate': 3.426259129067545e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.6295, 'train_samples_per_second': 458.295, 'train_steps_per_second': 57.457, 'train_loss': 0.3046903078316281, 'epoch': 9.0}\n",
      "{'eval_loss': 0.16943277418613434, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.6363636363636364, 'eval_f1': 0.6086956521739131, 'eval_runtime': 3.4321, 'eval_samples_per_second': 147.139, 'eval_steps_per_second': 18.647, 'epoch': 9.0}\n",
      "{'loss': 0.2509, 'learning_rate': 0.00021980008925462195, 'epoch': 1.98}\n",
      "{'loss': 0.1248, 'learning_rate': 0.0001579542565999731, 'epoch': 3.95}\n",
      "{'loss': 0.0724, 'learning_rate': 9.610842394532429e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0133, 'learning_rate': 3.426259129067545e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.5824, 'train_samples_per_second': 458.84, 'train_steps_per_second': 57.526, 'train_loss': 0.10249955653097213, 'epoch': 9.0}\n",
      "{'eval_loss': 0.17865198850631714, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 4.0227, 'eval_samples_per_second': 125.536, 'eval_steps_per_second': 15.91, 'epoch': 9.0}\n",
      "{'loss': 0.2085, 'learning_rate': 0.00021980008925462195, 'epoch': 1.98}\n",
      "{'loss': 0.0604, 'learning_rate': 0.0001579542565999731, 'epoch': 3.95}\n",
      "{'loss': 0.0114, 'learning_rate': 9.610842394532429e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0179, 'learning_rate': 3.426259129067545e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.1871, 'train_samples_per_second': 463.469, 'train_steps_per_second': 58.106, 'train_loss': 0.06598461302529839, 'epoch': 9.0}\n",
      "{'eval_loss': 0.11690743267536163, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.875, 'eval_f1': 0.7000000000000001, 'eval_runtime': 3.2569, 'eval_samples_per_second': 155.057, 'eval_steps_per_second': 19.651, 'epoch': 9.0}\n",
      "{'loss': 0.1332, 'learning_rate': 0.00021980008925462195, 'epoch': 1.98}\n",
      "{'loss': 0.0438, 'learning_rate': 0.0001579542565999731, 'epoch': 3.95}\n",
      "{'loss': 0.0212, 'learning_rate': 9.610842394532429e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0002, 'learning_rate': 3.426259129067545e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 34.8152, 'train_samples_per_second': 521.927, 'train_steps_per_second': 65.402, 'train_loss': 0.04357209376627592, 'epoch': 9.0}\n",
      "{'eval_loss': 0.021757803857326508, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.4987, 'eval_samples_per_second': 144.052, 'eval_steps_per_second': 18.007, 'epoch': 9.0}\n",
      "{'loss': 0.0927, 'learning_rate': 0.00021980008925462195, 'epoch': 1.98}\n",
      "{'loss': 0.0177, 'learning_rate': 0.0001579542565999731, 'epoch': 3.95}\n",
      "{'loss': 0.0152, 'learning_rate': 9.610842394532429e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0014, 'learning_rate': 3.426259129067545e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 39.8814, 'train_samples_per_second': 455.626, 'train_steps_per_second': 57.094, 'train_loss': 0.027880718278055244, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:29:39,000] Trial 34 finished with value: 0.7822300811316831 and parameters: {'learning_rate': 0.0002816459219092708, 'weight_decay': 0.00032983855007218067, 'num_train_epochs': 9}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0309719480574131, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.6587, 'eval_samples_per_second': 137.755, 'eval_steps_per_second': 17.219, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6553, 'learning_rate': 8.913374189854705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.4133, 'learning_rate': 5.4069327304311394e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2898, 'learning_rate': 1.900491271007573e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 33.0927, 'train_samples_per_second': 426.861, 'train_steps_per_second': 53.516, 'train_loss': 0.4157305393832878, 'epoch': 7.0}\n",
      "{'eval_loss': 0.16346041858196259, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.4166666666666667, 'eval_precision': 0.625, 'eval_f1': 0.5, 'eval_runtime': 3.4153, 'eval_samples_per_second': 147.864, 'eval_steps_per_second': 18.739, 'epoch': 7.0}\n",
      "{'loss': 0.3026, 'learning_rate': 8.913374189854705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1461, 'learning_rate': 5.4069327304311394e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0677, 'learning_rate': 1.900491271007573e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 34.9501, 'train_samples_per_second': 404.176, 'train_steps_per_second': 50.672, 'train_loss': 0.15895072488984033, 'epoch': 7.0}\n",
      "{'eval_loss': 0.16014181077480316, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.8862, 'eval_samples_per_second': 129.946, 'eval_steps_per_second': 16.468, 'epoch': 7.0}\n",
      "{'loss': 0.165, 'learning_rate': 8.913374189854705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0478, 'learning_rate': 5.4069327304311394e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0198, 'learning_rate': 1.900491271007573e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 20.262, 'train_samples_per_second': 697.166, 'train_steps_per_second': 87.405, 'train_loss': 0.0678844640377482, 'epoch': 7.0}\n",
      "{'eval_loss': 0.06640589237213135, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.75, 'eval_precision': 1.0, 'eval_f1': 0.8571428571428571, 'eval_runtime': 3.5212, 'eval_samples_per_second': 143.416, 'eval_steps_per_second': 18.175, 'epoch': 7.0}\n",
      "{'loss': 0.1182, 'learning_rate': 8.913374189854705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0382, 'learning_rate': 5.4069327304311394e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0024, 'learning_rate': 1.900491271007573e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 18.547, 'train_samples_per_second': 762.009, 'train_steps_per_second': 95.487, 'train_loss': 0.044865125736599246, 'epoch': 7.0}\n",
      "{'eval_loss': 0.026802022010087967, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 3.6459, 'eval_samples_per_second': 138.238, 'eval_steps_per_second': 17.28, 'epoch': 7.0}\n",
      "{'loss': 0.0054, 'learning_rate': 8.913374189854705e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0141, 'learning_rate': 5.4069327304311394e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0069, 'learning_rate': 1.900491271007573e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 19.9055, 'train_samples_per_second': 710.005, 'train_steps_per_second': 88.97, 'train_loss': 0.0074444321924973045, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:32:24,627] Trial 35 finished with value: 0.7708561685543783 and parameters: {'learning_rate': 0.00012419815649278271, 'weight_decay': 0.0017164896408033608, 'num_train_epochs': 7}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.021779343485832214, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.8777, 'eval_samples_per_second': 129.973, 'eval_steps_per_second': 16.247, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7904, 'learning_rate': 0.0006576205405891412, 'epoch': 1.98}\n",
      "{'loss': 0.7232, 'learning_rate': 0.0004418657700546461, 'epoch': 3.95}\n",
      "{'loss': 0.7349, 'learning_rate': 0.00022611099952015093, 'epoch': 5.93}\n",
      "{'loss': 0.7241, 'learning_rate': 1.0356228985655767e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 23.5988, 'train_samples_per_second': 684.104, 'train_steps_per_second': 85.767, 'train_loss': 0.7442510363612722, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16800475120544434, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.3232, 'eval_samples_per_second': 151.961, 'eval_steps_per_second': 19.258, 'epoch': 8.0}\n",
      "{'loss': 0.8264, 'learning_rate': 0.0006576205405891412, 'epoch': 1.98}\n",
      "{'loss': 0.7294, 'learning_rate': 0.0004418657700546461, 'epoch': 3.95}\n",
      "{'loss': 0.7358, 'learning_rate': 0.00022611099952015093, 'epoch': 5.93}\n",
      "{'loss': 0.7313, 'learning_rate': 1.0356228985655767e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 22.7389, 'train_samples_per_second': 709.972, 'train_steps_per_second': 89.01, 'train_loss': 0.7568902809158145, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16930928826332092, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.2986, 'eval_samples_per_second': 153.095, 'eval_steps_per_second': 19.402, 'epoch': 8.0}\n",
      "{'loss': 0.8117, 'learning_rate': 0.0006576205405891412, 'epoch': 1.98}\n",
      "{'loss': 0.7182, 'learning_rate': 0.0004418657700546461, 'epoch': 3.95}\n",
      "{'loss': 0.727, 'learning_rate': 0.00022611099952015093, 'epoch': 5.93}\n",
      "{'loss': 0.7305, 'learning_rate': 1.0356228985655767e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 22.966, 'train_samples_per_second': 702.952, 'train_steps_per_second': 88.13, 'train_loss': 0.7482260884974785, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16935397684574127, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.7454, 'eval_samples_per_second': 134.833, 'eval_steps_per_second': 17.088, 'epoch': 8.0}\n",
      "{'loss': 0.765, 'learning_rate': 0.0006576205405891412, 'epoch': 1.98}\n",
      "{'loss': 0.7724, 'learning_rate': 0.0004418657700546461, 'epoch': 3.95}\n",
      "{'loss': 0.7338, 'learning_rate': 0.00022611099952015093, 'epoch': 5.93}\n",
      "{'loss': 0.7821, 'learning_rate': 1.0356228985655767e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 21.1395, 'train_samples_per_second': 764.069, 'train_steps_per_second': 95.745, 'train_loss': 0.7608768379264198, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16414913535118103, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 3.6467, 'eval_samples_per_second': 138.205, 'eval_steps_per_second': 17.276, 'epoch': 8.0}\n",
      "{'loss': 0.6709, 'learning_rate': 0.0006576205405891412, 'epoch': 1.98}\n",
      "{'loss': 0.6056, 'learning_rate': 0.0004418657700546461, 'epoch': 3.95}\n",
      "{'loss': 0.6059, 'learning_rate': 0.00022611099952015093, 'epoch': 5.93}\n",
      "{'loss': 0.5936, 'learning_rate': 1.0356228985655767e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 23.3864, 'train_samples_per_second': 690.659, 'train_steps_per_second': 86.546, 'train_loss': 0.6184067434001818, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:34:58,252] Trial 36 finished with value: 0.03333333333333334 and parameters: {'learning_rate': 0.0008733753111236364, 'weight_decay': 0.0006168822269633476, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16063062846660614, 'eval_accuracy': 0.9801587301587301, 'eval_recall': 0.09090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.16666666666666669, 'eval_runtime': 3.9025, 'eval_samples_per_second': 129.15, 'eval_steps_per_second': 16.144, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6437, 'learning_rate': 0.00010797077615458393, 'epoch': 1.98}\n",
      "{'loss': 0.3952, 'learning_rate': 5.49399430727647e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2638, 'learning_rate': 1.9091099909454917e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 18.0403, 'train_samples_per_second': 671.165, 'train_steps_per_second': 84.145, 'train_loss': 0.4319742426413635, 'epoch': 6.0}\n",
      "{'eval_loss': 0.16215327382087708, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5, 'eval_precision': 0.6, 'eval_f1': 0.5454545454545454, 'eval_runtime': 3.9871, 'eval_samples_per_second': 126.657, 'eval_steps_per_second': 16.052, 'epoch': 6.0}\n",
      "{'loss': 0.3467, 'learning_rate': 0.00010797077615458393, 'epoch': 1.98}\n",
      "{'loss': 0.1427, 'learning_rate': 5.49399430727647e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0549, 'learning_rate': 1.9091099909454917e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 17.5557, 'train_samples_per_second': 689.692, 'train_steps_per_second': 86.468, 'train_loss': 0.18306794939305, 'epoch': 6.0}\n",
      "{'eval_loss': 0.16851793229579926, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.3911, 'eval_samples_per_second': 148.92, 'eval_steps_per_second': 18.873, 'epoch': 6.0}\n",
      "{'loss': 0.1674, 'learning_rate': 0.00010797077615458393, 'epoch': 1.98}\n",
      "{'loss': 0.0675, 'learning_rate': 5.49399430727647e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0087, 'learning_rate': 1.9091099909454917e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 16.75, 'train_samples_per_second': 722.866, 'train_steps_per_second': 90.627, 'train_loss': 0.08025497249885903, 'epoch': 6.0}\n",
      "{'eval_loss': 0.02341589517891407, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.8333333333333334, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.8695652173913043, 'eval_runtime': 3.6932, 'eval_samples_per_second': 136.736, 'eval_steps_per_second': 17.329, 'epoch': 6.0}\n",
      "{'loss': 0.1047, 'learning_rate': 0.00010797077615458393, 'epoch': 1.98}\n",
      "{'loss': 0.0205, 'learning_rate': 5.49399430727647e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0007, 'learning_rate': 1.9091099909454917e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 15.4979, 'train_samples_per_second': 781.654, 'train_steps_per_second': 97.949, 'train_loss': 0.041485903288621354, 'epoch': 6.0}\n",
      "{'eval_loss': 0.02703866921365261, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.3874, 'eval_samples_per_second': 114.875, 'eval_steps_per_second': 14.359, 'epoch': 6.0}\n",
      "{'loss': 0.0372, 'learning_rate': 0.00010797077615458393, 'epoch': 1.98}\n",
      "{'loss': 0.0403, 'learning_rate': 5.49399430727647e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0001, 'learning_rate': 1.9091099909454917e-06, 'epoch': 5.93}\n",
      "{'train_runtime': 18.0752, 'train_samples_per_second': 670.199, 'train_steps_per_second': 83.982, 'train_loss': 0.025569518087574575, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:37:03,939] Trial 37 finished with value: 0.7737735410369682 and parameters: {'learning_rate': 0.00016100160923640313, 'weight_decay': 0.0010141476938847955, 'num_train_epochs': 6}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03779217600822449, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.9865, 'eval_samples_per_second': 126.428, 'eval_steps_per_second': 15.803, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6559, 'learning_rate': 0.0001794441714881127, 'epoch': 1.98}\n",
      "{'loss': 0.3804, 'learning_rate': 0.0001088524439160778, 'epoch': 3.95}\n",
      "{'loss': 0.1852, 'learning_rate': 3.826071634404291e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 20.3711, 'train_samples_per_second': 693.432, 'train_steps_per_second': 86.937, 'train_loss': 0.36899274786201186, 'epoch': 7.0}\n",
      "{'eval_loss': 0.1881508082151413, 'eval_accuracy': 0.9782178217821782, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5384615384615384, 'eval_f1': 0.5599999999999999, 'eval_runtime': 4.0415, 'eval_samples_per_second': 124.954, 'eval_steps_per_second': 15.836, 'epoch': 7.0}\n",
      "{'loss': 0.3173, 'learning_rate': 0.0001794441714881127, 'epoch': 1.98}\n",
      "{'loss': 0.1151, 'learning_rate': 0.0001088524439160778, 'epoch': 3.95}\n",
      "{'loss': 0.0564, 'learning_rate': 3.826071634404291e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 19.7302, 'train_samples_per_second': 715.957, 'train_steps_per_second': 89.761, 'train_loss': 0.1385400003460691, 'epoch': 7.0}\n",
      "{'eval_loss': 0.17137880623340607, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 4.3801, 'eval_samples_per_second': 115.294, 'eval_steps_per_second': 14.612, 'epoch': 7.0}\n",
      "{'loss': 0.2032, 'learning_rate': 0.0001794441714881127, 'epoch': 1.98}\n",
      "{'loss': 0.0751, 'learning_rate': 0.0001088524439160778, 'epoch': 3.95}\n",
      "{'loss': 0.0301, 'learning_rate': 3.826071634404291e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 20.6923, 'train_samples_per_second': 682.67, 'train_steps_per_second': 85.587, 'train_loss': 0.087079581990207, 'epoch': 7.0}\n",
      "{'eval_loss': 0.01701604574918747, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.9166666666666666, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9166666666666666, 'eval_runtime': 3.7909, 'eval_samples_per_second': 133.213, 'eval_steps_per_second': 16.882, 'epoch': 7.0}\n",
      "{'loss': 0.1128, 'learning_rate': 0.0001794441714881127, 'epoch': 1.98}\n",
      "{'loss': 0.0648, 'learning_rate': 0.0001088524439160778, 'epoch': 3.95}\n",
      "{'loss': 0.0004, 'learning_rate': 3.826071634404291e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 19.3951, 'train_samples_per_second': 728.689, 'train_steps_per_second': 91.312, 'train_loss': 0.05026309650584862, 'epoch': 7.0}\n",
      "{'eval_loss': 0.018414532765746117, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.1454, 'eval_samples_per_second': 121.58, 'eval_steps_per_second': 15.197, 'epoch': 7.0}\n",
      "{'loss': 0.1295, 'learning_rate': 0.0001794441714881127, 'epoch': 1.98}\n",
      "{'loss': 0.0399, 'learning_rate': 0.0001088524439160778, 'epoch': 3.95}\n",
      "{'loss': 0.0036, 'learning_rate': 3.826071634404291e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 19.932, 'train_samples_per_second': 709.063, 'train_steps_per_second': 88.852, 'train_loss': 0.04882797271745276, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:39:25,671] Trial 38 finished with value: 0.8017891963109355 and parameters: {'learning_rate': 0.0002500358990601476, 'weight_decay': 0.00018119100191491065, 'num_train_epochs': 7}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02273561619222164, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.8096, 'eval_samples_per_second': 132.297, 'eval_steps_per_second': 16.537, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7507, 'learning_rate': 0.00043145629304222626, 'epoch': 1.98}\n",
      "{'loss': 0.5337, 'learning_rate': 0.0003100560980387861, 'epoch': 3.95}\n",
      "{'loss': 0.382, 'learning_rate': 0.00018865590303534597, 'epoch': 5.93}\n",
      "{'loss': 0.3027, 'learning_rate': 6.725570803190583e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 27.0906, 'train_samples_per_second': 670.418, 'train_steps_per_second': 84.051, 'train_loss': 0.4652224286481064, 'epoch': 9.0}\n",
      "{'eval_loss': 0.1426733434200287, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.875, 'eval_f1': 0.7000000000000001, 'eval_runtime': 3.8471, 'eval_samples_per_second': 131.269, 'eval_steps_per_second': 16.636, 'epoch': 9.0}\n",
      "{'loss': 0.4075, 'learning_rate': 0.00043145629304222626, 'epoch': 1.98}\n",
      "{'loss': 0.2508, 'learning_rate': 0.0003100560980387861, 'epoch': 3.95}\n",
      "{'loss': 0.2175, 'learning_rate': 0.00018865590303534597, 'epoch': 5.93}\n",
      "{'loss': 0.2357, 'learning_rate': 6.725570803190583e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 26.5824, 'train_samples_per_second': 683.233, 'train_steps_per_second': 85.658, 'train_loss': 0.26173723209935634, 'epoch': 9.0}\n",
      "{'eval_loss': 0.1590849608182907, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 4.1097, 'eval_samples_per_second': 122.879, 'eval_steps_per_second': 15.573, 'epoch': 9.0}\n",
      "{'loss': 0.4076, 'learning_rate': 0.00043145629304222626, 'epoch': 1.98}\n",
      "{'loss': 0.3151, 'learning_rate': 0.0003100560980387861, 'epoch': 3.95}\n",
      "{'loss': 0.2442, 'learning_rate': 0.00018865590303534597, 'epoch': 5.93}\n",
      "{'loss': 0.2376, 'learning_rate': 6.725570803190583e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 26.237, 'train_samples_per_second': 692.228, 'train_steps_per_second': 86.786, 'train_loss': 0.2897039404237904, 'epoch': 9.0}\n",
      "{'eval_loss': 0.058564092963933945, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.75, 'eval_precision': 1.0, 'eval_f1': 0.8571428571428571, 'eval_runtime': 4.4223, 'eval_samples_per_second': 114.194, 'eval_steps_per_second': 14.472, 'epoch': 9.0}\n",
      "{'loss': 0.4482, 'learning_rate': 0.00043145629304222626, 'epoch': 1.98}\n",
      "{'loss': 0.3197, 'learning_rate': 0.0003100560980387861, 'epoch': 3.95}\n",
      "{'loss': 0.2119, 'learning_rate': 0.00018865590303534597, 'epoch': 5.93}\n",
      "{'loss': 0.1805, 'learning_rate': 6.725570803190583e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 23.6777, 'train_samples_per_second': 767.431, 'train_steps_per_second': 96.166, 'train_loss': 0.27136523984323535, 'epoch': 9.0}\n",
      "{'eval_loss': 0.08757384121417999, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 3.5839, 'eval_samples_per_second': 140.628, 'eval_steps_per_second': 17.578, 'epoch': 9.0}\n",
      "{'loss': 0.3566, 'learning_rate': 0.00043145629304222626, 'epoch': 1.98}\n",
      "{'loss': 0.3295, 'learning_rate': 0.0003100560980387861, 'epoch': 3.95}\n",
      "{'loss': 0.219, 'learning_rate': 0.00018865590303534597, 'epoch': 5.93}\n",
      "{'loss': 0.1819, 'learning_rate': 6.725570803190583e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 26.4096, 'train_samples_per_second': 688.045, 'train_steps_per_second': 86.219, 'train_loss': 0.25800932631662243, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:42:17,711] Trial 39 finished with value: 0.7416806722689075 and parameters: {'learning_rate': 0.0005528564880456664, 'weight_decay': 0.001615137776926221, 'num_train_epochs': 9}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07914615422487259, 'eval_accuracy': 0.9900793650793651, 'eval_recall': 0.5454545454545454, 'eval_precision': 1.0, 'eval_f1': 0.7058823529411764, 'eval_runtime': 4.3218, 'eval_samples_per_second': 116.619, 'eval_steps_per_second': 14.577, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6434, 'learning_rate': 0.0001351046785749484, 'epoch': 1.98}\n",
      "{'loss': 0.3782, 'learning_rate': 9.077899662778684e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2153, 'learning_rate': 4.6453314680625305e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1542, 'learning_rate': 2.127632733463754e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.6979, 'train_samples_per_second': 681.242, 'train_steps_per_second': 85.408, 'train_loss': 0.3446599411163406, 'epoch': 8.0}\n",
      "{'eval_loss': 0.1940620094537735, 'eval_accuracy': 0.9801980198019802, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5833333333333334, 'eval_f1': 0.5833333333333334, 'eval_runtime': 3.5514, 'eval_samples_per_second': 142.196, 'eval_steps_per_second': 18.021, 'epoch': 8.0}\n",
      "{'loss': 0.2732, 'learning_rate': 0.0001351046785749484, 'epoch': 1.98}\n",
      "{'loss': 0.0944, 'learning_rate': 9.077899662778684e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0376, 'learning_rate': 4.6453314680625305e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0084, 'learning_rate': 2.127632733463754e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.9309, 'train_samples_per_second': 704.028, 'train_steps_per_second': 88.265, 'train_loss': 0.10217945736127983, 'epoch': 8.0}\n",
      "{'eval_loss': 0.16990135610103607, 'eval_accuracy': 0.9900990099009901, 'eval_recall': 0.5833333333333334, 'eval_precision': 1.0, 'eval_f1': 0.7368421052631579, 'eval_runtime': 4.4151, 'eval_samples_per_second': 114.381, 'eval_steps_per_second': 14.496, 'epoch': 8.0}\n",
      "{'loss': 0.1544, 'learning_rate': 0.0001351046785749484, 'epoch': 1.98}\n",
      "{'loss': 0.0524, 'learning_rate': 9.077899662778684e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0078, 'learning_rate': 4.6453314680625305e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0011, 'learning_rate': 2.127632733463754e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.5184, 'train_samples_per_second': 686.441, 'train_steps_per_second': 86.06, 'train_loss': 0.05327114556870504, 'epoch': 8.0}\n",
      "{'eval_loss': 0.002989380154758692, 'eval_accuracy': 0.998019801980198, 'eval_recall': 0.9166666666666666, 'eval_precision': 1.0, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.4594, 'eval_samples_per_second': 113.245, 'eval_steps_per_second': 14.352, 'epoch': 8.0}\n",
      "{'loss': 0.1246, 'learning_rate': 0.0001351046785749484, 'epoch': 1.98}\n",
      "{'loss': 0.047, 'learning_rate': 9.077899662778684e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0002, 'learning_rate': 4.6453314680625305e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.127632733463754e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 20.8681, 'train_samples_per_second': 774.005, 'train_steps_per_second': 96.99, 'train_loss': 0.04245926024934752, 'epoch': 8.0}\n",
      "{'eval_loss': 0.016591187566518784, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 6.1375, 'eval_samples_per_second': 82.119, 'eval_steps_per_second': 10.265, 'epoch': 8.0}\n",
      "{'loss': 0.0376, 'learning_rate': 0.0001351046785749484, 'epoch': 1.98}\n",
      "{'loss': 0.0103, 'learning_rate': 9.077899662778684e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0, 'learning_rate': 4.6453314680625305e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.127632733463754e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 24.0411, 'train_samples_per_second': 671.848, 'train_steps_per_second': 84.189, 'train_loss': 0.011835344879004915, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:44:57,770] Trial 40 finished with value: 0.8276338078397576 and parameters: {'learning_rate': 0.00017943036052210995, 'weight_decay': 0.0006964673934965837, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.011053582653403282, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 4.0497, 'eval_samples_per_second': 124.454, 'eval_steps_per_second': 15.557, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6667, 'learning_rate': 0.000273985602873132, 'epoch': 1.98}\n",
      "{'loss': 0.3631, 'learning_rate': 0.0001840953132165926, 'epoch': 3.95}\n",
      "{'loss': 0.1698, 'learning_rate': 9.420502356005325e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1404, 'learning_rate': 4.314733903513889e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.1201, 'train_samples_per_second': 698.267, 'train_steps_per_second': 87.543, 'train_loss': 0.3310684978597514, 'epoch': 8.0}\n",
      "{'eval_loss': 0.1348343789577484, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.6666666666666666, 'eval_precision': 0.6153846153846154, 'eval_f1': 0.64, 'eval_runtime': 4.6235, 'eval_samples_per_second': 109.225, 'eval_steps_per_second': 13.842, 'epoch': 8.0}\n",
      "{'loss': 0.3274, 'learning_rate': 0.000273985602873132, 'epoch': 1.98}\n",
      "{'loss': 0.1753, 'learning_rate': 0.0001840953132165926, 'epoch': 3.95}\n",
      "{'loss': 0.0655, 'learning_rate': 9.420502356005325e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0347, 'learning_rate': 4.314733903513889e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.566, 'train_samples_per_second': 685.055, 'train_steps_per_second': 85.886, 'train_loss': 0.1489201920344439, 'epoch': 8.0}\n",
      "{'eval_loss': 0.13271553814411163, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 4.0478, 'eval_samples_per_second': 124.76, 'eval_steps_per_second': 15.811, 'epoch': 8.0}\n",
      "{'loss': 0.2055, 'learning_rate': 0.000273985602873132, 'epoch': 1.98}\n",
      "{'loss': 0.1244, 'learning_rate': 0.0001840953132165926, 'epoch': 3.95}\n",
      "{'loss': 0.0212, 'learning_rate': 9.420502356005325e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0041, 'learning_rate': 4.314733903513889e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.9973, 'train_samples_per_second': 701.996, 'train_steps_per_second': 88.01, 'train_loss': 0.08827479701975117, 'epoch': 8.0}\n",
      "{'eval_loss': 0.030238673090934753, 'eval_accuracy': 0.994059405940594, 'eval_recall': 1.0, 'eval_precision': 0.8, 'eval_f1': 0.888888888888889, 'eval_runtime': 4.3827, 'eval_samples_per_second': 115.227, 'eval_steps_per_second': 14.603, 'epoch': 8.0}\n",
      "{'loss': 0.1089, 'learning_rate': 0.000273985602873132, 'epoch': 1.98}\n",
      "{'loss': 0.0221, 'learning_rate': 0.0001840953132165926, 'epoch': 3.95}\n",
      "{'loss': 0.0226, 'learning_rate': 9.420502356005325e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0095, 'learning_rate': 4.314733903513889e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 21.666, 'train_samples_per_second': 745.5, 'train_steps_per_second': 93.418, 'train_loss': 0.04027593097274041, 'epoch': 8.0}\n",
      "{'eval_loss': 0.02191917970776558, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.5156, 'eval_samples_per_second': 111.614, 'eval_steps_per_second': 13.952, 'epoch': 8.0}\n",
      "{'loss': 0.1131, 'learning_rate': 0.000273985602873132, 'epoch': 1.98}\n",
      "{'loss': 0.0514, 'learning_rate': 0.0001840953132165926, 'epoch': 3.95}\n",
      "{'loss': 0.0001, 'learning_rate': 9.420502356005325e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0014, 'learning_rate': 4.314733903513889e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.1182, 'train_samples_per_second': 698.671, 'train_steps_per_second': 87.55, 'train_loss': 0.04099773109473864, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:47:37,741] Trial 41 finished with value: 0.8208916494133887 and parameters: {'learning_rate': 0.0003638758925296713, 'weight_decay': 0.0008530734766577331, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01551055908203125, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 5.1246, 'eval_samples_per_second': 98.349, 'eval_steps_per_second': 12.294, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6566, 'learning_rate': 0.0002671312678039836, 'epoch': 1.98}\n",
      "{'loss': 0.3588, 'learning_rate': 0.0001794897757423092, 'epoch': 3.95}\n",
      "{'loss': 0.1819, 'learning_rate': 9.184828368063479e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1518, 'learning_rate': 4.206791618960372e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.7802, 'train_samples_per_second': 708.685, 'train_steps_per_second': 88.849, 'train_loss': 0.3333811446170326, 'epoch': 8.0}\n",
      "{'eval_loss': 0.18987822532653809, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5, 'eval_precision': 0.6666666666666666, 'eval_f1': 0.5714285714285715, 'eval_runtime': 4.8143, 'eval_samples_per_second': 104.896, 'eval_steps_per_second': 13.294, 'epoch': 8.0}\n",
      "{'loss': 0.3123, 'learning_rate': 0.0002671312678039836, 'epoch': 1.98}\n",
      "{'loss': 0.1551, 'learning_rate': 0.0001794897757423092, 'epoch': 3.95}\n",
      "{'loss': 0.0709, 'learning_rate': 9.184828368063479e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0673, 'learning_rate': 4.206791618960372e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.5962, 'train_samples_per_second': 714.455, 'train_steps_per_second': 89.572, 'train_loss': 0.14961924996772752, 'epoch': 8.0}\n",
      "{'eval_loss': 0.14221204817295074, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 4.4373, 'eval_samples_per_second': 113.808, 'eval_steps_per_second': 14.423, 'epoch': 8.0}\n",
      "{'loss': 0.1817, 'learning_rate': 0.0002671312678039836, 'epoch': 1.98}\n",
      "{'loss': 0.0909, 'learning_rate': 0.0001794897757423092, 'epoch': 3.95}\n",
      "{'loss': 0.0101, 'learning_rate': 9.184828368063479e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0001, 'learning_rate': 4.206791618960372e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.55, 'train_samples_per_second': 715.92, 'train_steps_per_second': 89.756, 'train_loss': 0.06983697012414476, 'epoch': 8.0}\n",
      "{'eval_loss': 0.07629992812871933, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.8333333333333334, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.8695652173913043, 'eval_runtime': 4.3566, 'eval_samples_per_second': 115.916, 'eval_steps_per_second': 14.69, 'epoch': 8.0}\n",
      "{'loss': 0.1475, 'learning_rate': 0.0002671312678039836, 'epoch': 1.98}\n",
      "{'loss': 0.0528, 'learning_rate': 0.0001794897757423092, 'epoch': 3.95}\n",
      "{'loss': 0.0005, 'learning_rate': 9.184828368063479e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0152, 'learning_rate': 4.206791618960372e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 21.2118, 'train_samples_per_second': 761.463, 'train_steps_per_second': 95.419, 'train_loss': 0.05337702762393056, 'epoch': 8.0}\n",
      "{'eval_loss': 2.2522710423800163e-05, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 4.361, 'eval_samples_per_second': 115.569, 'eval_steps_per_second': 14.446, 'epoch': 8.0}\n",
      "{'loss': 0.0823, 'learning_rate': 0.0002671312678039836, 'epoch': 1.98}\n",
      "{'loss': 0.0606, 'learning_rate': 0.0001794897757423092, 'epoch': 3.95}\n",
      "{'loss': 0.0, 'learning_rate': 9.184828368063479e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0079, 'learning_rate': 4.206791618960372e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.7089, 'train_samples_per_second': 681.263, 'train_steps_per_second': 85.369, 'train_loss': 0.037277457708811926, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:50:16,589] Trial 42 finished with value: 0.7929606625258799 and parameters: {'learning_rate': 0.000354772759865658, 'weight_decay': 0.0018218114251380656, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05907484143972397, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 3.7357, 'eval_samples_per_second': 134.915, 'eval_steps_per_second': 16.864, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6578, 'learning_rate': 0.0001746433949891143, 'epoch': 1.98}\n",
      "{'loss': 0.3704, 'learning_rate': 0.00011734569322103218, 'epoch': 3.95}\n",
      "{'loss': 0.2098, 'learning_rate': 6.004799145295006e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1454, 'learning_rate': 2.7502896848679415e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.7192, 'train_samples_per_second': 710.588, 'train_steps_per_second': 89.088, 'train_loss': 0.3417705035328556, 'epoch': 8.0}\n",
      "{'eval_loss': 0.17944274842739105, 'eval_accuracy': 0.9841584158415841, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.7, 'eval_f1': 0.6363636363636365, 'eval_runtime': 4.2721, 'eval_samples_per_second': 118.208, 'eval_steps_per_second': 14.981, 'epoch': 8.0}\n",
      "{'loss': 0.2739, 'learning_rate': 0.0001746433949891143, 'epoch': 1.98}\n",
      "{'loss': 0.0996, 'learning_rate': 0.00011734569322103218, 'epoch': 3.95}\n",
      "{'loss': 0.0584, 'learning_rate': 6.004799145295006e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0039, 'learning_rate': 2.7502896848679415e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 24.9395, 'train_samples_per_second': 647.328, 'train_steps_per_second': 81.157, 'train_loss': 0.10764092400676609, 'epoch': 8.0}\n",
      "{'eval_loss': 0.1704009771347046, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 4.254, 'eval_samples_per_second': 118.713, 'eval_steps_per_second': 15.045, 'epoch': 8.0}\n",
      "{'loss': 0.1662, 'learning_rate': 0.0001746433949891143, 'epoch': 1.98}\n",
      "{'loss': 0.0592, 'learning_rate': 0.00011734569322103218, 'epoch': 3.95}\n",
      "{'loss': 0.008, 'learning_rate': 6.004799145295006e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0021, 'learning_rate': 2.7502896848679415e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.6723, 'train_samples_per_second': 712.058, 'train_steps_per_second': 89.272, 'train_loss': 0.05819569996709056, 'epoch': 8.0}\n",
      "{'eval_loss': 0.021043434739112854, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.8333333333333334, 'eval_precision': 1.0, 'eval_f1': 0.9090909090909091, 'eval_runtime': 4.1469, 'eval_samples_per_second': 121.777, 'eval_steps_per_second': 15.433, 'epoch': 8.0}\n",
      "{'loss': 0.133, 'learning_rate': 0.0001746433949891143, 'epoch': 1.98}\n",
      "{'loss': 0.0322, 'learning_rate': 0.00011734569322103218, 'epoch': 3.95}\n",
      "{'loss': 0.0082, 'learning_rate': 6.004799145295006e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.7502896848679415e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 21.2986, 'train_samples_per_second': 758.358, 'train_steps_per_second': 95.03, 'train_loss': 0.0428532936890449, 'epoch': 8.0}\n",
      "{'eval_loss': 0.02168019860982895, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.3542, 'eval_samples_per_second': 115.75, 'eval_steps_per_second': 14.469, 'epoch': 8.0}\n",
      "{'loss': 0.0758, 'learning_rate': 0.0001746433949891143, 'epoch': 1.98}\n",
      "{'loss': 0.0269, 'learning_rate': 0.00011734569322103218, 'epoch': 3.95}\n",
      "{'loss': 0.0002, 'learning_rate': 6.004799145295006e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0052, 'learning_rate': 2.7502896848679415e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.3472, 'train_samples_per_second': 691.819, 'train_steps_per_second': 86.692, 'train_loss': 0.026704014012498712, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:52:55,262] Trial 43 finished with value: 0.8155467720685113 and parameters: {'learning_rate': 0.00023194109675719643, 'weight_decay': 0.001238904463365714, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04418201372027397, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 3.9265, 'eval_samples_per_second': 128.358, 'eval_steps_per_second': 16.045, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7724, 'learning_rate': 0.0005844352227502615, 'epoch': 1.98}\n",
      "{'loss': 0.7117, 'learning_rate': 0.0004199908719482745, 'epoch': 3.95}\n",
      "{'loss': 0.7238, 'learning_rate': 0.00025554652114628763, 'epoch': 5.93}\n",
      "{'loss': 0.7138, 'learning_rate': 9.110217034430074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 25.8832, 'train_samples_per_second': 701.69, 'train_steps_per_second': 87.972, 'train_loss': 0.7289663255345575, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1697949469089508, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 5.327, 'eval_samples_per_second': 94.801, 'eval_steps_per_second': 12.014, 'epoch': 9.0}\n",
      "{'loss': 0.8059, 'learning_rate': 0.0005844352227502615, 'epoch': 1.98}\n",
      "{'loss': 0.707, 'learning_rate': 0.0004199908719482745, 'epoch': 3.95}\n",
      "{'loss': 0.7157, 'learning_rate': 0.00025554652114628763, 'epoch': 5.93}\n",
      "{'loss': 0.7045, 'learning_rate': 9.110217034430074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 25.0789, 'train_samples_per_second': 724.195, 'train_steps_per_second': 90.793, 'train_loss': 0.7305437640029713, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1679583340883255, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 5.059, 'eval_samples_per_second': 99.822, 'eval_steps_per_second': 12.651, 'epoch': 9.0}\n",
      "{'loss': 0.7846, 'learning_rate': 0.0005844352227502615, 'epoch': 1.98}\n",
      "{'loss': 0.624, 'learning_rate': 0.0004199908719482745, 'epoch': 3.95}\n",
      "{'loss': 0.6723, 'learning_rate': 0.00025554652114628763, 'epoch': 5.93}\n",
      "{'loss': 0.6522, 'learning_rate': 9.110217034430074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 25.5652, 'train_samples_per_second': 710.418, 'train_steps_per_second': 89.066, 'train_loss': 0.6817908071351251, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14753016829490662, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 6.0741, 'eval_samples_per_second': 83.14, 'eval_steps_per_second': 10.537, 'epoch': 9.0}\n",
      "{'loss': 0.6774, 'learning_rate': 0.0005844352227502615, 'epoch': 1.98}\n",
      "{'loss': 0.6769, 'learning_rate': 0.0004199908719482745, 'epoch': 3.95}\n",
      "{'loss': 0.6281, 'learning_rate': 0.00025554652114628763, 'epoch': 5.93}\n",
      "{'loss': 0.6565, 'learning_rate': 9.110217034430074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 23.7996, 'train_samples_per_second': 763.501, 'train_steps_per_second': 95.674, 'train_loss': 0.6569112879066652, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/losullivan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1631297767162323, 'eval_accuracy': 0.9781746031746031, 'eval_recall': 0.0, 'eval_precision': 0.0, 'eval_f1': 0.0, 'eval_runtime': 5.4869, 'eval_samples_per_second': 91.854, 'eval_steps_per_second': 11.482, 'epoch': 9.0}\n",
      "{'loss': 0.7094, 'learning_rate': 0.0005844352227502615, 'epoch': 1.98}\n",
      "{'loss': 0.7407, 'learning_rate': 0.0004199908719482745, 'epoch': 3.95}\n",
      "{'loss': 0.5887, 'learning_rate': 0.00025554652114628763, 'epoch': 5.93}\n",
      "{'loss': 0.5424, 'learning_rate': 9.110217034430074e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 25.6771, 'train_samples_per_second': 707.674, 'train_steps_per_second': 88.678, 'train_loss': 0.6240788234866498, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:55:52,577] Trial 44 finished with value: 0.07499999999999998 and parameters: {'learning_rate': 0.0007488795735522484, 'weight_decay': 0.0005162876944908032, 'num_train_epochs': 9}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16141773760318756, 'eval_accuracy': 0.9801587301587301, 'eval_recall': 0.2727272727272727, 'eval_precision': 0.6, 'eval_f1': 0.37499999999999994, 'eval_runtime': 4.0934, 'eval_samples_per_second': 123.126, 'eval_steps_per_second': 15.391, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6527, 'learning_rate': 0.00023531555048772777, 'epoch': 1.98}\n",
      "{'loss': 0.3487, 'learning_rate': 0.00014274452354526995, 'epoch': 3.95}\n",
      "{'loss': 0.1716, 'learning_rate': 5.017349660281214e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 19.8931, 'train_samples_per_second': 710.097, 'train_steps_per_second': 89.026, 'train_loss': 0.3480902337408685, 'epoch': 7.0}\n",
      "{'eval_loss': 0.17862221598625183, 'eval_accuracy': 0.9782178217821782, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5384615384615384, 'eval_f1': 0.5599999999999999, 'eval_runtime': 4.8565, 'eval_samples_per_second': 103.984, 'eval_steps_per_second': 13.178, 'epoch': 7.0}\n",
      "{'loss': 0.3004, 'learning_rate': 0.00023531555048772777, 'epoch': 1.98}\n",
      "{'loss': 0.1331, 'learning_rate': 0.00014274452354526995, 'epoch': 3.95}\n",
      "{'loss': 0.0375, 'learning_rate': 5.017349660281214e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 19.4186, 'train_samples_per_second': 727.448, 'train_steps_per_second': 91.201, 'train_loss': 0.13694702683701346, 'epoch': 7.0}\n",
      "{'eval_loss': 0.1854940503835678, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 4.9693, 'eval_samples_per_second': 101.624, 'eval_steps_per_second': 12.879, 'epoch': 7.0}\n",
      "{'loss': 0.1913, 'learning_rate': 0.00023531555048772777, 'epoch': 1.98}\n",
      "{'loss': 0.0503, 'learning_rate': 0.00014274452354526995, 'epoch': 3.95}\n",
      "{'loss': 0.0156, 'learning_rate': 5.017349660281214e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 20.4794, 'train_samples_per_second': 689.766, 'train_steps_per_second': 86.477, 'train_loss': 0.0732042604351636, 'epoch': 7.0}\n",
      "{'eval_loss': 0.08248172700405121, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.8333333333333334, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.8695652173913043, 'eval_runtime': 4.7132, 'eval_samples_per_second': 107.145, 'eval_steps_per_second': 13.579, 'epoch': 7.0}\n",
      "{'loss': 0.1493, 'learning_rate': 0.00023531555048772777, 'epoch': 1.98}\n",
      "{'loss': 0.0889, 'learning_rate': 0.00014274452354526995, 'epoch': 3.95}\n",
      "{'loss': 0.0009, 'learning_rate': 5.017349660281214e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 18.2305, 'train_samples_per_second': 775.239, 'train_steps_per_second': 97.145, 'train_loss': 0.06902549527312052, 'epoch': 7.0}\n",
      "{'eval_loss': 0.04013532027602196, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 4.6975, 'eval_samples_per_second': 107.292, 'eval_steps_per_second': 13.411, 'epoch': 7.0}\n",
      "{'loss': 0.1024, 'learning_rate': 0.00023531555048772777, 'epoch': 1.98}\n",
      "{'loss': 0.0616, 'learning_rate': 0.00014274452354526995, 'epoch': 3.95}\n",
      "{'loss': 0.0014, 'learning_rate': 5.017349660281214e-05, 'epoch': 5.93}\n",
      "{'train_runtime': 20.5755, 'train_samples_per_second': 686.886, 'train_steps_per_second': 86.073, 'train_loss': 0.046726390319749636, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 15:58:20,450] Trial 45 finished with value: 0.7653782841199721 and parameters: {'learning_rate': 0.0003278865774301856, 'weight_decay': 0.0009460358719496141, 'num_train_epochs': 7}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05878017842769623, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.8181818181818182, 'eval_precision': 1.0, 'eval_f1': 0.9, 'eval_runtime': 4.301, 'eval_samples_per_second': 117.183, 'eval_steps_per_second': 14.648, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6497, 'learning_rate': 0.00015883755617365522, 'epoch': 1.98}\n",
      "{'loss': 0.372, 'learning_rate': 0.00010672549706156361, 'epoch': 3.95}\n",
      "{'loss': 0.2053, 'learning_rate': 5.461343794947201e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1237, 'learning_rate': 2.501378837380397e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.4246, 'train_samples_per_second': 719.923, 'train_steps_per_second': 90.258, 'train_loss': 0.33377230642253, 'epoch': 8.0}\n",
      "{'eval_loss': 0.18276353180408478, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.6363636363636364, 'eval_f1': 0.6086956521739131, 'eval_runtime': 3.7937, 'eval_samples_per_second': 133.115, 'eval_steps_per_second': 16.87, 'epoch': 8.0}\n",
      "{'loss': 0.2141, 'learning_rate': 0.00015883755617365522, 'epoch': 1.98}\n",
      "{'loss': 0.0825, 'learning_rate': 0.00010672549706156361, 'epoch': 3.95}\n",
      "{'loss': 0.0229, 'learning_rate': 5.461343794947201e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0065, 'learning_rate': 2.501378837380397e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 24.7602, 'train_samples_per_second': 652.013, 'train_steps_per_second': 81.744, 'train_loss': 0.08055806434595969, 'epoch': 8.0}\n",
      "{'eval_loss': 0.21172234416007996, 'eval_accuracy': 0.9861386138613861, 'eval_recall': 0.4166666666666667, 'eval_precision': 1.0, 'eval_f1': 0.5882352941176471, 'eval_runtime': 3.8625, 'eval_samples_per_second': 130.743, 'eval_steps_per_second': 16.569, 'epoch': 8.0}\n",
      "{'loss': 0.1833, 'learning_rate': 0.00015883755617365522, 'epoch': 1.98}\n",
      "{'loss': 0.0739, 'learning_rate': 0.00010672549706156361, 'epoch': 3.95}\n",
      "{'loss': 0.0093, 'learning_rate': 5.461343794947201e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.501378837380397e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.3868, 'train_samples_per_second': 690.304, 'train_steps_per_second': 86.545, 'train_loss': 0.06587481023854182, 'epoch': 8.0}\n",
      "{'eval_loss': 0.023319333791732788, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.9166666666666666, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9166666666666666, 'eval_runtime': 4.7139, 'eval_samples_per_second': 107.131, 'eval_steps_per_second': 13.577, 'epoch': 8.0}\n",
      "{'loss': 0.0873, 'learning_rate': 0.00015883755617365522, 'epoch': 1.98}\n",
      "{'loss': 0.0089, 'learning_rate': 0.00010672549706156361, 'epoch': 3.95}\n",
      "{'loss': 0.0004, 'learning_rate': 5.461343794947201e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.501378837380397e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 20.9322, 'train_samples_per_second': 771.636, 'train_steps_per_second': 96.693, 'train_loss': 0.0238690605964308, 'epoch': 8.0}\n",
      "{'eval_loss': 0.023545484989881516, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.8529, 'eval_samples_per_second': 103.856, 'eval_steps_per_second': 12.982, 'epoch': 8.0}\n",
      "{'loss': 0.0892, 'learning_rate': 0.00015883755617365522, 'epoch': 1.98}\n",
      "{'loss': 0.0394, 'learning_rate': 0.00010672549706156361, 'epoch': 3.95}\n",
      "{'loss': 0.0, 'learning_rate': 5.461343794947201e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 2.501378837380397e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.3974, 'train_samples_per_second': 721.155, 'train_steps_per_second': 90.368, 'train_loss': 0.03177137871190411, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 16:00:59,213] Trial 46 finished with value: 0.7958420522359141 and parameters: {'learning_rate': 0.00021094961528574685, 'weight_decay': 0.003347546354257197, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.025308843702077866, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.9090909090909091, 'eval_precision': 0.9090909090909091, 'eval_f1': 0.9090909090909091, 'eval_runtime': 4.7432, 'eval_samples_per_second': 106.257, 'eval_steps_per_second': 13.282, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6637, 'learning_rate': 8.444436523190577e-05, 'epoch': 1.98}\n",
      "{'loss': 0.4371, 'learning_rate': 6.068399234729525e-05, 'epoch': 3.95}\n",
      "{'loss': 0.3173, 'learning_rate': 3.692361946268474e-05, 'epoch': 5.93}\n",
      "{'loss': 0.2352, 'learning_rate': 1.3163246578074225e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 25.9968, 'train_samples_per_second': 698.623, 'train_steps_per_second': 87.588, 'train_loss': 0.3897846541909413, 'epoch': 9.0}\n",
      "{'eval_loss': 0.17921951413154602, 'eval_accuracy': 0.9762376237623762, 'eval_recall': 0.4166666666666667, 'eval_precision': 0.5, 'eval_f1': 0.45454545454545453, 'eval_runtime': 4.4407, 'eval_samples_per_second': 113.72, 'eval_steps_per_second': 14.412, 'epoch': 9.0}\n",
      "{'loss': 0.2769, 'learning_rate': 8.444436523190577e-05, 'epoch': 1.98}\n",
      "{'loss': 0.1384, 'learning_rate': 6.068399234729525e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0646, 'learning_rate': 3.692361946268474e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0543, 'learning_rate': 1.3163246578074225e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 26.7752, 'train_samples_per_second': 678.314, 'train_steps_per_second': 85.041, 'train_loss': 0.12393296283224355, 'epoch': 9.0}\n",
      "{'eval_loss': 0.14273595809936523, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.9966, 'eval_samples_per_second': 126.356, 'eval_steps_per_second': 16.013, 'epoch': 9.0}\n",
      "{'loss': 0.1929, 'learning_rate': 8.444436523190577e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0756, 'learning_rate': 6.068399234729525e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0558, 'learning_rate': 3.692361946268474e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0128, 'learning_rate': 1.3163246578074225e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 25.9775, 'train_samples_per_second': 699.143, 'train_steps_per_second': 87.653, 'train_loss': 0.07791052002837692, 'epoch': 9.0}\n",
      "{'eval_loss': 0.03629494830965996, 'eval_accuracy': 0.996039603960396, 'eval_recall': 0.9166666666666666, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9166666666666666, 'eval_runtime': 4.9083, 'eval_samples_per_second': 102.887, 'eval_steps_per_second': 13.039, 'epoch': 9.0}\n",
      "{'loss': 0.0793, 'learning_rate': 8.444436523190577e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0839, 'learning_rate': 6.068399234729525e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0006, 'learning_rate': 3.692361946268474e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0004, 'learning_rate': 1.3163246578074225e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 26.8691, 'train_samples_per_second': 676.28, 'train_steps_per_second': 84.744, 'train_loss': 0.0360566780340666, 'epoch': 9.0}\n",
      "{'eval_loss': 0.027311716228723526, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.4465, 'eval_samples_per_second': 113.349, 'eval_steps_per_second': 14.169, 'epoch': 9.0}\n",
      "{'loss': 0.0288, 'learning_rate': 8.444436523190577e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0626, 'learning_rate': 6.068399234729525e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0001, 'learning_rate': 3.692361946268474e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0001, 'learning_rate': 1.3163246578074225e-05, 'epoch': 7.91}\n",
      "{'train_runtime': 25.8336, 'train_samples_per_second': 703.388, 'train_steps_per_second': 88.141, 'train_loss': 0.020106801053386004, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 16:03:57,252] Trial 47 finished with value: 0.7788801054018445 and parameters: {'learning_rate': 0.00010820473811651628, 'weight_decay': 0.0020261556456688135, 'num_train_epochs': 9}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03805989399552345, 'eval_accuracy': 0.996031746031746, 'eval_recall': 0.8181818181818182, 'eval_precision': 1.0, 'eval_f1': 0.9, 'eval_runtime': 4.4244, 'eval_samples_per_second': 113.913, 'eval_steps_per_second': 14.239, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6389, 'learning_rate': 0.00011317512238414081, 'epoch': 1.98}\n",
      "{'loss': 0.3908, 'learning_rate': 7.604417672005262e-05, 'epoch': 3.95}\n",
      "{'loss': 0.2418, 'learning_rate': 3.8913231055964426e-05, 'epoch': 5.93}\n",
      "{'loss': 0.1603, 'learning_rate': 1.782285391876233e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 23.0616, 'train_samples_per_second': 700.039, 'train_steps_per_second': 87.765, 'train_loss': 0.3543485681058861, 'epoch': 8.0}\n",
      "{'eval_loss': 0.17736200988292694, 'eval_accuracy': 0.9821782178217822, 'eval_recall': 0.5, 'eval_precision': 0.6666666666666666, 'eval_f1': 0.5714285714285715, 'eval_runtime': 3.5783, 'eval_samples_per_second': 141.13, 'eval_steps_per_second': 17.886, 'epoch': 8.0}\n",
      "{'loss': 0.2687, 'learning_rate': 0.00011317512238414081, 'epoch': 1.98}\n",
      "{'loss': 0.096, 'learning_rate': 7.604417672005262e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0294, 'learning_rate': 3.8913231055964426e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0199, 'learning_rate': 1.782285391876233e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 24.2239, 'train_samples_per_second': 666.449, 'train_steps_per_second': 83.554, 'train_loss': 0.10226804485890588, 'epoch': 8.0}\n",
      "{'eval_loss': 0.15321369469165802, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.6284, 'eval_samples_per_second': 139.18, 'eval_steps_per_second': 17.639, 'epoch': 8.0}\n",
      "{'loss': 0.1587, 'learning_rate': 0.00011317512238414081, 'epoch': 1.98}\n",
      "{'loss': 0.0228, 'learning_rate': 7.604417672005262e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0257, 'learning_rate': 3.8913231055964426e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0032, 'learning_rate': 1.782285391876233e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.7191, 'train_samples_per_second': 710.593, 'train_steps_per_second': 89.088, 'train_loss': 0.0521403970601766, 'epoch': 8.0}\n",
      "{'eval_loss': 0.00020983941794838756, 'eval_accuracy': 1.0, 'eval_recall': 1.0, 'eval_precision': 1.0, 'eval_f1': 1.0, 'eval_runtime': 4.385, 'eval_samples_per_second': 115.165, 'eval_steps_per_second': 14.595, 'epoch': 8.0}\n",
      "{'loss': 0.0853, 'learning_rate': 0.00011317512238414081, 'epoch': 1.98}\n",
      "{'loss': 0.0273, 'learning_rate': 7.604417672005262e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0198, 'learning_rate': 3.8913231055964426e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0043, 'learning_rate': 1.782285391876233e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 21.135, 'train_samples_per_second': 764.23, 'train_steps_per_second': 95.765, 'train_loss': 0.03376997397258618, 'epoch': 8.0}\n",
      "{'eval_loss': 0.020840419456362724, 'eval_accuracy': 0.998015873015873, 'eval_recall': 1.0, 'eval_precision': 0.9166666666666666, 'eval_f1': 0.9565217391304348, 'eval_runtime': 4.1333, 'eval_samples_per_second': 121.938, 'eval_steps_per_second': 15.242, 'epoch': 8.0}\n",
      "{'loss': 0.0324, 'learning_rate': 0.00011317512238414081, 'epoch': 1.98}\n",
      "{'loss': 0.0337, 'learning_rate': 7.604417672005262e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0061, 'learning_rate': 3.8913231055964426e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0, 'learning_rate': 1.782285391876233e-06, 'epoch': 7.91}\n",
      "{'train_runtime': 22.3988, 'train_samples_per_second': 721.109, 'train_steps_per_second': 90.362, 'train_loss': 0.017833334135807472, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 16:06:32,499] Trial 48 finished with value: 0.829399585921325 and parameters: {'learning_rate': 0.000150306068048229, 'weight_decay': 0.0013936924090544142, 'num_train_epochs': 8}. Best is trial 25 with value: 0.8595837419636047.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.012225878424942493, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.6991, 'eval_samples_per_second': 136.248, 'eval_steps_per_second': 17.031, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/4095140949.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
      "/tmp/ipykernel_130760/4095140949.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6708, 'learning_rate': 0.00024905828939058563, 'epoch': 1.98}\n",
      "{'loss': 0.386, 'learning_rate': 8.627509371046431e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 13.9557, 'train_samples_per_second': 723.0, 'train_steps_per_second': 90.644, 'train_loss': 0.4634969718842638, 'epoch': 5.0}\n",
      "{'eval_loss': 0.1445016860961914, 'eval_accuracy': 0.9782178217821782, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.5384615384615384, 'eval_f1': 0.5599999999999999, 'eval_runtime': 4.7378, 'eval_samples_per_second': 106.589, 'eval_steps_per_second': 13.508, 'epoch': 5.0}\n",
      "{'loss': 0.3839, 'learning_rate': 0.00024905828939058563, 'epoch': 1.98}\n",
      "{'loss': 0.1678, 'learning_rate': 8.627509371046431e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 13.7763, 'train_samples_per_second': 732.418, 'train_steps_per_second': 91.824, 'train_loss': 0.2497690253578156, 'epoch': 5.0}\n",
      "{'eval_loss': 0.12307528406381607, 'eval_accuracy': 0.9881188118811881, 'eval_recall': 0.5, 'eval_precision': 1.0, 'eval_f1': 0.6666666666666666, 'eval_runtime': 3.566, 'eval_samples_per_second': 141.616, 'eval_steps_per_second': 17.947, 'epoch': 5.0}\n",
      "{'loss': 0.3396, 'learning_rate': 0.00024905828939058563, 'epoch': 1.98}\n",
      "{'loss': 0.223, 'learning_rate': 8.627509371046431e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 14.092, 'train_samples_per_second': 716.008, 'train_steps_per_second': 89.767, 'train_loss': 0.2613663202217916, 'epoch': 5.0}\n",
      "{'eval_loss': 0.05993935838341713, 'eval_accuracy': 0.994059405940594, 'eval_recall': 0.75, 'eval_precision': 1.0, 'eval_f1': 0.8571428571428571, 'eval_runtime': 4.13, 'eval_samples_per_second': 122.276, 'eval_steps_per_second': 15.496, 'epoch': 5.0}\n",
      "{'loss': 0.3349, 'learning_rate': 0.00024905828939058563, 'epoch': 1.98}\n",
      "{'loss': 0.2388, 'learning_rate': 8.627509371046431e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 14.3507, 'train_samples_per_second': 703.45, 'train_steps_per_second': 88.149, 'train_loss': 0.2544450360324543, 'epoch': 5.0}\n",
      "{'eval_loss': 0.08646654337644577, 'eval_accuracy': 0.9940476190476191, 'eval_recall': 0.8181818181818182, 'eval_precision': 0.9, 'eval_f1': 0.8571428571428572, 'eval_runtime': 4.3651, 'eval_samples_per_second': 115.461, 'eval_steps_per_second': 14.433, 'epoch': 5.0}\n",
      "{'loss': 0.3282, 'learning_rate': 0.00024905828939058563, 'epoch': 1.98}\n",
      "{'loss': 0.2008, 'learning_rate': 8.627509371046431e-05, 'epoch': 3.95}\n",
      "{'train_runtime': 14.051, 'train_samples_per_second': 718.454, 'train_steps_per_second': 90.029, 'train_loss': 0.23217447152722023, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-09 16:08:25,943] Trial 49 finished with value: 0.7786666666666667 and parameters: {'learning_rate': 0.000411841485070707, 'weight_decay': 0.0006967775337055864, 'num_train_epochs': 5}. Best is trial 25 with value: 0.8595837419636047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01356352586299181, 'eval_accuracy': 0.998015873015873, 'eval_recall': 0.9090909090909091, 'eval_precision': 1.0, 'eval_f1': 0.9523809523809523, 'eval_runtime': 3.4895, 'eval_samples_per_second': 144.435, 'eval_steps_per_second': 18.054, 'epoch': 5.0}\n",
      "0.8595837419636047\n",
      "{'learning_rate': 0.00025987619417987257, 'weight_decay': 0.0010315325907121007, 'num_train_epochs': 9}\n",
      "FrozenTrial(number=25, state=TrialState.COMPLETE, values=[0.8595837419636047], datetime_start=datetime.datetime(2023, 11, 9, 14, 52, 9, 762092), datetime_complete=datetime.datetime(2023, 11, 9, 14, 56, 1, 323781), params={'learning_rate': 0.00025987619417987257, 'weight_decay': 0.0010315325907121007, 'num_train_epochs': 9}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.01, log=True, low=4e-05, step=None), 'weight_decay': FloatDistribution(high=0.01, log=True, low=4e-05, step=None), 'num_train_epochs': IntDistribution(high=10, log=False, low=4, step=1)}, trial_id=25, value=None)\n"
     ]
    }
   ],
   "source": [
    "#https://medium.com/carbon-consulting/transformer-models-hyperparameter-optimization-with-the-optuna-299e185044a8\n",
    "import hyperopt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"DeepChem/ChemBERTa-77M-MTR\", num_labels=2, problem_type = \"single_label_classification\")\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"optuna-test\",\n",
    "        learning_rate=trial.suggest_loguniform(\"learning_rate\", low=4e-5, high=0.01),\n",
    "        weight_decay=trial.suggest_loguniform(\"weight_decay\", 4e-5, 0.01),\n",
    "        num_train_epochs=trial.suggest_int(\"num_train_epochs\", low=4, high=10),\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        disable_tqdm=True,\n",
    "    )\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle = True, random_state=62)\n",
    "\n",
    "    # lists for this cv\n",
    "    y_tests = []\n",
    "    y_preds = []\n",
    "    f1s = []\n",
    "\n",
    "    for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "        # fit model to cv's X[train]\n",
    "\n",
    "        train_df = pd.DataFrame(X[train], columns=['SMILES'])\n",
    "        test_df =  pd.DataFrame(X[test], columns=['SMILES'])\n",
    "\n",
    "        train_dataset = Dataset(train_df, y[train], tokenizer)\n",
    "        test_dataset = Dataset(test_df, y[test], tokenizer)\n",
    "\n",
    "\n",
    "        trainer = CustomTrainer(\n",
    "          model=model,\n",
    "          args=training_args,\n",
    "          train_dataset=train_dataset,\n",
    "          eval_dataset=test_dataset,\n",
    "          compute_metrics=compute_metrics,\n",
    "        )\n",
    "\n",
    "        # predict on cValidation set\n",
    "        result = trainer.train()\n",
    "        predictions = trainer.predict(test_dataset)\n",
    "        y_pred = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "        # save y_test, y_pred (and y_prob) to compute confmats (& curves)\n",
    "        y_tests.append(y[test])\n",
    "        y_preds.append(y_pred)\n",
    "        results = trainer.evaluate()\n",
    "        f1s.append(results['eval_f1'])\n",
    "\n",
    "\n",
    "    #final_score = metric.compute(predictions=y_pred, references=y_test)\n",
    "    return sum(f1s)/len(f1s)\n",
    "\n",
    "\n",
    "# We want to minimise the f1\n",
    "study = optuna.create_study(study_name=\"hyper-parameter-search\", direction=\"maximize\")\n",
    "study.optimize(func=objective, n_trials=50)\n",
    "print(study.best_value)\n",
    "print(study.best_params)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "hwgDeyjYOlx3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.00025987619417987257, 'weight_decay': 0.0010315325907121007, 'num_train_epochs': 9}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "AB7ZRaOBpVBS"
   },
   "outputs": [],
   "source": [
    "X = training_df[['SMILES']]\n",
    "y = training_df['senolytic']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "train_dataset = Dataset(X_train, y_train, tokenizer)\n",
    "test_dataset = Dataset(X_test, y_test, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "scITAOltPAtr"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# many more parameters to experiment with https://huggingface.co/docs/transformers/v4.33.2/en/main_classes/trainer#transformers.TrainingArguments\n",
    "training_args = TrainingArguments(output_dir=\"test_1\", load_best_model_at_end=True, evaluation_strategy='epoch',\n",
    "    logging_strategy=\"epoch\", save_strategy=\"epoch\",per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,optim=\"adamw_torch\", num_train_epochs=study.best_params['num_train_epochs'], learning_rate=study.best_params['learning_rate'],\n",
    "                                  weight_decay=study.best_params['weight_decay']) # switch optimizer to avoid warning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "wtAfs7GKE0dU"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Define a callback for printing validation loss\n",
    "class PrintValidationLossCallback(TrainerCallback):\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        if state is not None and hasattr(state, 'eval_loss'):\n",
    "            print(f\"Validation loss: {state.eval_loss:.4f}\")\n",
    "\n",
    "# Add the callback to the trainer\n",
    "trainer.add_callback(PrintValidationLossCallback())\n",
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "GEDQnTztZeuf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='999' max='999' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [999/999 00:53, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.771000</td>\n",
       "      <td>1.469531</td>\n",
       "      <td>0.978864</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.635300</td>\n",
       "      <td>1.258575</td>\n",
       "      <td>0.974901</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.387097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>1.594242</td>\n",
       "      <td>0.982827</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.409600</td>\n",
       "      <td>1.226784</td>\n",
       "      <td>0.978864</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.240800</td>\n",
       "      <td>1.538455</td>\n",
       "      <td>0.981506</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>1.524746</td>\n",
       "      <td>0.976222</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>1.965213</td>\n",
       "      <td>0.980185</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>1.888573</td>\n",
       "      <td>0.980185</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.516129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>1.908437</td>\n",
       "      <td>0.980185</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.516129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=999, training_loss=0.32371615074776317, metrics={'train_runtime': 53.9751, 'train_samples_per_second': 294.469, 'train_steps_per_second': 18.509, 'total_flos': 74375638590240.0, 'train_loss': 0.32371615074776317, 'epoch': 9.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "8VxPSWR_oprj"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "trainer.save_model(\"./full_model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "t6BCwFDVKM05"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "GqQG_UvsqAXV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(predictions.predictions, axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "athSKeXvraLC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "CuX5MHp_7j3k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# senolytics predicted\n",
    "y_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "5QG0sQUi7oKK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.771,\n",
       "  'learning_rate': 0.00023100106149322004,\n",
       "  'epoch': 1.0,\n",
       "  'step': 111},\n",
       " {'eval_loss': 1.4695311784744263,\n",
       "  'eval_accuracy': 0.9788639365918098,\n",
       "  'eval_recall': 0.058823529411764705,\n",
       "  'eval_precision': 1.0,\n",
       "  'eval_f1': 0.1111111111111111,\n",
       "  'eval_runtime': 4.1391,\n",
       "  'eval_samples_per_second': 182.888,\n",
       "  'eval_steps_per_second': 2.899,\n",
       "  'epoch': 1.0,\n",
       "  'step': 111},\n",
       " {'loss': 0.6353,\n",
       "  'learning_rate': 0.00020212592880656757,\n",
       "  'epoch': 2.0,\n",
       "  'step': 222},\n",
       " {'eval_loss': 1.2585749626159668,\n",
       "  'eval_accuracy': 0.9749009247027741,\n",
       "  'eval_recall': 0.35294117647058826,\n",
       "  'eval_precision': 0.42857142857142855,\n",
       "  'eval_f1': 0.3870967741935484,\n",
       "  'eval_runtime': 4.0022,\n",
       "  'eval_samples_per_second': 189.144,\n",
       "  'eval_steps_per_second': 2.998,\n",
       "  'epoch': 2.0,\n",
       "  'step': 222},\n",
       " {'loss': 0.514,\n",
       "  'learning_rate': 0.00017325079611991504,\n",
       "  'epoch': 3.0,\n",
       "  'step': 333},\n",
       " {'eval_loss': 1.594241976737976,\n",
       "  'eval_accuracy': 0.9828269484808454,\n",
       "  'eval_recall': 0.35294117647058826,\n",
       "  'eval_precision': 0.75,\n",
       "  'eval_f1': 0.48,\n",
       "  'eval_runtime': 3.779,\n",
       "  'eval_samples_per_second': 200.318,\n",
       "  'eval_steps_per_second': 3.175,\n",
       "  'epoch': 3.0,\n",
       "  'step': 333},\n",
       " {'loss': 0.4096,\n",
       "  'learning_rate': 0.00014437566343326254,\n",
       "  'epoch': 4.0,\n",
       "  'step': 444},\n",
       " {'eval_loss': 1.2267839908599854,\n",
       "  'eval_accuracy': 0.9788639365918098,\n",
       "  'eval_recall': 0.47058823529411764,\n",
       "  'eval_precision': 0.5333333333333333,\n",
       "  'eval_f1': 0.5,\n",
       "  'eval_runtime': 3.6757,\n",
       "  'eval_samples_per_second': 205.944,\n",
       "  'eval_steps_per_second': 3.265,\n",
       "  'epoch': 4.0,\n",
       "  'step': 444},\n",
       " {'loss': 0.2408,\n",
       "  'learning_rate': 0.00011550053074661002,\n",
       "  'epoch': 5.0,\n",
       "  'step': 555},\n",
       " {'eval_loss': 1.5384554862976074,\n",
       "  'eval_accuracy': 0.9815059445178336,\n",
       "  'eval_recall': 0.47058823529411764,\n",
       "  'eval_precision': 0.6153846153846154,\n",
       "  'eval_f1': 0.5333333333333333,\n",
       "  'eval_runtime': 4.2357,\n",
       "  'eval_samples_per_second': 178.718,\n",
       "  'eval_steps_per_second': 2.833,\n",
       "  'epoch': 5.0,\n",
       "  'step': 555},\n",
       " {'loss': 0.18,\n",
       "  'learning_rate': 8.662539805995752e-05,\n",
       "  'epoch': 6.0,\n",
       "  'step': 666},\n",
       " {'eval_loss': 1.524746060371399,\n",
       "  'eval_accuracy': 0.9762219286657859,\n",
       "  'eval_recall': 0.5294117647058824,\n",
       "  'eval_precision': 0.47368421052631576,\n",
       "  'eval_f1': 0.5,\n",
       "  'eval_runtime': 4.4014,\n",
       "  'eval_samples_per_second': 171.989,\n",
       "  'eval_steps_per_second': 2.726,\n",
       "  'epoch': 6.0,\n",
       "  'step': 666},\n",
       " {'loss': 0.0634,\n",
       "  'learning_rate': 5.775026537330501e-05,\n",
       "  'epoch': 7.0,\n",
       "  'step': 777},\n",
       " {'eval_loss': 1.9652127027511597,\n",
       "  'eval_accuracy': 0.9801849405548216,\n",
       "  'eval_recall': 0.4117647058823529,\n",
       "  'eval_precision': 0.5833333333333334,\n",
       "  'eval_f1': 0.4827586206896552,\n",
       "  'eval_runtime': 4.4861,\n",
       "  'eval_samples_per_second': 168.744,\n",
       "  'eval_steps_per_second': 2.675,\n",
       "  'epoch': 7.0,\n",
       "  'step': 777},\n",
       " {'loss': 0.0626,\n",
       "  'learning_rate': 2.8875132686652505e-05,\n",
       "  'epoch': 8.0,\n",
       "  'step': 888},\n",
       " {'eval_loss': 1.888573169708252,\n",
       "  'eval_accuracy': 0.9801849405548216,\n",
       "  'eval_recall': 0.47058823529411764,\n",
       "  'eval_precision': 0.5714285714285714,\n",
       "  'eval_f1': 0.5161290322580646,\n",
       "  'eval_runtime': 4.1773,\n",
       "  'eval_samples_per_second': 181.216,\n",
       "  'eval_steps_per_second': 2.873,\n",
       "  'epoch': 8.0,\n",
       "  'step': 888},\n",
       " {'loss': 0.0368, 'learning_rate': 0.0, 'epoch': 9.0, 'step': 999},\n",
       " {'eval_loss': 1.908436894416809,\n",
       "  'eval_accuracy': 0.9801849405548216,\n",
       "  'eval_recall': 0.47058823529411764,\n",
       "  'eval_precision': 0.5714285714285714,\n",
       "  'eval_f1': 0.5161290322580646,\n",
       "  'eval_runtime': 3.5473,\n",
       "  'eval_samples_per_second': 213.404,\n",
       "  'eval_steps_per_second': 3.383,\n",
       "  'epoch': 9.0,\n",
       "  'step': 999},\n",
       " {'train_runtime': 53.9751,\n",
       "  'train_samples_per_second': 294.469,\n",
       "  'train_steps_per_second': 18.509,\n",
       "  'total_flos': 74375638590240.0,\n",
       "  'train_loss': 0.32371615074776317,\n",
       "  'epoch': 9.0,\n",
       "  'step': 999}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "fV2PWhiFZbP_"
   },
   "outputs": [],
   "source": [
    "training_losses = [element['loss'] for element in trainer.state.log_history if 'loss' in element.keys()]\n",
    "val_losses = [element['eval_loss'] for element in trainer.state.log_history if 'eval_loss' in element.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "5qHIg_KbZ1px"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.title(\"Train and validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks([i for i in range(0,len(val_losses))])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "-hF5zaSDteh1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9788639365918098\n",
      "Precision: 0.5333333333333333\n",
      "Recall: 0.47058823529411764\n",
      "F1: 0.5\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "pE2ZM8FXu_aO"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.PrecisionRecallDisplay.html\n",
    "from sklearn.metrics import (precision_recall_curve,\n",
    "                              PrecisionRecallDisplay)\n",
    "\n",
    "disp = PrecisionRecallDisplay.from_predictions(y_test, y_pred)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DG4kSuxgxb8X",
    "outputId": "e2e1b720-c53d-4dbb-ad40-b38ce46d0f1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 191, 271, 359, 554, 598, 618, 729]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/67432457/python-get-the-index-of-two-list-where-the-values-are-the-same\n",
    "print([i for i, v in enumerate(list(y_pred)) if v == list(y_test)[i] and v==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ESeeSJV6x1mi"
   },
   "outputs": [],
   "source": [
    "#X_test.iloc[213]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "peULwIvIyMEo",
    "outputId": "e6209437-c3fe-4ba2-88c7-c01f8a152d14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SMILES    c12c(\\C(=C/C(O1)=O)\\C)cc1c(c2C)oc(c1)C\n",
       "Name: 702, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[244]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5wtXyo8gPss",
    "outputId": "e4c6bb80-afaa-416f-89a4-3b3f3a8f82aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8595837419636047\n",
      "{'learning_rate': 0.00025987619417987257, 'weight_decay': 0.0010315325907121007, 'num_train_epochs': 9}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_value)\n",
    "print(study.best_params)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "091723f2ddaa43b98f16a4756fd02390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8088374a3d6f4332b642708bbd768add",
      "max": 6771,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d97c6f2aac474568949ac75dcae64a78",
      "value": 6771
     }
    },
    "1bee975014d1451b9ff65d5fe1900ff3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7f77b287bc334e3dba59b9d4c3307e46",
       "IPY_MODEL_091723f2ddaa43b98f16a4756fd02390",
       "IPY_MODEL_5d939c494595405797930594beee593d"
      ],
      "layout": "IPY_MODEL_74135322bba54fa3b6578825dbfac89f"
     }
    },
    "35f2824b2c644032a227f956719fe2a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58da272eecb64352a162858fdfdb9a10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d939c494595405797930594beee593d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58da272eecb64352a162858fdfdb9a10",
      "placeholder": "​",
      "style": "IPY_MODEL_f5f0d29fc0ef4fcfb09f17906c822687",
      "value": " 6.77k/6.77k [00:00&lt;00:00, 224kB/s]"
     }
    },
    "74135322bba54fa3b6578825dbfac89f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f77b287bc334e3dba59b9d4c3307e46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9781d331577d4612bcabe465634f52a2",
      "placeholder": "​",
      "style": "IPY_MODEL_35f2824b2c644032a227f956719fe2a7",
      "value": "Downloading builder script: 100%"
     }
    },
    "8088374a3d6f4332b642708bbd768add": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9781d331577d4612bcabe465634f52a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d97c6f2aac474568949ac75dcae64a78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f5f0d29fc0ef4fcfb09f17906c822687": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
